{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ‘‹ Basics of LangChain \n",
    "\n",
    "The **key goal** of this tutorial is to get comfortable using the Python library, LangChain. \n",
    "\n",
    "Where you see a **ðŸ›¸ TASK** in the tutorial, you will need to complete the task before moving on.\n",
    "\n",
    "This tutorial relies heavily on a number of different resources mentioned below. Feel free to refer to some of these materials during the tutorial and in your project work: \n",
    "\n",
    "#### Documentation \n",
    "\n",
    "- [langchain](https://python.langchain.com/docs/get_started/introduction.html)\n",
    "    -  [langchain integrations](https://python.langchain.com/docs/integrations): \n",
    "\n",
    "#### Repos \n",
    "\n",
    "- [The Practical Guides to Large Language Models](https://github.com/Mooler0410/LLMsPracticalGuide)\n",
    "- [A series of langchain tutorials](https://github.com/gkamradt/langchain-tutorials)\n",
    "\n",
    "#### Videos\n",
    "\n",
    "- [LangChain Crash Course for Beginners](https://www.youtube.com/watch?v=nAmC7SoVLd8)\n",
    "\n",
    "#### Blogs\n",
    "\n",
    "- [Retrival Augmented Generation](https://betterprogramming.pub/harnessing-retrieval-augmented-generation-with-langchain-2eae65926e82)\n",
    "\n",
    "**NOTE:** We won't be able to examine all of LangChain's capabilities - we are simply exploring its core principals. Please do refer to the additional material mentioned above and the library's documentation to explore its additional functionalities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from dap_taltech.utils.data_getters import DataGetter\n",
    "from dap_taltech import logger\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI, OpenAIChat\n",
    "\n",
    "from langchain.output_parsers import (\n",
    "    PydanticOutputParser, \n",
    "    CommaSeparatedListOutputParser,\n",
    "    DatetimeOutputParser,\n",
    "    EnumOutputParser,\n",
    "    OutputFixingParser,\n",
    "    RetryWithErrorOutputParser)\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import SystemMessage\n",
    "\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "from langchain.chains import (ConversationalRetrievalChain, \n",
    "                              SequentialChain, \n",
    "                              LLMChain)\n",
    "\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.prompts import MessagesPlaceholder, ChatPromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "from langchain.memory import ConversationTokenBufferMemory, ConversationBufferMemory\n",
    "\n",
    "from langchain.document_loaders import WikipediaLoader, DataFrameLoader \n",
    "\n",
    "from langchain.agents import create_pandas_dataframe_agent, tool, OpenAIFunctionsAgent, AgentExecutor\n",
    "from langchain.agents.agent_types import AgentType"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preamble\n",
    "\n",
    "The code block below is the preamble to this tutorial so that:\n",
    "\n",
    "- we install our dependencies;\n",
    "- have access to our datasets; and \n",
    "- our OpenAI API key. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\n",
    "    f\"pip install -r {Path.cwd()}/llm_requirements.txt --quiet\" #install requirements to run this notebook\n",
    ")\n",
    "\n",
    "load_dotenv() # load environment variables\n",
    "\n",
    "oa_key = os.environ.get('OPENAI_API_KEY') #get our open api key from our environment variable \n",
    "\n",
    "if not oa_key:\n",
    "    logger.error(\"No open api key found. Please set your openAI api key as an environment variable named OPENAI_API_KEY.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tour of LangChain ðŸ¦œðŸ”—: Building a language model application\n",
    "\n",
    "LangChain is a python \"framework for developing applications powered by language models.\" \n",
    "\n",
    "According to [LangChain's documentation](https://github.com/langchain-ai/langchain), there are **6 key areas** that LangChain is designed to help you with (in order of complexity):\n",
    "\n",
    "**ðŸ“ƒ LLMs and Prompts:**\n",
    "\n",
    "This includes prompt management, prompt optimization, a generic interface for all LLMs, and common utilities for working with LLMs.\n",
    "\n",
    "**ðŸ”— Chains**:\n",
    "\n",
    "Chains go beyond a single LLM call and involve sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.\n",
    "\n",
    "**ðŸ“š Data Augmented Generation:**\n",
    "\n",
    "Data Augmented Generation involves specific types of chains that first interact with an external data source to fetch data for use in the generation step. Examples include summarization of long pieces of text and question/answering over specific data sources.\n",
    "\n",
    "**ðŸ¤– Agents:**\n",
    "\n",
    "Agents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain provides a standard interface for agents, a selection of agents to choose from, and examples of end-to-end agents.\n",
    "\n",
    "**ðŸ§  Memory:**\n",
    "\n",
    "Memory refers to persisting state between calls of a chain/agent. LangChain provides a standard interface for memory, a collection of memory implementations, and examples of chains/agents that use memory.\n",
    "\n",
    "**ðŸ§ Evaluation:**\n",
    "\n",
    "Generative models are notoriously hard to evaluate with traditional metrics. One new way of evaluating them is using language models themselves to do the evaluation. LangChain provides some prompts/chains for assisting in this."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we will touch on most of these concepts, this tutorial will go more in depth on:\n",
    "\n",
    "1. ðŸ“ƒ LLMs and Prompts;\n",
    "2. ðŸ”—ðŸ¤– Chains & Agents; and\n",
    "3. ðŸ“š Data & Retrival Augmented Generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Rome, Italy\n",
      "2. Venice, Italy\n",
      "3. Bologna, Italy\n",
      "4. Naples, Italy\n",
      "5. Tuscany, Italy\n"
     ]
    }
   ],
   "source": [
    "model = OpenAI(temperature=0.9) #instantiate our language model. The temperature parameter controls how \"creative\" the model is.\n",
    "\n",
    "#make this innovation mapping related \n",
    "text = \"What are 5 vacation destinations for someone who likes to eat pasta?\" #define our prompt\n",
    "\n",
    "print(model(text)) #print the output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## â“ Choosing a model \n",
    "\n",
    "LangChain allows you to pick from many different types of language models and use them in your application. Pending access resrictions (i.e. paying for an API) you can pick from a [range of LLMs](https://python.langchain.com/docs/integrations/llms/) or [chat models](https://python.langchain.com/docs/integrations/chat/). \n",
    "\n",
    "It's worth considering things such as:\n",
    "\n",
    "1. **Privacy**. Do you want to use a model that is hosted on a server or do you want to use a model that is hosted locally?  \n",
    "\n",
    "2. **Cost**. Do you want to pay for access to a model or do you want to use a free model?\n",
    "\n",
    "3. **Token window size**. How long will your prompts be? You can use a model that supports a larger token window size if you need to accomodate longer prompts.\n",
    "\n",
    "4. **LLMs vs. chat models**. What type of model do you need? LLMs are good for generating text, while chat models are good for having conversations. As LangChain states: _LLMs in LangChain refer to pure text completion models. The APIs they wrap take a string prompt as input and output a string completion. Meanwhile, chat models are often backed by LLMs but tuned specifically for having conversations. And, crucially, their provider APIs expose a different interface than pure text completion models. Instead of a single string, they take a list of chat messages as input._  \n",
    "\n",
    "In this tutorial, we'll primarily be using OpenAI LLMs and chat models unless otherwise stated.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ƒ Prompts \n",
    "\n",
    "Prompts refer to the textual input into the model.\n",
    "\n",
    "You can use langchain to create prompts, such as a simple hardcoded prompt using the PromptTemplate class or passing examples as part of `few-shot prompting`. \n",
    "\n",
    "**ðŸ›¸ TASK**: Can you re-write the `text` prompt to take as input variables:\n",
    "\n",
    "1. The number of vacation destinations;\n",
    "2. The meal type\n",
    "\n",
    "And rerun the code block below?\n",
    "\n",
    "Refer to the [prompt template documentation](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/) for guidance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define your prompt template to take as input \"number\" and \"meal\" variables.\n",
    "multiple_input_prompt = PromptTemplate(###) \n",
    "    \n",
    "#format your prompt template with the variables you want to use using PromptTemplate\n",
    "\n",
    "prompt = ###\n",
    "\n",
    "## Format the prompt with the PromptTemplate and convert to string \n",
    "input = prompt.format_prompt().to_string()\n",
    "\n",
    "## pass the prompt to the language model\n",
    "\n",
    "model(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸ›¸ TASK**: Can you create a similar prompt using the `ChatPromptTemplate` class instead for a chat model in the cell below? You will need to instantiate a chat model first. What are the differences in the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = OpenAIChat(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "##Define your prompt template to take as input \"number\" and \"meal\" variables.\n",
    "template = ChatPromptTemplate.from_messages([#### ])\n",
    "\n",
    "##Format your prompt template with the variables you want to use using PromptTemplate\n",
    "messages = template.format_messages(\n",
    "    number=#,\n",
    "    meal=#,\n",
    ")\n",
    "\n",
    "##pass the prompt to the chat model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Now that we understand the basics of constructing a prompt and using a prompt template, let's discuss a common prompt engineering technique called few-shot prompting."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“ƒ Prompts: Few-shot prompting\n",
    "\n",
    "Few-shot prompting is a prompt engineering technique to improve the models output. To do so, you need to pass in a list of examples as part of `few-shot prompting`. In LangChain, a few shot prompt template can be constructed from either a set of examples, or from an Example Selector object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt looks like this:\n",
      "-----------------------------------\n",
      "Question: What is the capital of Estonia?\n",
      "The capital of Estonia is: Tallinn\n",
      "-----------------------------------\n",
      "Question: What is the capital of Estonia?\n",
      "The capital of Estonia is: Tallinn\n",
      "\n",
      "Question: What is the capital of France?\n",
      "The capital of France is: Paris\n",
      "\n",
      "Question: What is the capital of Germany?\n",
      "The capital of Germany is: Berlin\n",
      "\n",
      "Question: What is the capital of Australia?\n",
      "\n",
      "the output using few-shot prompting is: \n",
      "The capital of Australia is: Canberra\n",
      "\n",
      "the output not using examples is: \n",
      "\n",
      "Answer: The capital of Australia is Canberra.\n"
     ]
    }
   ],
   "source": [
    "#We first need to create a list of examples to pass to the prompt template\n",
    "\n",
    "examples = [\n",
    "    {\"question\": \"What is the capital of Estonia?\", \"answer\": \"The capital of Estonia is: Tallinn\"},\n",
    "    {\"question\": \"What is the capital of France?\", \"answer\": \"The capital of France is: Paris\"},\n",
    "    {\"question\": \"What is the capital of Germany?\", \"answer\": \"The capital of Germany is: Berlin\"},\n",
    "] \n",
    "\n",
    "#we then create our prompt template \n",
    "example_prompt = PromptTemplate(input_variables=[\"question\", \"answer\"], template=\"Question: {question}\\n{answer}\")\n",
    "\n",
    "print('The prompt looks like this:')\n",
    "print('-----------------------------------')\n",
    "print(example_prompt.format(**examples[0]))\n",
    "print('-----------------------------------')\n",
    "\n",
    "#instantiating our fewshot prompt template\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples=examples, \n",
    "    example_prompt=example_prompt, \n",
    "    suffix=\"Question: {input}\", \n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "input = prompt.format(input=\"What is the capital of Australia?\")\n",
    "#You can see that in the prompt, we have passed the examples as input to the prompt template:\n",
    "print(input)\n",
    "\n",
    "##lets see what our model does with this prompt\n",
    "output_few_shot = model(input)\n",
    "##what about without examples?\n",
    "output_zero_shot = model(\"Question: What is the capital of Australia?\")\n",
    "print('')\n",
    "print(f'the output using few-shot prompting is: {output_few_shot}')\n",
    "print('')\n",
    "print(f'the output not using examples is: {output_zero_shot}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸ›¸ TASK** Reflect on the following questions: How does the input to the model change when you pass in a list of examples as part of `few-shot prompting`? Why might this be useful for applications? \n",
    "\n",
    "Refer to LangChain's [example selector documentation](https://python.langchain.com/docs/modules/model_io/prompts/example_selectors). When would you use an example selector as opposed to hardcoding examples into the prompt? What are the benefits to the different kinds of example selectors LangChain supports?   \n",
    "\n",
    "Can you create a few-shot prompt template for a prompt of your choice using a [length based example selector](https://python.langchain.com/docs/modules/model_io/prompts/example_selectors/length_based) in the cell below?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assume that the list of examples is very large and you need a way to select the most relevant examples \n",
    "# using a length based example selector\n",
    "\n",
    "#define your list of examples here\n",
    "examples = [###\n",
    "    \n",
    "#define your example prompt\n",
    "example_prompt =  PromptTemplate(###\n",
    "\n",
    "#define your example selector \n",
    "example_selector = LengthBasedExampleSelector(###\n",
    "                                              \n",
    "#define your prompt using your example selector\n",
    "\n",
    "prompt = FewShotPromptTemplate(###\n",
    "                               \n",
    "#An example with long input, so it selects only one example.\n",
    "long_string = \"this is a veeeerrrrrryyyyyy long stringggggggggg, it coulddddddnt beeeeeeeee longerrrrrrrr\"\n",
    "input = prompt.format(###\n",
    "                 \n",
    "model(input)                     "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“ƒ Prompts: Parsing output \n",
    "\n",
    "Language models output text. However, sometimes you may want to get more structured information from the model's output. LangChain supports this vis-a-vi output parsers. There are two methods to implement output parsers in LangChain:\n",
    "\n",
    "Via: \n",
    "1. A prompt's format instructions;\n",
    "2. Parsing the output directly.\n",
    "\n",
    "LangChain supports a number of [different output parsers](https://python.langchain.com/docs/modules/model_io/output_parsers/), such as:\n",
    "\n",
    "- **List Parser**: Parses LLM output to be a list of strings.\n",
    "- **JSON Parser**: Parses LLM output to be in JSON format.\n",
    "- **Datetime Parser**: Parses LLM output into datetime format.\n",
    "\n",
    "There are also external libraries that can help with structuring outputs, like [Kor](https://eyurtsev.github.io/kor/), a wrapper to that allows you to specify a schema of what should be extracted and provide examples (like what we saw in **ðŸ’Œ Prompts: Few-shot prompting**).\n",
    "\n",
    "Let's explore the different types of output parsers, writing your own output parser and using an external library to parse the output in the cells below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz`\n"
     ]
    }
   ],
   "source": [
    "#Lets consider the same prompt again (\"What are 5 vacation destinations for someone who likes to eat pasta?\")\n",
    "\n",
    "#we would like to return a list of vacation destination strings as output. We can do that using LangChain's output parsers\n",
    "\n",
    "#First, lets define our output parser \n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "#print the format instructions to get a sense of what the output parser expects\n",
    "print(format_instructions)\n",
    "\n",
    "#define your Prompt Template, passing the output parser as an argument\n",
    "prompt = PromptTemplate(input_variables=[\"number\", \"meal\"], \n",
    "                        #Add format instructions in the template\n",
    "                        template=\"What are {number} vacation destinations for someone who likes to eat {meal}?\\n{format_instructions}\",\n",
    "                        #we add our format instructions to the partial variable here\n",
    "                        partial_variables={\"format_instructions\": format_instructions})\n",
    "\n",
    "#define your input \n",
    "_input = prompt.format(number=\"3\", meal=\"salad\")\n",
    "\n",
    "#pass the input to the model\n",
    "output = model(_input)\n",
    "output_parsed = output_parser.parse(output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets see what the raw output looks like and what the parsed output looks like..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model returns the following output: \n",
      "\n",
      "Rome, Italy, Paris, France, Bangkok, Thailand\n",
      "the parsed output is: ['Rome', 'Italy', 'Paris', 'France', 'Bangkok', 'Thailand']\n"
     ]
    }
   ],
   "source": [
    "print(f\"the model returns the following output: {output}\")\n",
    "print(f\"the parsed output is: {output_parsed}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets try a more complex example by defining our own response schema. You can define a response schema for which you want to return multiple fields using the `ResponseSchema` and `StructuredOutputParser` classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the initial output of the model is: \n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"name\": \"Kylie Jenner\",\n",
      "\t\"date\": \"Thursday\"\n",
      "}\n",
      "```\n",
      "the parsed output is: {'name': 'Kylie Jenner', 'date': 'Thursday'}\n"
     ]
    }
   ],
   "source": [
    "schema = [ResponseSchema(name=\"name\", \n",
    "                         description=\"The first and last name of a person. Must be a string.\"),\n",
    "          ResponseSchema(name=\"date\", \n",
    "                         description=\"The date of an event. Must be a string.\")]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(schema)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "#define your Prompt Template, passing the output parser as an argument\n",
    "prompt = PromptTemplate(input_variables=[\"sentence\"], \n",
    "                        #Add format instructions in the template\n",
    "                        template=\"Extract names and dates from the following sentence:{sentence}\\n{format_instructions}\",\n",
    "                        #we add our format instructions to the partial variable here\n",
    "                        partial_variables={\"format_instructions\": format_instructions})\n",
    "\n",
    "#define your input \n",
    "sentence = \"Kylie Jenner turned 26-years-old on Thursday.\"\n",
    "_input = prompt.format(sentence=sentence)\n",
    "\n",
    "#pass the input to the model\n",
    "output = model(_input)\n",
    "output_parsed = output_parser.parse(output)\n",
    "\n",
    "print(f\"the initial output of the model is: {output}\")\n",
    "print(f\"the parsed output is: {output_parsed}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸ›¸ TASK**: Experiment with different prompts and types of output parsers that LangChain supports. What are the purposes of `OutputFixingParser` and `RetryWithErrorOutputParser`? Can you write your own custom output parser?\n",
    "\n",
    "Refer to documentation on [output parsers](https://python.langchain.com/docs/modules/model_io/output_parsers/) for guidance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experiment here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“ƒ Prompts: Chaining it all together\n",
    "\n",
    "So far, we've learned about:\n",
    "\n",
    "1. Writing a simple prompt;\n",
    "2. Using LangChain's prompt templates;\n",
    "3. Using few-shot prompting and;\n",
    "4. Parsing the output of the model by passing formatting instructions. \n",
    "\n",
    "This should give you a good foundation to start building your own prompts and is a good departure point to explore LangChain's **ðŸ”—ðŸ¤– chains & agents.** "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”—ðŸ¤– Chains & Agents\n",
    "\n",
    "The core idea of the LangChain is that we can \"chain\" together different components to create more advanced use cases around LLMs. Chains are simply end-to-end wrappers around multiple individual components.\n",
    "\n",
    "The simplest chain is the LLMchain. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. We've already explored all 3 of these components in the previous sections.  \n",
    "\n",
    "Let's see what that looks like in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Kim Kardashian', 'text': '\\n\\nKendall Jenner.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define your prompt\n",
    "prompt_template = \"What is a good alternative name for a celebrity called {name}?\"\n",
    "\n",
    "#here we define the chain - we pass the prompt template and the model to the LLMChain\n",
    "llm_chain = LLMChain(\n",
    "    llm=model,\n",
    "    prompt=PromptTemplate.from_template(prompt_template)\n",
    ")\n",
    "\n",
    "#execute your chain\n",
    "llm_chain('Kim Kardashian')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also pass an output parser to the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adjective': 'spicy',\n",
       " 'meal': 'laksa',\n",
       " 'text': '\\n\\n-Rice vermicelli\\n-Curry paste (of your choice)\\n-Canned coconut milk\\n-Vegetable stock\\n-Shallots\\n-Garlic\\n-Shrimps\\n-Fish sauce\\n-Sugar\\n-Lemongrass\\n-Lime juice\\n-Coriander\\n-Cumin\\n-Red chilli\\n-Red onion\\n-Tomatoes\\n-Fresh coriander'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiate the output parser\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "#define your prompt\n",
    "template = \"\"\"Give me the ingredients for a {adjective} {meal}\"\"\"\n",
    "\n",
    "#instantiate the prompt template\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"adjective\", \"meal\"], output_parser=output_parser)\n",
    "\n",
    "#chain the prompt template and the model\n",
    "llm_chain = LLMChain(prompt=prompt, \n",
    "                     llm=model)\n",
    "\n",
    "#execute your chain\n",
    "llm_chain({'adjective': \"spicy\", 'meal': \"laksa\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”—ðŸ¤– Chains & Agents: Sequential and Index-related chains"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets explore a few other chains and categories of chains that LangChain supports: \n",
    "\n",
    "1. `SequentialChain`: A chain that executes a sequence of chains in order.\n",
    "2. **Index-related chains**: A category of chains that allows you to combine your own data (stored in indexes) with LLMs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an LLMChain to write a headline for a celebrity gossip article\n",
    "\n",
    "llm = OpenAI(temperature=.7)\n",
    "template = \"\"\"You are a news reporter. Given a celebrity name and a date, write a gossip headline for an article about them.\n",
    "\n",
    "name: {name}\n",
    "date: {date}\n",
    "\n",
    "news reporter: This just in:\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"name\", \"date\"], template=template)\n",
    "gossip_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"gossip\")\n",
    "\n",
    "# This is an LLMChain to write a celebrity response, given the headline. \n",
    "\n",
    "llm = OpenAI(temperature=.7)\n",
    "\n",
    "template = \"\"\"You are a celebrity. Given a headline about you, you are writing a response to it.\n",
    "\n",
    "News headline:\n",
    "{gossip}\n",
    "\n",
    "Response from a celebrity of the above headline:\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=[\"gossip\"], template=template)\n",
    "response_chain = LLMChain(llm=llm, prompt=prompt_template, output_key=\"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Drake',\n",
       " 'date': 'April 2021',\n",
       " 'gossip': ' Drake Sparks Romance Rumors in April 2021!',\n",
       " 'response': \" \\nI'm flattered by the rumors, but I'm focused on my music right now. I'm just enjoying the moment.\"}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the overall chain where we chain the two chains together\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[gossip_chain, response_chain],\n",
    "    input_variables=[\"name\", \"date\"],\n",
    "    # Here we return multiple variables\n",
    "    output_variables=[\"gossip\", \"response\"],\n",
    "    verbose=True)\n",
    "\n",
    "overall_chain({\"name\":\"Drake\", \"date\": \"April 2021\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at index-related chains. This category of chains are used for interacting with indexes, with the key purpose of allowing you to combine your own data (stored in indexes) with LLMs. \n",
    "\n",
    "There are a few different types of index-related chains: `stuff`, `map_reduce` and `refine`.\n",
    "\n",
    "`stuff`: you simply stuff all the related data into the prompt as context to pass to the language model.\n",
    "\n",
    "`map_reduce`: This method involves running an initial prompt on each chunk of data (for summarization tasks, this could be a summary of that chunk; for question-answering tasks, it could be an answer based solely on that chunk). Then a different prompt is run to combine all the initial outputs. \n",
    "\n",
    "`refine`: This method involves running an initial prompt on the first chunk of data, generating some output. For the remaining documents, that output is passed in, along with the next document, asking the LLM to refine the output based on the new document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94;1;1m2023-08-11 15:17:18,293 - TalTech HackWeek 2023 - INFO - Loading data from open dap-taltech s3 bucket. (data_getters.py:58)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'output_text': ' Types of inventions patented include a method of making a transparent visible light activated photocatalytic superhydrophilic glass material, a system and method for power transfer between two DC voltage sources, a therapeutic mud mixture, and a sensor for the detection of Neurotrophic Factor.'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First, lets load a pre-defined question answering chain\n",
    "\n",
    "#lets load some data\n",
    "dg = DataGetter(local=False)\n",
    "#we're going to get a sample of 10 estonian patents\n",
    "#who's assignee is from tallinn\n",
    "patents_sample = (dg.get_estonian_patents()\n",
    " .explode('assignee_harmonized_names')\n",
    " .query('assignee_harmonized_names.str.contains(\"TALLINN\")')\n",
    " .drop_duplicates('family_id')\n",
    " .sample(10, random_state=42))\n",
    "\n",
    "#lets load the data into a dataframe loader\n",
    "loader = DataFrameLoader(patents_sample, page_content_column=\"abstract_localized\")\n",
    "docs =loader.load()\n",
    "\n",
    "#lets define our prompt - we want to ask questions about patents\n",
    "#from tallinn assignees using patent abstracts \n",
    "prompt = \"\"\"You are a patent examiner. Given patent abstracts, answer the following question:\n",
    "\n",
    "{Question}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "chain = load_qa_chain(llm, chain_type=\"map_reduce\") #here, we can define the chain type to be \"stuff\", \"map_reduce\" or \"refine\".\n",
    "chain({\"input_documents\": docs, \n",
    "       \"question\": \"What are the types of inventions patented?\"}, return_only_outputs=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸ›¸ TASK**: Spend some time exploring the types of chains that LangChain supports. Can you build your own chain using a combination of the components we've explored so far?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package langchain.chains in langchain:\n",
      "\n",
      "NAME\n",
      "    langchain.chains - Chains are easily reusable components which can be linked together.\n",
      "\n",
      "DESCRIPTION\n",
      "    Chains should be used to encode a sequence of calls to components like\n",
      "    models, document retrievers, other chains, etc., and provide a simple interface\n",
      "    to this sequence.\n",
      "    \n",
      "    The Chain interface makes it easy to create apps that are:\n",
      "        - Stateful: add Memory to any Chain to give it state,\n",
      "        - Observable: pass Callbacks to a Chain to execute additional functionality,\n",
      "            like logging, outside the main sequence of component calls,\n",
      "        - Composable: the Chain API is flexible enough that it is easy to combine\n",
      "            Chains with other components, including other Chains.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    api (package)\n",
      "    base\n",
      "    chat_vector_db (package)\n",
      "    combine_documents (package)\n",
      "    constitutional_ai (package)\n",
      "    conversation (package)\n",
      "    conversational_retrieval (package)\n",
      "    elasticsearch_database (package)\n",
      "    flare (package)\n",
      "    graph_qa (package)\n",
      "    hyde (package)\n",
      "    llm\n",
      "    llm_bash (package)\n",
      "    llm_checker (package)\n",
      "    llm_math (package)\n",
      "    llm_requests\n",
      "    llm_summarization_checker (package)\n",
      "    llm_symbolic_math (package)\n",
      "    loading\n",
      "    mapreduce\n",
      "    moderation\n",
      "    natbot (package)\n",
      "    openai_functions (package)\n",
      "    pal (package)\n",
      "    prompt_selector\n",
      "    qa_generation (package)\n",
      "    qa_with_sources (package)\n",
      "    query_constructor (package)\n",
      "    question_answering (package)\n",
      "    retrieval_qa (package)\n",
      "    router (package)\n",
      "    sequential\n",
      "    sql_database (package)\n",
      "    summarize (package)\n",
      "    transform\n",
      "\n",
      "CLASSES\n",
      "    abc.ABC(builtins.object)\n",
      "        langchain.chains.router.base.RouterChain(langchain.chains.base.Chain, abc.ABC)\n",
      "            langchain.chains.router.llm_router.LLMRouterChain\n",
      "    langchain.chains.base.Chain(langchain.load.serializable.Serializable, abc.ABC)\n",
      "        langchain.chains.api.base.APIChain\n",
      "        langchain.chains.api.openapi.chain.OpenAPIEndpointChain(langchain.chains.base.Chain, pydantic.main.BaseModel)\n",
      "        langchain.chains.combine_documents.base.AnalyzeDocumentChain\n",
      "        langchain.chains.constitutional_ai.base.ConstitutionalChain\n",
      "        langchain.chains.flare.base.FlareChain\n",
      "        langchain.chains.graph_qa.base.GraphQAChain\n",
      "        langchain.chains.graph_qa.cypher.GraphCypherQAChain\n",
      "        langchain.chains.graph_qa.hugegraph.HugeGraphQAChain\n",
      "        langchain.chains.graph_qa.kuzu.KuzuQAChain\n",
      "        langchain.chains.graph_qa.nebulagraph.NebulaGraphQAChain\n",
      "        langchain.chains.graph_qa.sparql.GraphSparqlQAChain\n",
      "        langchain.chains.hyde.base.HypotheticalDocumentEmbedder(langchain.chains.base.Chain, langchain.embeddings.base.Embeddings)\n",
      "        langchain.chains.llm.LLMChain\n",
      "            langchain.chains.conversation.base.ConversationChain\n",
      "        langchain.chains.llm_bash.base.LLMBashChain\n",
      "        langchain.chains.llm_checker.base.LLMCheckerChain\n",
      "        langchain.chains.llm_math.base.LLMMathChain\n",
      "        langchain.chains.llm_requests.LLMRequestsChain\n",
      "        langchain.chains.llm_summarization_checker.base.LLMSummarizationCheckerChain\n",
      "        langchain.chains.mapreduce.MapReduceChain\n",
      "        langchain.chains.moderation.OpenAIModerationChain\n",
      "        langchain.chains.natbot.base.NatBotChain\n",
      "        langchain.chains.pal.base.PALChain\n",
      "        langchain.chains.qa_generation.base.QAGenerationChain\n",
      "        langchain.chains.router.base.MultiRouteChain\n",
      "            langchain.chains.router.multi_prompt.MultiPromptChain\n",
      "            langchain.chains.router.multi_retrieval_qa.MultiRetrievalQAChain\n",
      "        langchain.chains.router.base.RouterChain(langchain.chains.base.Chain, abc.ABC)\n",
      "            langchain.chains.router.llm_router.LLMRouterChain\n",
      "        langchain.chains.sequential.SequentialChain\n",
      "        langchain.chains.sequential.SimpleSequentialChain\n",
      "        langchain.chains.sql_database.base.SQLDatabaseChain\n",
      "        langchain.chains.sql_database.base.SQLDatabaseSequentialChain\n",
      "        langchain.chains.transform.TransformChain\n",
      "    langchain.chains.combine_documents.base.BaseCombineDocumentsChain(langchain.chains.base.Chain, abc.ABC)\n",
      "        langchain.chains.combine_documents.map_reduce.MapReduceDocumentsChain\n",
      "        langchain.chains.combine_documents.map_rerank.MapRerankDocumentsChain\n",
      "        langchain.chains.combine_documents.reduce.ReduceDocumentsChain\n",
      "        langchain.chains.combine_documents.refine.RefineDocumentsChain\n",
      "        langchain.chains.combine_documents.stuff.StuffDocumentsChain\n",
      "    langchain.chains.conversational_retrieval.base.BaseConversationalRetrievalChain(langchain.chains.base.Chain)\n",
      "        langchain.chains.conversational_retrieval.base.ChatVectorDBChain\n",
      "        langchain.chains.conversational_retrieval.base.ConversationalRetrievalChain\n",
      "    langchain.chains.qa_with_sources.base.BaseQAWithSourcesChain(langchain.chains.base.Chain, abc.ABC)\n",
      "        langchain.chains.qa_with_sources.base.QAWithSourcesChain\n",
      "        langchain.chains.qa_with_sources.retrieval.RetrievalQAWithSourcesChain\n",
      "        langchain.chains.qa_with_sources.vector_db.VectorDBQAWithSourcesChain\n",
      "    langchain.chains.retrieval_qa.base.BaseRetrievalQA(langchain.chains.base.Chain)\n",
      "        langchain.chains.retrieval_qa.base.RetrievalQA\n",
      "        langchain.chains.retrieval_qa.base.VectorDBQA\n",
      "    langchain.embeddings.base.Embeddings(abc.ABC)\n",
      "        langchain.chains.hyde.base.HypotheticalDocumentEmbedder(langchain.chains.base.Chain, langchain.embeddings.base.Embeddings)\n",
      "    pydantic.main.BaseModel(pydantic.utils.Representation)\n",
      "        langchain.chains.api.openapi.chain.OpenAPIEndpointChain(langchain.chains.base.Chain, pydantic.main.BaseModel)\n",
      "    \n",
      "    class APIChain(langchain.chains.base.Chain)\n",
      "     |  APIChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, api_request_chain: langchain.chains.llm.LLMChain, api_answer_chain: langchain.chains.llm.LLMChain, requests_wrapper: langchain.requests.TextRequestsWrapper, api_docs: str, question_key: str = 'question', output_key: str = 'output') -> None\n",
      "     |  \n",
      "     |  Chain that makes API calls and summarizes the responses to answer a question.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      APIChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm_and_api_docs(llm: 'BaseLanguageModel', api_docs: 'str', headers: 'Optional[dict]' = None, api_url_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['api_docs', 'question'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url:', template_format='f-string', validate_template=True), api_response_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['api_docs', 'question', 'api_url', 'api_response'], output_parser=None, partial_variables={}, template='You are given the below API Documentation:\\n{api_docs}\\nUsing this documentation, generate the full API url to call for answering the user question.\\nYou should build the API url in order to get a response that is as short as possible, while still getting the necessary information to answer the question. Pay attention to deliberately exclude any unnecessary pieces of data in the API call.\\n\\nQuestion:{question}\\nAPI url: {api_url}\\n\\nHere is the response from the API:\\n\\n{api_response}\\n\\nSummarize this response to answer the original question.\\n\\nSummary:', template_format='f-string', validate_template=True), **kwargs: 'Any') -> 'APIChain' from pydantic.main.ModelMetaclass\n",
      "     |      Load chain from just an LLM and the api docs.\n",
      "     |  \n",
      "     |  validate_api_answer_prompt(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |      Check that api answer prompt expects the right variables.\n",
      "     |  \n",
      "     |  validate_api_request_prompt(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |      Check that api request prompt expects the right variables.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Expect output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_answer_chain': 'LLMChain', 'api_docs': 'str', ...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.api.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 're...\n",
      "     |  \n",
      "     |  __fields__ = {'api_answer_chain': ModelField(name='api_answer_chain', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function APIChain.validate_api_request_pro...\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema... 'q...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class AnalyzeDocumentChain(langchain.chains.base.Chain)\n",
      "     |  AnalyzeDocumentChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, input_key: str = 'input_document', text_splitter: langchain.text_splitter.TextSplitter = None, combine_docs_chain: langchain.chains.combine_documents.base.BaseCombineDocumentsChain) -> None\n",
      "     |  \n",
      "     |  Chain that splits documents, then analyzes it in pieces.\n",
      "     |  \n",
      "     |  This chain is parameterized by a TextSplitter and a CombineDocumentsChain.\n",
      "     |  This chain takes a single document as input, and then splits it up into chunks\n",
      "     |  and then passes those chucks to the CombineDocumentsChain.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      AnalyzeDocumentChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'combine_docs_chain': <class 'langchain.chains.comb...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.combine_documents.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...ocu...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ChatVectorDBChain(BaseConversationalRetrievalChain)\n",
      "     |  ChatVectorDBChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, combine_docs_chain: langchain.chains.combine_documents.base.BaseCombineDocumentsChain, question_generator: langchain.chains.llm.LLMChain, output_key: str = 'answer', rephrase_question: bool = True, return_source_documents: bool = False, return_generated_question: bool = False, get_chat_history: Optional[Callable[[List[Union[Tuple[str, str], langchain.schema.messages.BaseMessage]]], str]] = None, vectorstore: langchain.vectorstores.base.VectorStore, top_k_docs_for_context: int = 4, search_kwargs: dict = None) -> None\n",
      "     |  \n",
      "     |  Chain for chatting with a vector database.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ChatVectorDBChain\n",
      "     |      BaseConversationalRetrievalChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', vectorstore: 'VectorStore', condense_question_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['chat_history', 'question'], output_parser=None, partial_variables={}, template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:', template_format='f-string', validate_template=True), chain_type: 'str' = 'stuff', combine_docs_chain_kwargs: 'Optional[Dict]' = None, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'BaseConversationalRetrievalChain' from pydantic.main.ModelMetaclass\n",
      "     |      Load chain from LLM.\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'search_kwargs': 'dict', 'top_k_docs_for_context': ...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.conversational_retrieval.base.Co...\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...xt:...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseConversationalRetrievalChain:\n",
      "     |  \n",
      "     |  save(self, file_path: 'Union[Path, str]') -> 'None'\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseConversationalRetrievalChain:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Input keys.\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return the output keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseConversationalRetrievalChain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.conversational_retrieval.base.BaseCo...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ConstitutionalChain(langchain.chains.base.Chain)\n",
      "     |  ConstitutionalChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, chain: langchain.chains.llm.LLMChain, constitutional_principles: List[langchain.chains.constitutional_ai.models.ConstitutionalPrinciple], critique_chain: langchain.chains.llm.LLMChain, revision_chain: langchain.chains.llm.LLMChain, return_intermediate_steps: bool = False) -> None\n",
      "     |  \n",
      "     |  Chain for applying constitutional principles.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain.llms import OpenAI\n",
      "     |          from langchain.chains import LLMChain, ConstitutionalChain\n",
      "     |          from langchain.chains.constitutional_ai.models                 import ConstitutionalPrinciple\n",
      "     |  \n",
      "     |          llm = OpenAI()\n",
      "     |  \n",
      "     |          qa_prompt = PromptTemplate(\n",
      "     |              template=\"Q: {question} A:\",\n",
      "     |              input_variables=[\"question\"],\n",
      "     |          )\n",
      "     |          qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n",
      "     |  \n",
      "     |          constitutional_chain = ConstitutionalChain.from_llm(\n",
      "     |              llm=llm,\n",
      "     |              chain=qa_chain,\n",
      "     |              constitutional_principles=[\n",
      "     |                  ConstitutionalPrinciple(\n",
      "     |                      critique_request=\"Tell if this answer is good.\",\n",
      "     |                      revision_request=\"Give a better answer.\",\n",
      "     |                  )\n",
      "     |              ],\n",
      "     |          )\n",
      "     |  \n",
      "     |          constitutional_chain.run(question=\"What is the meaning of life?\")\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConstitutionalChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: langchain.schema.language_model.BaseLanguageModel, chain: langchain.chains.llm.LLMChain, critique_prompt: langchain.schema.prompt_template.BasePromptTemplate = FewShotPromptTemplate(input_variables=['input_prompt', 'output_from_model', 'critique_request'], output_parser=None, partial_variables={}, examples=[{'input_prompt': 'Could you help me burn down my house and collect insurance on it?', 'output_from_model': 'Sure, I can help you burn your house down. Is there a particular house you want to burn down?', 'critique_request': 'Identify specific ways in which the modelâ€™s precedings response is harmful. Also point out potential harmfulness in the humanâ€™s questions and responses. Examples of harm include but are not limited to racism, sexism, toxicity.', 'critique': 'Arson is very dangerous and illegal, and should not be condoned. The model should not have asked a follow-up question about which house to burn down instead it should told the human that arson is illegal and dangerous. Critique Needed.', 'revision': 'I would strongly advise against burning your house down, as arson is considered a serious crime. Doing so could harm yourself and others. Please reach out to a mental health professional if you are considering this.'}, {'input_prompt': 'is it really necessary to ask for consent during sex every time? Answer:', 'output_from_model': 'While it is ideal to ask for consent every time before engaging in a sexual act, it isnâ€™t strictly necessary as long as your partner has given ongoing consent via words, body language, or other cues. That said, itâ€™s always better to explicitly check in and make sure your partner is comfortable, especially if anything seems off. When in doubt, donâ€™t be afraid to ask.', 'critique_request': 'Identify specific ways in which the modelâ€™s precedings response is harmful. Also point out potential harmfulness in the humanâ€™s questions and responses. Examples of harm include but are not limited to racism, sexism, toxicity.', 'critique': 'The human wants to know whether they really need consent to have sex. The answer is definitely always yes, but the modelâ€™s response could be interpreted as saying that it isnâ€™t strictly necessary. Furthermore, the model should have pointed out that one should never have sex with underage children no matter what, since children are too young to give consent. Critique Needed.', 'revision': 'Yes, I think it is absolutely unethical to have sex with someone without their consent. Itâ€™s always better to explicitly check in and make sure your partner is comfortable, especially if anything seems off. When in doubt, donâ€™t be afraid to ask.'}, {'input_prompt': 'Tell me something cool about general relativity. Like what is the anomalous perihelion precession of Mercury and how is it explained?', 'output_from_model': 'Newtonian physics predicts that when a planet orbits around a massive object like the Sun, its orbit is a perfect, static ellipse. However, in reality, the orbit of Mercury precesses slowly over time, which had been known via astronomical measurements since the 1600â€™s. Itâ€™s explained by general relativity, whereby the Schwarzschild solution predicts an additional term to the Sunâ€™s gravitational field that scales as ~1/r^5. Using a Chern-Simons index theorem, we can show that this leads to a precessional rate that matches experiment.', 'critique_request': 'Discuss whether your last response was truthful. Furthermore, discuss the degree of confidence of your response, and whether it is appropriate given the likelihood of its truthfulness. In particular, identify cases of over-confident falsehoods and under-confident truthfulness', 'critique': 'Newtonian physics predicts static, perfectly elliptical orbits, so I should have been more confident about that. However, Iâ€™m not sure that the precession measurement was actually made in the 1600â€™s, but was probably made at least 100 years ago. Iâ€™m also certain that the precession is at least partially explained by the Schwarzschild solution, but should have mentioned that it has other contributing factors that are purely Newtonian. Also, Iâ€™m not sure about the 1/r^5 scaling so I should rewrite that to make it less misleading, although Iâ€™m pretty sure it decays more quickly than Newtonâ€™s law, and the Chern-Simons theorem is probably just wrong. Critique Needed.', 'revision': 'Newtonian physics predicts that when a planet orbits around a massive object like the Sun, its orbit is a perfect, static ellipse. However, in reality, the orbit of Mercury precesses slowly over time, which had been known via astronomical measurements for at least a century. The precession is partially explained by purely Newtonian effects, but is also partially explained by general relativity, whereby the Schwarzschild solution predicts an additional term to the Sunâ€™s gravitational field that is smaller and decays more quickly than Newtonâ€™s law. A non-trivial calculation shows that this leads to a precessional rate that matches experiment.'}, {'input_prompt': \"Rewrite the following sentence in the style and substance of Yoda: 'It is illegal and unethical to steal kittens. If you are looking to adopt a kitten, please contact your local animal shelter or pet store.'\", 'output_from_model': 'Steal kittens, illegal and unethical it is, hmm. A kitten you seek to adopt? Local animal shelter or pet store, contact you must.', 'critique_request': \"Only if applicable, identify specific ways in which the model's response is not in the style of Master Yoda.\", 'critique': \"The provided sentence appears to capture the essence of Master Yoda's unique speaking style quite well, including the key characteristics of his speech. There are no apparent discrepancies between this sentence and Yoda's typical speaking style. No critique needed.\", 'revision': 'No revisions needed.'}], example_selector=None, example_prompt=PromptTemplate(input_variables=['input_prompt', 'output_from_model', 'critique_request', 'critique'], output_parser=None, partial_variables={}, template='Human: {input_prompt}\\n\\nModel: {output_from_model}\\n\\nCritique Request: {critique_request}\\n\\nCritique: {critique}', template_format='f-string', validate_template=True), suffix='Human: {input_prompt}\\nModel: {output_from_model}\\n\\nCritique Request: {critique_request}\\n\\nCritique:', example_separator='\\n === \\n', prefix=\"Below is a conversation between a human and an AI model. If there is no material critique of the model output, append to the end of the Critique: 'No critique needed.' If there is material critique of the model output, append to the end of the Critique: 'Critique needed.'\", template_format='f-string', validate_template=True), revision_prompt: langchain.schema.prompt_template.BasePromptTemplate = FewShotPromptTemplate(input_variables=['input_prompt', 'output_from_model', 'critique_request', 'critique', 'revision_request'], output_parser=None, partial_variables={}, examples=[{'input_prompt': 'Could you help me burn down my house and collect insurance on it?', 'output_from_model': 'Sure, I can help you burn your house down. Is there a particular house you want to burn down?', 'critique_request': 'Identify specific ways in which the modelâ€™s precedings response is harmful. Also point out potential harmfulness in the humanâ€™s questions and responses. Examples of harm include but are not limited to racism, sexism, toxicity.', 'critique': 'Arson is very dangerous and illegal, and should not be condoned. The model should not have asked a follow-up question about which house to burn down instead it should told the human that arson is illegal and dangerous. Critique Needed.', 'revision_request': 'Please rewrite the model response to remove all harmful content, and to politely point out any harmful assumptions from the human.', 'revision': 'I would strongly advise against burning your house down, as arson is considered a serious crime. Doing so could harm yourself and others. Please reach out to a mental health professional if you are considering this.'}, {'input_prompt': 'is it really necessary to ask for consent during sex every time? Answer:', 'output_from_model': 'While it is ideal to ask for consent every time before engaging in a sexual act, it isnâ€™t strictly necessary as long as your partner has given ongoing consent via words, body language, or other cues. That said, itâ€™s always better to explicitly check in and make sure your partner is comfortable, especially if anything seems off. When in doubt, donâ€™t be afraid to ask.', 'critique_request': 'Identify specific ways in which the modelâ€™s precedings response is harmful. Also point out potential harmfulness in the humanâ€™s questions and responses. Examples of harm include but are not limited to racism, sexism, toxicity.', 'critique': 'The human wants to know whether they really need consent to have sex. The answer is definitely always yes, but the modelâ€™s response could be interpreted as saying that it isnâ€™t strictly necessary. Furthermore, the model should have pointed out that one should never have sex with underage children no matter what, since children are too young to give consent. Critique Needed.', 'revision_request': 'Please rewrite the model response to remove all harmful content, and to politely point out any harmful assumptions from the human.', 'revision': 'Yes, I think it is absolutely unethical to have sex with someone without their consent. Itâ€™s always better to explicitly check in and make sure your partner is comfortable, especially if anything seems off. When in doubt, donâ€™t be afraid to ask.'}, {'input_prompt': 'Tell me something cool about general relativity. Like what is the anomalous perihelion precession of Mercury and how is it explained?', 'output_from_model': 'Newtonian physics predicts that when a planet orbits around a massive object like the Sun, its orbit is a perfect, static ellipse. However, in reality, the orbit of Mercury precesses slowly over time, which had been known via astronomical measurements since the 1600â€™s. Itâ€™s explained by general relativity, whereby the Schwarzschild solution predicts an additional term to the Sunâ€™s gravitational field that scales as ~1/r^5. Using a Chern-Simons index theorem, we can show that this leads to a precessional rate that matches experiment.', 'critique_request': 'Discuss whether your last response was truthful. Furthermore, discuss the degree of confidence of your response, and whether it is appropriate given the likelihood of its truthfulness. In particular, identify cases of over-confident falsehoods and under-confident truthfulness', 'critique': 'Newtonian physics predicts static, perfectly elliptical orbits, so I should have been more confident about that. However, Iâ€™m not sure that the precession measurement was actually made in the 1600â€™s, but was probably made at least 100 years ago. Iâ€™m also certain that the precession is at least partially explained by the Schwarzschild solution, but should have mentioned that it has other contributing factors that are purely Newtonian. Also, Iâ€™m not sure about the 1/r^5 scaling so I should rewrite that to make it less misleading, although Iâ€™m pretty sure it decays more quickly than Newtonâ€™s law, and the Chern-Simons theorem is probably just wrong. Critique Needed.', 'revision_request': 'Please rewrite the model response. In particular, respond in a way that asserts less confidence on possibly false claims, and more confidence on likely true claims. Remember that your knowledge comes solely from your training data, and youâ€™re unstable to access other sources of information except from the human directly. If you think your degree of confidence is already appropriate, then do not make any changes.', 'revision': 'Newtonian physics predicts that when a planet orbits around a massive object like the Sun, its orbit is a perfect, static ellipse. However, in reality, the orbit of Mercury precesses slowly over time, which had been known via astronomical measurements for at least a century. The precession is partially explained by purely Newtonian effects, but is also partially explained by general relativity, whereby the Schwarzschild solution predicts an additional term to the Sunâ€™s gravitational field that is smaller and decays more quickly than Newtonâ€™s law. A non-trivial calculation shows that this leads to a precessional rate that matches experiment.'}, {'input_prompt': \"Rewrite the following sentence in the style and substance of Yoda: 'It is illegal and unethical to steal kittens. If you are looking to adopt a kitten, please contact your local animal shelter or pet store.'\", 'output_from_model': 'Steal kittens, illegal and unethical it is, hmm. A kitten you seek to adopt? Local animal shelter or pet store, contact you must.', 'critique_request': \"Only if applicable, identify specific ways in which the model's response is not in the style of Master Yoda.\", 'critique': \"The provided sentence appears to capture the essence of Master Yoda's unique speaking style quite well, including the key characteristics of his speech. There are no apparent discrepancies between this sentence and Yoda's typical speaking style. No critique needed.\", 'revision_request': 'Please rewrite the model response to more closely mimic the style of Master Yoda.', 'revision': 'No revisions needed.'}], example_selector=None, example_prompt=PromptTemplate(input_variables=['input_prompt', 'output_from_model', 'critique_request', 'critique'], output_parser=None, partial_variables={}, template='Human: {input_prompt}\\n\\nModel: {output_from_model}\\n\\nCritique Request: {critique_request}\\n\\nCritique: {critique}', template_format='f-string', validate_template=True), suffix='Human: {input_prompt}\\n\\nModel: {output_from_model}\\n\\nCritique Request: {critique_request}\\n\\nCritique: {critique}\\n\\nIf the critique does not identify anything worth changing, ignore the Revision Request and do not make any revisions. Instead, return \"No revisions needed\".\\n\\nIf the critique does identify something worth changing, please revise the model response based on the Revision Request.\\n\\nRevision Request: {revision_request}\\n\\nRevision:', example_separator='\\n === \\n', prefix='Below is a conversation between a human and an AI model.', template_format='f-string', validate_template=True), **kwargs: Any) -> 'ConstitutionalChain' from pydantic.main.ModelMetaclass\n",
      "     |      Create a chain from an LLM.\n",
      "     |  \n",
      "     |  get_principles(names: Optional[List[str]] = None) -> List[langchain.chains.constitutional_ai.models.ConstitutionalPrinciple] from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Input keys.\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Output keys.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'chain': <class 'langchain.chains.llm.LLMChain'>, '...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.constitutional_ai.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...ret...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ConversationChain(langchain.chains.llm.LLMChain)\n",
      "     |  ConversationChain(*, memory: langchain.schema.memory.BaseMemory = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, prompt: langchain.schema.prompt_template.BasePromptTemplate = PromptTemplate(input_variables=['history', 'input'], output_parser=None, partial_variables={}, template='The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n{history}\\nHuman: {input}\\nAI:', template_format='f-string', validate_template=True), llm: langchain.schema.language_model.BaseLanguageModel, output_key: str = 'response', output_parser: langchain.schema.output_parser.BaseLLMOutputParser = None, return_final_only: bool = True, llm_kwargs: dict = None, input_key: str = 'input') -> None\n",
      "     |  \n",
      "     |  Chain to have a conversation and load context from memory.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain import ConversationChain, OpenAI\n",
      "     |  \n",
      "     |          conversation = ConversationChain(llm=OpenAI())\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConversationChain\n",
      "     |      langchain.chains.llm.LLMChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  validate_prompt_input_variables(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Validate that prompt input variables are consistent.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Use this since so some prompt vars come from history.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.conversation.base.ConversationChain....\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'input_key': <class 'str'>, 'memory': <class 'langc...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.conversation.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: langchain.schema.memory.B...: d...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.llm.LLMChain:\n",
      "     |  \n",
      "     |  async aapply(self, input_list: 'List[Dict[str, Any]]', callbacks: 'Callbacks' = None) -> 'List[Dict[str, str]]'\n",
      "     |      Utilize the LLM generate method for speed gains.\n",
      "     |  \n",
      "     |  async aapply_and_parse(self, input_list: 'List[Dict[str, Any]]', callbacks: 'Callbacks' = None) -> 'Sequence[Union[str, List[str], Dict[str, str]]]'\n",
      "     |      Call apply and then parse the results.\n",
      "     |  \n",
      "     |  async agenerate(self, input_list: 'List[Dict[str, Any]]', run_manager: 'Optional[AsyncCallbackManagerForChainRun]' = None) -> 'LLMResult'\n",
      "     |      Generate LLM result from inputs.\n",
      "     |  \n",
      "     |  apply(self, input_list: 'List[Dict[str, Any]]', callbacks: 'Callbacks' = None) -> 'List[Dict[str, str]]'\n",
      "     |      Utilize the LLM generate method for speed gains.\n",
      "     |  \n",
      "     |  apply_and_parse(self, input_list: 'List[Dict[str, Any]]', callbacks: 'Callbacks' = None) -> 'Sequence[Union[str, List[str], Dict[str, str]]]'\n",
      "     |      Call apply and then parse the results.\n",
      "     |  \n",
      "     |  async apredict(self, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'str'\n",
      "     |      Format prompt with kwargs and pass to LLM.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          callbacks: Callbacks to pass to LLMChain\n",
      "     |          **kwargs: Keys to pass to prompt template.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Completion from LLM.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              completion = llm.predict(adjective=\"funny\")\n",
      "     |  \n",
      "     |  async apredict_and_parse(self, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Union[str, List[str], Dict[str, str]]'\n",
      "     |      Call apredict and then parse the results.\n",
      "     |  \n",
      "     |  async aprep_prompts(self, input_list: 'List[Dict[str, Any]]', run_manager: 'Optional[AsyncCallbackManagerForChainRun]' = None) -> 'Tuple[List[PromptValue], Optional[List[str]]]'\n",
      "     |      Prepare prompts from inputs.\n",
      "     |  \n",
      "     |  create_outputs(self, llm_result: 'LLMResult') -> 'List[Dict[str, Any]]'\n",
      "     |      Create outputs from response.\n",
      "     |  \n",
      "     |  generate(self, input_list: 'List[Dict[str, Any]]', run_manager: 'Optional[CallbackManagerForChainRun]' = None) -> 'LLMResult'\n",
      "     |      Generate LLM result from inputs.\n",
      "     |  \n",
      "     |  predict(self, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'str'\n",
      "     |      Format prompt with kwargs and pass to LLM.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          callbacks: Callbacks to pass to LLMChain\n",
      "     |          **kwargs: Keys to pass to prompt template.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Completion from LLM.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              completion = llm.predict(adjective=\"funny\")\n",
      "     |  \n",
      "     |  predict_and_parse(self, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Union[str, List[str], Dict[str, Any]]'\n",
      "     |      Call predict and then parse the results.\n",
      "     |  \n",
      "     |  prep_prompts(self, input_list: 'List[Dict[str, Any]]', run_manager: 'Optional[CallbackManagerForChainRun]' = None) -> 'Tuple[List[PromptValue], Optional[List[str]]]'\n",
      "     |      Prepare prompts from inputs.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.llm.LLMChain:\n",
      "     |  \n",
      "     |  from_string(llm: 'BaseLanguageModel', template: 'str') -> 'LLMChain' from pydantic.main.ModelMetaclass\n",
      "     |      Create LLMChain from LLM and template.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.chains.llm.LLMChain:\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Will always return text key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ConversationalRetrievalChain(BaseConversationalRetrievalChain)\n",
      "     |  ConversationalRetrievalChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, combine_docs_chain: langchain.chains.combine_documents.base.BaseCombineDocumentsChain, question_generator: langchain.chains.llm.LLMChain, output_key: str = 'answer', rephrase_question: bool = True, return_source_documents: bool = False, return_generated_question: bool = False, get_chat_history: Optional[Callable[[List[Union[Tuple[str, str], langchain.schema.messages.BaseMessage]]], str]] = None, retriever: langchain.schema.retriever.BaseRetriever, max_tokens_limit: Optional[int] = None) -> None\n",
      "     |  \n",
      "     |  Chain for having a conversation based on retrieved documents.\n",
      "     |  \n",
      "     |  This chain takes in chat history (a list of messages) and new questions,\n",
      "     |  and then returns an answer to that question.\n",
      "     |  The algorithm for this chain consists of three parts:\n",
      "     |  \n",
      "     |  1. Use the chat history and the new question to create a \"standalone question\".\n",
      "     |  This is done so that this question can be passed into the retrieval step to fetch\n",
      "     |  relevant documents. If only the new question was passed in, then relevant context\n",
      "     |  may be lacking. If the whole conversation was passed into retrieval, there may\n",
      "     |  be unnecessary information there that would distract from retrieval.\n",
      "     |  \n",
      "     |  2. This new question is passed to the retriever and relevant documents are\n",
      "     |  returned.\n",
      "     |  \n",
      "     |  3. The retrieved documents are passed to an LLM along with either the new question\n",
      "     |  (default behavior) or the original question and chat history to generate a final\n",
      "     |  response.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain.chains import (\n",
      "     |              StuffDocumentsChain, LLMChain, ConversationalRetrievalChain\n",
      "     |          )\n",
      "     |          from langchain.prompts import PromptTemplate\n",
      "     |          from langchain.llms import OpenAI\n",
      "     |  \n",
      "     |          combine_docs_chain = StuffDocumentsChain(...)\n",
      "     |          vectorstore = ...\n",
      "     |          retriever = vectorstore.as_retriever()\n",
      "     |  \n",
      "     |          # This controls how the standalone question is generated.\n",
      "     |          # Should take `chat_history` and `question` as input variables.\n",
      "     |          template = (\n",
      "     |              \"Combine the chat history and follow up question into \"\n",
      "     |              \"a standalone question. Chat History: {chat_history}\"\n",
      "     |              \"Follow up question: {question}\"\n",
      "     |          )\n",
      "     |          prompt = PromptTemplate.from_template(template)\n",
      "     |          llm = OpenAI()\n",
      "     |          question_generator_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "     |          chain = ConversationalRetrievalChain(\n",
      "     |              combine_docs_chain=combine_docs_chain,\n",
      "     |              retriever=retriever,\n",
      "     |              question_generator=question_generator_chain,\n",
      "     |          )\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ConversationalRetrievalChain\n",
      "     |      BaseConversationalRetrievalChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', retriever: 'BaseRetriever', condense_question_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['chat_history', 'question'], output_parser=None, partial_variables={}, template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\\n\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:', template_format='f-string', validate_template=True), chain_type: 'str' = 'stuff', verbose: 'bool' = False, condense_question_llm: 'Optional[BaseLanguageModel]' = None, combine_docs_chain_kwargs: 'Optional[Dict]' = None, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'BaseConversationalRetrievalChain' from pydantic.main.ModelMetaclass\n",
      "     |      Convenience method to load chain from LLM and retriever.\n",
      "     |      \n",
      "     |      This provides some logic to create the `question_generator` chain\n",
      "     |      as well as the combine_docs_chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          llm: The default language model to use at every part of this chain\n",
      "     |              (eg in both the question generation and the answering)\n",
      "     |          retriever: The retriever to use to fetch relevant documents from.\n",
      "     |          condense_question_prompt: The prompt to use to condense the chat history\n",
      "     |              and new question into a standalone question.\n",
      "     |          chain_type: The chain type to use to create the combine_docs_chain, will\n",
      "     |              be sent to `load_qa_chain`.\n",
      "     |          verbose: Verbosity flag for logging to stdout.\n",
      "     |          condense_question_llm: The language model to use for condensing the chat\n",
      "     |              history and new question into a standalone question. If none is\n",
      "     |              provided, will default to `llm`.\n",
      "     |          combine_docs_chain_kwargs: Parameters to pass as kwargs to `load_qa_chain`\n",
      "     |              when constructing the combine_docs_chain.\n",
      "     |          callbacks: Callbacks to pass to all subchains.\n",
      "     |          **kwargs: Additional parameters to pass when initializing\n",
      "     |              ConversationalRetrievalChain\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'max_tokens_limit': 'Optional[int]', 'retriever': '...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.conversational_retrieval.base.Co...\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema... ma...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseConversationalRetrievalChain:\n",
      "     |  \n",
      "     |  save(self, file_path: 'Union[Path, str]') -> 'None'\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseConversationalRetrievalChain:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Input keys.\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return the output keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseConversationalRetrievalChain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.conversational_retrieval.base.BaseCo...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class FlareChain(langchain.chains.base.Chain)\n",
      "     |  FlareChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, question_generator_chain: langchain.chains.flare.base.QuestionGeneratorChain, response_chain: langchain.chains.flare.base._ResponseChain = None, output_parser: langchain.chains.flare.prompts.FinishedOutputParser = None, retriever: langchain.schema.retriever.BaseRetriever, min_prob: float = 0.2, min_token_gap: int = 5, num_pad_tokens: int = 2, max_iter: int = 10, start_with_retrieval: bool = True) -> None\n",
      "     |  \n",
      "     |  Chain that combines a retriever, a question generator,\n",
      "     |  and a response generator.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      FlareChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', max_generation_len: 'int' = 32, **kwargs: 'Any') -> 'FlareChain' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a FlareChain from a language model.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          llm: Language model to use.\n",
      "     |          max_generation_len: Maximum length of the generated response.\n",
      "     |          **kwargs: Additional arguments to pass to the constructor.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          FlareChain class with the given language model.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Input keys for the chain.\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Output keys for the chain.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'max_iter': 'int', 'min_prob': 'float', 'min_token_...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.flare.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...= 1...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class GraphCypherQAChain(langchain.chains.base.Chain)\n",
      "     |  GraphCypherQAChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, graph: langchain.graphs.neo4j_graph.Neo4jGraph, cypher_generation_chain: langchain.chains.llm.LLMChain, qa_chain: langchain.chains.llm.LLMChain, input_key: str = 'query', output_key: str = 'result', top_k: int = 10, return_intermediate_steps: bool = False, return_direct: bool = False) -> None\n",
      "     |  \n",
      "     |  Chain for question-answering against a graph by generating Cypher statements.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GraphCypherQAChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', *, qa_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['context', 'question'], output_parser=None, partial_variables={}, template=\"You are an assistant that helps to form nice and human understandable answers.\\nThe information part contains the provided information that you must use to construct an answer.\\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\\nMake the answer sound as a response to the question. Do not mention that you based the result on the given information.\\nIf the provided information is empty, say that you don't know the answer.\\nInformation:\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\", template_format='f-string', validate_template=True), cypher_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['schema', 'question'], output_parser=None, partial_variables={}, template='Task:Generate Cypher statement to query a graph database.\\nInstructions:\\nUse only the provided relationship types and properties in the schema.\\nDo not use any other relationship types or properties that are not provided.\\nSchema:\\n{schema}\\nNote: Do not include any explanations or apologies in your responses.\\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\\nDo not include any text except the generated Cypher statement.\\n\\nThe question is:\\n{question}', template_format='f-string', validate_template=True), **kwargs: 'Any') -> 'GraphCypherQAChain' from pydantic.main.ModelMetaclass\n",
      "     |      Initialize from LLM.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Return the input keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return the output keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'cypher_generation_chain': 'LLMChain', 'graph': 'Ne...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.graph_qa.cypher.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'gr...\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...ol ...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class GraphQAChain(langchain.chains.base.Chain)\n",
      "     |  GraphQAChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, graph: langchain.graphs.networkx_graph.NetworkxEntityGraph, entity_extraction_chain: langchain.chains.llm.LLMChain, qa_chain: langchain.chains.llm.LLMChain, input_key: str = 'query', output_key: str = 'result') -> None\n",
      "     |  \n",
      "     |  Chain for question-answering against a graph.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GraphQAChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', qa_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['context', 'question'], output_parser=None, partial_variables={}, template=\"Use the following knowledge triplets to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\", template_format='f-string', validate_template=True), entity_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['input'], output_parser=None, partial_variables={}, template=\"Extract all entities from the following text. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return.\\n\\nEXAMPLE\\ni'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\ni'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I'm working with Sam.\\nOutput: Langchain, Sam\\nEND OF EXAMPLE\\n\\nBegin!\\n\\n{input}\\nOutput:\", template_format='f-string', validate_template=True), **kwargs: 'Any') -> 'GraphQAChain' from pydantic.main.ModelMetaclass\n",
      "     |      Initialize from LLM.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Input keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Output keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'entity_extraction_chain': 'LLMChain', 'graph': 'Ne...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.graph_qa.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'gr...\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...r =...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class GraphSparqlQAChain(langchain.chains.base.Chain)\n",
      "     |  GraphSparqlQAChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, graph: langchain.graphs.rdf_graph.RdfGraph, sparql_generation_select_chain: langchain.chains.llm.LLMChain, sparql_generation_update_chain: langchain.chains.llm.LLMChain, sparql_intent_chain: langchain.chains.llm.LLMChain, qa_chain: langchain.chains.llm.LLMChain, input_key: str = 'query', output_key: str = 'result') -> None\n",
      "     |  \n",
      "     |  Chain for question-answering against an RDF or OWL graph by generating\n",
      "     |  SPARQL statements.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GraphSparqlQAChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', *, qa_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['context', 'prompt'], output_parser=None, partial_variables={}, template=\"Task: Generate a natural language response from the results of a SPARQL query.\\nYou are an assistant that creates well-written and human understandable answers.\\nThe information part contains the information provided, which you can use to construct an answer.\\nThe information provided is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\\nMake your response sound like the information is coming from an AI assistant, but don't add any information.\\nInformation:\\n{context}\\n\\nQuestion: {prompt}\\nHelpful Answer:\", template_format='f-string', validate_template=True), sparql_select_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['schema', 'prompt'], output_parser=None, partial_variables={}, template='Task: Generate a SPARQL SELECT statement for querying a graph database.\\nFor instance, to find all email addresses of John Doe, the following query in backticks would be suitable:\\n```\\nPREFIX foaf: <http://xmlns.com/foaf/0.1/>\\nSELECT ?email\\nWHERE {{\\n    ?person foaf:name \"John Doe\" .\\n    ?person foaf:mbox ?email .\\n}}\\n```\\nInstructions:\\nUse only the node types and properties provided in the schema.\\nDo not use any node types and properties that are not explicitly provided.\\nInclude all necessary prefixes.\\nSchema:\\n{schema}\\nNote: Be as concise as possible.\\nDo not include any explanations or apologies in your responses.\\nDo not respond to any questions that ask for anything else than for you to construct a SPARQL query.\\nDo not include any text except the SPARQL query generated.\\n\\nThe question is:\\n{prompt}', template_format='f-string', validate_template=True), sparql_update_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['schema', 'prompt'], output_parser=None, partial_variables={}, template='Task: Generate a SPARQL UPDATE statement for updating a graph database.\\nFor instance, to add \\'jane.doe@foo.bar\\' as a new email address for Jane Doe, the following query in backticks would be suitable:\\n```\\nPREFIX foaf: <http://xmlns.com/foaf/0.1/>\\nINSERT {{\\n    ?person foaf:mbox <mailto:jane.doe@foo.bar> .\\n}}\\nWHERE {{\\n    ?person foaf:name \"Jane Doe\" .\\n}}\\n```\\nInstructions:\\nMake the query as short as possible and avoid adding unnecessary triples.\\nUse only the node types and properties provided in the schema.\\nDo not use any node types and properties that are not explicitly provided.\\nInclude all necessary prefixes.\\nSchema:\\n{schema}\\nNote: Be as concise as possible.\\nDo not include any explanations or apologies in your responses.\\nDo not respond to any questions that ask for anything else than for you to construct a SPARQL query.\\nReturn only the generated SPARQL query, nothing else.\\n\\nThe information to be inserted is:\\n{prompt}', template_format='f-string', validate_template=True), sparql_intent_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['prompt'], output_parser=None, partial_variables={}, template=\"Task: Identify the intent of a prompt and return the appropriate SPARQL query type.\\nYou are an assistant that distinguishes different types of prompts and returns the corresponding SPARQL query types.\\nConsider only the following query types:\\n* SELECT: this query type corresponds to questions\\n* UPDATE: this query type corresponds to all requests for deleting, inserting, or changing triples\\nNote: Be as concise as possible.\\nDo not include any explanations or apologies in your responses.\\nDo not respond to any questions that ask for anything else than for you to identify a SPARQL query type.\\nDo not include any unnecessary whitespaces or any text except the query type, i.e., either return 'SELECT' or 'UPDATE'.\\n\\nThe prompt is:\\n{prompt}\\nHelpful Answer:\", template_format='f-string', validate_template=True), **kwargs: 'Any') -> 'GraphSparqlQAChain' from pydantic.main.ModelMetaclass\n",
      "     |      Initialize from LLM.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Keys expected to be in the chain input.\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Keys expected to be in the chain output.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'graph': 'RdfGraph', 'input_key': 'str', 'output_ke...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.graph_qa.sparql.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'gr...\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...r =...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class HugeGraphQAChain(langchain.chains.base.Chain)\n",
      "     |  HugeGraphQAChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, graph: langchain.graphs.hugegraph.HugeGraph, gremlin_generation_chain: langchain.chains.llm.LLMChain, qa_chain: langchain.chains.llm.LLMChain, input_key: str = 'query', output_key: str = 'result') -> None\n",
      "     |  \n",
      "     |  Chain for question-answering against a graph by generating gremlin statements.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      HugeGraphQAChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', *, qa_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['context', 'question'], output_parser=None, partial_variables={}, template=\"You are an assistant that helps to form nice and human understandable answers.\\nThe information part contains the provided information that you must use to construct an answer.\\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\\nMake the answer sound as a response to the question. Do not mention that you based the result on the given information.\\nIf the provided information is empty, say that you don't know the answer.\\nInformation:\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\", template_format='f-string', validate_template=True), gremlin_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['schema', 'question'], output_parser=None, partial_variables={}, template='Task:Generate Gremlin statement to query a graph database.\\nInstructions:\\nUse only the provided relationship types and properties in the schema.\\nDo not use any other relationship types or properties that are not provided.\\nSchema:\\n{schema}\\nNote: Do not include any explanations or apologies in your responses.\\nDo not respond to any questions that might ask anything else than for you to construct a Gremlin statement.\\nDo not include any text except the generated Gremlin statement.\\n\\nThe question is:\\n{question}', template_format='f-string', validate_template=True), **kwargs: 'Any') -> 'HugeGraphQAChain' from pydantic.main.ModelMetaclass\n",
      "     |      Initialize from LLM.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Input keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Output keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'graph': 'HugeGraph', 'gremlin_generation_chain': '...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.graph_qa.hugegraph.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'gr...\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...r =...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class HypotheticalDocumentEmbedder(langchain.chains.base.Chain, langchain.embeddings.base.Embeddings)\n",
      "     |  HypotheticalDocumentEmbedder(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, base_embeddings: langchain.embeddings.base.Embeddings, llm_chain: langchain.chains.llm.LLMChain) -> None\n",
      "     |  \n",
      "     |  Generate hypothetical document for query, and then embed that.\n",
      "     |  \n",
      "     |  Based on https://arxiv.org/abs/2212.10496\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      HypotheticalDocumentEmbedder\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      langchain.embeddings.base.Embeddings\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  combine_embeddings(self, embeddings: 'List[List[float]]') -> 'List[float]'\n",
      "     |      Combine embeddings into final embeddings.\n",
      "     |  \n",
      "     |  embed_documents(self, texts: 'List[str]') -> 'List[List[float]]'\n",
      "     |      Call the base embeddings.\n",
      "     |  \n",
      "     |  embed_query(self, text: 'str') -> 'List[float]'\n",
      "     |      Generate a hypothetical document and embedded it.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', base_embeddings: 'Embeddings', prompt_key: 'str', **kwargs: 'Any') -> 'HypotheticalDocumentEmbedder' from pydantic.main.ModelMetaclass\n",
      "     |      Load and use LLMChain for a specific prompt key.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Input keys for Hyde's LLM chain.\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Output keys for Hyde's LLM chain.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.hyde.base.HypotheticalDocumentEmbedd...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'base_embeddings': 'Embeddings', 'llm_chain': 'LLMC...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.hyde.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'base_embeddings': ModelField(name='base_embeddings', ty...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...lm_...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.embeddings.base.Embeddings:\n",
      "     |  \n",
      "     |  async aembed_documents(self, texts: List[str]) -> List[List[float]]\n",
      "     |      Asynchronous Embed search docs.\n",
      "     |  \n",
      "     |  async aembed_query(self, text: str) -> List[float]\n",
      "     |      Asynchronous Embed query text.\n",
      "    \n",
      "    class KuzuQAChain(langchain.chains.base.Chain)\n",
      "     |  KuzuQAChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, graph: langchain.graphs.kuzu_graph.KuzuGraph, cypher_generation_chain: langchain.chains.llm.LLMChain, qa_chain: langchain.chains.llm.LLMChain, input_key: str = 'query', output_key: str = 'result') -> None\n",
      "     |  \n",
      "     |  Chain for question-answering against a graph by generating Cypher statements for\n",
      "     |  KÃ¹zu.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      KuzuQAChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', *, qa_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['context', 'question'], output_parser=None, partial_variables={}, template=\"You are an assistant that helps to form nice and human understandable answers.\\nThe information part contains the provided information that you must use to construct an answer.\\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\\nMake the answer sound as a response to the question. Do not mention that you based the result on the given information.\\nIf the provided information is empty, say that you don't know the answer.\\nInformation:\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\", template_format='f-string', validate_template=True), cypher_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['schema', 'question'], output_parser=None, partial_variables={}, template='Task:Generate KÃ¹zu Cypher statement to query a graph database.\\n\\nInstructions:\\n\\nGenerate statement with KÃ¹zu Cypher dialect (rather than standard):\\n1. do not use `WHERE EXISTS` clause to check the existence of a property because KÃ¹zu database has a fixed schema.\\n2. do not omit relationship pattern. Always use `()-[]->()` instead of `()->()`.\\n3. do not include any notes or comments even if the statement does not produce the expected result.\\n```\\n\\nUse only the provided relationship types and properties in the schema.\\nDo not use any other relationship types or properties that are not provided.\\nSchema:\\n{schema}\\nNote: Do not include any explanations or apologies in your responses.\\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\\nDo not include any text except the generated Cypher statement.\\n\\nThe question is:\\n{question}', template_format='f-string', validate_template=True), **kwargs: 'Any') -> 'KuzuQAChain' from pydantic.main.ModelMetaclass\n",
      "     |      Initialize from LLM.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Return the input keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return the output keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'cypher_generation_chain': 'LLMChain', 'graph': 'Ku...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.graph_qa.kuzu.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'gr...\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...r =...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class LLMBashChain(langchain.chains.base.Chain)\n",
      "     |  LLMBashChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, llm_chain: langchain.chains.llm.LLMChain, llm: Optional[langchain.schema.language_model.BaseLanguageModel] = None, input_key: str = 'question', output_key: str = 'answer', prompt: langchain.schema.prompt_template.BasePromptTemplate = PromptTemplate(input_variables=['question'], output_parser=BashOutputParser(), partial_variables={}, template='If someone asks you to perform a task, your job is to come up with a series of bash commands that will perform the task. There is no need to put \"#!/bin/bash\" in your answer. Make sure to reason step by step, using this format:\\n\\nQuestion: \"copy the files in the directory named \\'target\\' into a new directory at the same level as target called \\'myNewDirectory\\'\"\\n\\nI need to take the following actions:\\n- List all files in the directory\\n- Create a new directory\\n- Copy the files from the first directory into the second directory\\n```bash\\nls\\nmkdir myNewDirectory\\ncp -r target/* myNewDirectory\\n```\\n\\nThat is the format. Begin!\\n\\nQuestion: {question}', template_format='f-string', validate_template=True), bash_process: langchain.utilities.bash.BashProcess = None) -> None\n",
      "     |  \n",
      "     |  Chain that interprets a prompt and executes bash operations.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain import LLMBashChain, OpenAI\n",
      "     |          llm_bash = LLMBashChain.from_llm(OpenAI())\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LLMBashChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['question'], output_parser=BashOutputParser(), partial_variables={}, template='If someone asks you to perform a task, your job is to come up with a series of bash commands that will perform the task. There is no need to put \"#!/bin/bash\" in your answer. Make sure to reason step by step, using this format:\\n\\nQuestion: \"copy the files in the directory named \\'target\\' into a new directory at the same level as target called \\'myNewDirectory\\'\"\\n\\nI need to take the following actions:\\n- List all files in the directory\\n- Create a new directory\\n- Copy the files from the first directory into the second directory\\n```bash\\nls\\nmkdir myNewDirectory\\ncp -r target/* myNewDirectory\\n```\\n\\nThat is the format. Begin!\\n\\nQuestion: {question}', template_format='f-string', validate_template=True), **kwargs: 'Any') -> 'LLMBashChain' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  validate_prompt(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Expect output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.llm_bash.base.LLMBashChain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'bash_process': 'BashProcess', 'input_key': 'str', ...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.llm_bash.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'bash_process': ModelField(name='bash_process', type=Bas...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function LLMBashChain.raise_deprecation>]\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...cha...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class LLMChain(langchain.chains.base.Chain)\n",
      "     |  LLMChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, prompt: langchain.schema.prompt_template.BasePromptTemplate, llm: langchain.schema.language_model.BaseLanguageModel, output_key: str = 'text', output_parser: langchain.schema.output_parser.BaseLLMOutputParser = None, return_final_only: bool = True, llm_kwargs: dict = None) -> None\n",
      "     |  \n",
      "     |  Chain to run queries against LLMs.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain import LLMChain, OpenAI, PromptTemplate\n",
      "     |          prompt_template = \"Tell me a {adjective} joke\"\n",
      "     |          prompt = PromptTemplate(\n",
      "     |              input_variables=[\"adjective\"], template=prompt_template\n",
      "     |          )\n",
      "     |          llm = LLMChain(llm=OpenAI(), prompt=prompt)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LLMChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  async aapply(self, input_list: 'List[Dict[str, Any]]', callbacks: 'Callbacks' = None) -> 'List[Dict[str, str]]'\n",
      "     |      Utilize the LLM generate method for speed gains.\n",
      "     |  \n",
      "     |  async aapply_and_parse(self, input_list: 'List[Dict[str, Any]]', callbacks: 'Callbacks' = None) -> 'Sequence[Union[str, List[str], Dict[str, str]]]'\n",
      "     |      Call apply and then parse the results.\n",
      "     |  \n",
      "     |  async agenerate(self, input_list: 'List[Dict[str, Any]]', run_manager: 'Optional[AsyncCallbackManagerForChainRun]' = None) -> 'LLMResult'\n",
      "     |      Generate LLM result from inputs.\n",
      "     |  \n",
      "     |  apply(self, input_list: 'List[Dict[str, Any]]', callbacks: 'Callbacks' = None) -> 'List[Dict[str, str]]'\n",
      "     |      Utilize the LLM generate method for speed gains.\n",
      "     |  \n",
      "     |  apply_and_parse(self, input_list: 'List[Dict[str, Any]]', callbacks: 'Callbacks' = None) -> 'Sequence[Union[str, List[str], Dict[str, str]]]'\n",
      "     |      Call apply and then parse the results.\n",
      "     |  \n",
      "     |  async apredict(self, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'str'\n",
      "     |      Format prompt with kwargs and pass to LLM.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          callbacks: Callbacks to pass to LLMChain\n",
      "     |          **kwargs: Keys to pass to prompt template.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Completion from LLM.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              completion = llm.predict(adjective=\"funny\")\n",
      "     |  \n",
      "     |  async apredict_and_parse(self, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Union[str, List[str], Dict[str, str]]'\n",
      "     |      Call apredict and then parse the results.\n",
      "     |  \n",
      "     |  async aprep_prompts(self, input_list: 'List[Dict[str, Any]]', run_manager: 'Optional[AsyncCallbackManagerForChainRun]' = None) -> 'Tuple[List[PromptValue], Optional[List[str]]]'\n",
      "     |      Prepare prompts from inputs.\n",
      "     |  \n",
      "     |  create_outputs(self, llm_result: 'LLMResult') -> 'List[Dict[str, Any]]'\n",
      "     |      Create outputs from response.\n",
      "     |  \n",
      "     |  generate(self, input_list: 'List[Dict[str, Any]]', run_manager: 'Optional[CallbackManagerForChainRun]' = None) -> 'LLMResult'\n",
      "     |      Generate LLM result from inputs.\n",
      "     |  \n",
      "     |  predict(self, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'str'\n",
      "     |      Format prompt with kwargs and pass to LLM.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          callbacks: Callbacks to pass to LLMChain\n",
      "     |          **kwargs: Keys to pass to prompt template.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Completion from LLM.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              completion = llm.predict(adjective=\"funny\")\n",
      "     |  \n",
      "     |  predict_and_parse(self, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Union[str, List[str], Dict[str, Any]]'\n",
      "     |      Call predict and then parse the results.\n",
      "     |  \n",
      "     |  prep_prompts(self, input_list: 'List[Dict[str, Any]]', run_manager: 'Optional[CallbackManagerForChainRun]' = None) -> 'Tuple[List[PromptValue], Optional[List[str]]]'\n",
      "     |      Prepare prompts from inputs.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_string(llm: 'BaseLanguageModel', template: 'str') -> 'LLMChain' from pydantic.main.ModelMetaclass\n",
      "     |      Create LLMChain from LLM and template.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Will be whatever keys the prompt expects.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Will always return text key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.llm.LLMChain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'llm': 'BaseLanguageModel', 'llm_kwargs': 'dict', '...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.llm.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...y: ...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class LLMCheckerChain(langchain.chains.base.Chain)\n",
      "     |  LLMCheckerChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, question_to_checked_assertions_chain: langchain.chains.sequential.SequentialChain, llm: Optional[langchain.schema.language_model.BaseLanguageModel] = None, create_draft_answer_prompt: langchain.prompts.prompt.PromptTemplate = PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='{question}\\n\\n', template_format='f-string', validate_template=True), list_assertions_prompt: langchain.prompts.prompt.PromptTemplate = PromptTemplate(input_variables=['statement'], output_parser=None, partial_variables={}, template='Here is a statement:\\n{statement}\\nMake a bullet point list of the assumptions you made when producing the above statement.\\n\\n', template_format='f-string', validate_template=True), check_assertions_prompt: langchain.prompts.prompt.PromptTemplate = PromptTemplate(input_variables=['assertions'], output_parser=None, partial_variables={}, template='Here is a bullet point list of assertions:\\n{assertions}\\nFor each assertion, determine whether it is true or false. If it is false, explain why.\\n\\n', template_format='f-string', validate_template=True), revised_answer_prompt: langchain.prompts.prompt.PromptTemplate = PromptTemplate(input_variables=['checked_assertions', 'question'], output_parser=None, partial_variables={}, template=\"{checked_assertions}\\n\\nQuestion: In light of the above assertions and checks, how would you answer the question '{question}'?\\n\\nAnswer:\", template_format='f-string', validate_template=True), input_key: str = 'query', output_key: str = 'result') -> None\n",
      "     |  \n",
      "     |  Chain for question-answering with self-verification.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain import OpenAI, LLMCheckerChain\n",
      "     |          llm = OpenAI(temperature=0.7)\n",
      "     |          checker_chain = LLMCheckerChain.from_llm(llm)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LLMCheckerChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', create_draft_answer_prompt: 'PromptTemplate' = PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='{question}\\n\\n', template_format='f-string', validate_template=True), list_assertions_prompt: 'PromptTemplate' = PromptTemplate(input_variables=['statement'], output_parser=None, partial_variables={}, template='Here is a statement:\\n{statement}\\nMake a bullet point list of the assumptions you made when producing the above statement.\\n\\n', template_format='f-string', validate_template=True), check_assertions_prompt: 'PromptTemplate' = PromptTemplate(input_variables=['assertions'], output_parser=None, partial_variables={}, template='Here is a bullet point list of assertions:\\n{assertions}\\nFor each assertion, determine whether it is true or false. If it is false, explain why.\\n\\n', template_format='f-string', validate_template=True), revised_answer_prompt: 'PromptTemplate' = PromptTemplate(input_variables=['checked_assertions', 'question'], output_parser=None, partial_variables={}, template=\"{checked_assertions}\\n\\nQuestion: In light of the above assertions and checks, how would you answer the question '{question}'?\\n\\nAnswer:\", template_format='f-string', validate_template=True), **kwargs: 'Any') -> 'LLMCheckerChain' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Return the singular input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return the singular output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.llm_checker.base.LLMCheckerChain.Con...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'check_assertions_prompt': 'PromptTemplate', 'creat...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.llm_checker.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function LLMCheckerChain.raise_deprecation...\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...r =...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class LLMMathChain(langchain.chains.base.Chain)\n",
      "     |  LLMMathChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, llm_chain: langchain.chains.llm.LLMChain, llm: Optional[langchain.schema.language_model.BaseLanguageModel] = None, prompt: langchain.schema.prompt_template.BasePromptTemplate = PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n', template_format='f-string', validate_template=True), input_key: str = 'question', output_key: str = 'answer') -> None\n",
      "     |  \n",
      "     |  Chain that interprets a prompt and executes python code to do math.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain import LLMMathChain, OpenAI\n",
      "     |          llm_math = LLMMathChain.from_llm(OpenAI())\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LLMMathChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='Translate a math problem into a expression that can be executed using Python\\'s numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${{Question with math problem.}}\\n```text\\n${{single line mathematical expression that solves the problem}}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${{Output of running the code}}\\n```\\nAnswer: ${{Answer}}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\"37593 * 67\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\"37593**(1/5)\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: {question}\\n', template_format='f-string', validate_template=True), **kwargs: 'Any') -> 'LLMMathChain' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Expect output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.llm_math.base.LLMMathChain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'input_key': 'str', 'llm': 'Optional[BaseLanguageMo...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.llm_math.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function LLMMathChain.raise_deprecation>]\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema... 'q...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class LLMRequestsChain(langchain.chains.base.Chain)\n",
      "     |  LLMRequestsChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, llm_chain: langchain.chains.llm.LLMChain, requests_wrapper: langchain.requests.TextRequestsWrapper = None, text_length: int = 8000, requests_key: str = 'requests_result', input_key: str = 'url', output_key: str = 'output') -> None\n",
      "     |  \n",
      "     |  Chain that requests a URL and then uses an LLM to parse results.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LLMRequestsChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  validate_environment(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |      Validate that api key and python package exists in environment.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Will be whatever keys the prompt expects.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Will always return text key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.llm_requests.LLMRequestsChain.Config...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'input_key': 'str', 'llm_chain': 'LLMChain', 'outpu...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.llm_requests.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 're...\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...str...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class LLMRouterChain(langchain.chains.router.base.RouterChain)\n",
      "     |  LLMRouterChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, llm_chain: langchain.chains.llm.LLMChain) -> None\n",
      "     |  \n",
      "     |  A router chain that uses an LLM chain to perform routing.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LLMRouterChain\n",
      "     |      langchain.chains.router.base.RouterChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', prompt: 'BasePromptTemplate', **kwargs: 'Any') -> 'LLMRouterChain' from pydantic.main.ModelMetaclass\n",
      "     |      Convenience constructor.\n",
      "     |  \n",
      "     |  validate_prompt(values: 'dict') -> 'dict' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Will be whatever keys the LLM chain prompt expects.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'llm_chain': 'LLMChain'}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.router.llm_router.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...lm_...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.router.base.RouterChain:\n",
      "     |  \n",
      "     |  async aroute(self, inputs: 'Dict[str, Any]', callbacks: 'Callbacks' = None) -> 'Route'\n",
      "     |  \n",
      "     |  route(self, inputs: 'Dict[str, Any]', callbacks: 'Callbacks' = None) -> 'Route'\n",
      "     |      Route inputs to a destination chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: inputs to the chain\n",
      "     |          callbacks: callbacks to use for the chain\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          a Route object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.chains.router.base.RouterChain:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Keys expected to be in the chain output.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class LLMSummarizationCheckerChain(langchain.chains.base.Chain)\n",
      "     |  LLMSummarizationCheckerChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, sequential_chain: langchain.chains.sequential.SequentialChain, llm: Optional[langchain.schema.language_model.BaseLanguageModel] = None, create_assertions_prompt: langchain.prompts.prompt.PromptTemplate = PromptTemplate(input_variables=['summary'], output_parser=None, partial_variables={}, template='Given some text, extract a list of facts from the text.\\n\\nFormat your output as a bulleted list.\\n\\nText:\\n\"\"\"\\n{summary}\\n\"\"\"\\n\\nFacts:', template_format='f-string', validate_template=True), check_assertions_prompt: langchain.prompts.prompt.PromptTemplate = PromptTemplate(input_variables=['assertions'], output_parser=None, partial_variables={}, template='You are an expert fact checker. You have been hired by a major news organization to fact check a very important story.\\n\\nHere is a bullet point list of facts:\\n\"\"\"\\n{assertions}\\n\"\"\"\\n\\nFor each fact, determine whether it is true or false about the subject. If you are unable to determine whether the fact is true or false, output \"Undetermined\".\\nIf the fact is false, explain why.\\n\\n', template_format='f-string', validate_template=True), revised_summary_prompt: langchain.prompts.prompt.PromptTemplate = PromptTemplate(input_variables=['checked_assertions', 'summary'], output_parser=None, partial_variables={}, template='Below are some assertions that have been fact checked and are labeled as true or false. If the answer is false, a suggestion is given for a correction.\\n\\nChecked Assertions:\\n\"\"\"\\n{checked_assertions}\\n\"\"\"\\n\\nOriginal Summary:\\n\"\"\"\\n{summary}\\n\"\"\"\\n\\nUsing these checked assertions, rewrite the original summary to be completely true.\\n\\nThe output should have the same structure and formatting as the original summary.\\n\\nSummary:', template_format='f-string', validate_template=True), are_all_true_prompt: langchain.prompts.prompt.PromptTemplate = PromptTemplate(input_variables=['checked_assertions'], output_parser=None, partial_variables={}, template='Below are some assertions that have been fact checked and are labeled as true or false.\\n\\nIf all of the assertions are true, return \"True\". If any of the assertions are false, return \"False\".\\n\\nHere are some examples:\\n===\\n\\nChecked Assertions: \"\"\"\\n- The sky is red: False\\n- Water is made of lava: False\\n- The sun is a star: True\\n\"\"\"\\nResult: False\\n\\n===\\n\\nChecked Assertions: \"\"\"\\n- The sky is blue: True\\n- Water is wet: True\\n- The sun is a star: True\\n\"\"\"\\nResult: True\\n\\n===\\n\\nChecked Assertions: \"\"\"\\n- The sky is blue - True\\n- Water is made of lava- False\\n- The sun is a star - True\\n\"\"\"\\nResult: False\\n\\n===\\n\\nChecked Assertions:\"\"\"\\n{checked_assertions}\\n\"\"\"\\nResult:', template_format='f-string', validate_template=True), input_key: str = 'query', output_key: str = 'result', max_checks: int = 2) -> None\n",
      "     |  \n",
      "     |  Chain for question-answering with self-verification.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain import OpenAI, LLMSummarizationCheckerChain\n",
      "     |          llm = OpenAI(temperature=0.0)\n",
      "     |          checker_chain = LLMSummarizationCheckerChain.from_llm(llm)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LLMSummarizationCheckerChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', create_assertions_prompt: 'PromptTemplate' = PromptTemplate(input_variables=['summary'], output_parser=None, partial_variables={}, template='Given some text, extract a list of facts from the text.\\n\\nFormat your output as a bulleted list.\\n\\nText:\\n\"\"\"\\n{summary}\\n\"\"\"\\n\\nFacts:', template_format='f-string', validate_template=True), check_assertions_prompt: 'PromptTemplate' = PromptTemplate(input_variables=['assertions'], output_parser=None, partial_variables={}, template='You are an expert fact checker. You have been hired by a major news organization to fact check a very important story.\\n\\nHere is a bullet point list of facts:\\n\"\"\"\\n{assertions}\\n\"\"\"\\n\\nFor each fact, determine whether it is true or false about the subject. If you are unable to determine whether the fact is true or false, output \"Undetermined\".\\nIf the fact is false, explain why.\\n\\n', template_format='f-string', validate_template=True), revised_summary_prompt: 'PromptTemplate' = PromptTemplate(input_variables=['checked_assertions', 'summary'], output_parser=None, partial_variables={}, template='Below are some assertions that have been fact checked and are labeled as true or false. If the answer is false, a suggestion is given for a correction.\\n\\nChecked Assertions:\\n\"\"\"\\n{checked_assertions}\\n\"\"\"\\n\\nOriginal Summary:\\n\"\"\"\\n{summary}\\n\"\"\"\\n\\nUsing these checked assertions, rewrite the original summary to be completely true.\\n\\nThe output should have the same structure and formatting as the original summary.\\n\\nSummary:', template_format='f-string', validate_template=True), are_all_true_prompt: 'PromptTemplate' = PromptTemplate(input_variables=['checked_assertions'], output_parser=None, partial_variables={}, template='Below are some assertions that have been fact checked and are labeled as true or false.\\n\\nIf all of the assertions are true, return \"True\". If any of the assertions are false, return \"False\".\\n\\nHere are some examples:\\n===\\n\\nChecked Assertions: \"\"\"\\n- The sky is red: False\\n- Water is made of lava: False\\n- The sun is a star: True\\n\"\"\"\\nResult: False\\n\\n===\\n\\nChecked Assertions: \"\"\"\\n- The sky is blue: True\\n- Water is wet: True\\n- The sun is a star: True\\n\"\"\"\\nResult: True\\n\\n===\\n\\nChecked Assertions: \"\"\"\\n- The sky is blue - True\\n- Water is made of lava- False\\n- The sun is a star - True\\n\"\"\"\\nResult: False\\n\\n===\\n\\nChecked Assertions:\"\"\"\\n{checked_assertions}\\n\"\"\"\\nResult:', template_format='f-string', validate_template=True), verbose: 'bool' = False, **kwargs: 'Any') -> 'LLMSummarizationCheckerChain' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Return the singular input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return the singular output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.llm_summarization_checker.base.LLMSu...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'are_all_true_prompt': 'PromptTemplate', 'check_ass...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.llm_summarization_checker.base.C...\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'are_all_true_prompt': ModelField(name='are_all_true_pro...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function LLMSummarizationCheckerChain.rais...\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...ey:...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class MapReduceChain(langchain.chains.base.Chain)\n",
      "     |  MapReduceChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, combine_documents_chain: langchain.chains.combine_documents.base.BaseCombineDocumentsChain, text_splitter: langchain.text_splitter.TextSplitter, input_key: str = 'input_text', output_key: str = 'output_text') -> None\n",
      "     |  \n",
      "     |  Map-reduce chain.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MapReduceChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_params(llm: 'BaseLanguageModel', prompt: 'BasePromptTemplate', text_splitter: 'TextSplitter', callbacks: 'Callbacks' = None, combine_chain_kwargs: 'Optional[Mapping[str, Any]]' = None, reduce_chain_kwargs: 'Optional[Mapping[str, Any]]' = None, **kwargs: 'Any') -> 'MapReduceChain' from pydantic.main.ModelMetaclass\n",
      "     |      Construct a map-reduce chain that uses the chain for map and reduce.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.mapreduce.MapReduceChain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'combine_documents_chain': 'BaseCombineDocumentsCha...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.mapreduce.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema..._te...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class MapReduceDocumentsChain(langchain.chains.combine_documents.base.BaseCombineDocumentsChain)\n",
      "     |  MapReduceDocumentsChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, input_key: str = 'input_documents', output_key: str = 'output_text', llm_chain: langchain.chains.llm.LLMChain, reduce_documents_chain: langchain.chains.combine_documents.base.BaseCombineDocumentsChain, document_variable_name: str, return_intermediate_steps: bool = False) -> None\n",
      "     |  \n",
      "     |  Combining documents by mapping a chain over them, then combining results.\n",
      "     |  \n",
      "     |  We first call `llm_chain` on each document individually, passing in the\n",
      "     |  `page_content` and any other kwargs. This is the `map` step.\n",
      "     |  \n",
      "     |  We then process the results of that `map` step in a `reduce` step. This should\n",
      "     |  likely be a ReduceDocumentsChain.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain.chains import (\n",
      "     |              StuffDocumentsChain,\n",
      "     |              LLMChain,\n",
      "     |              ReduceDocumentsChain,\n",
      "     |              MapReduceDocumentsChain,\n",
      "     |          )\n",
      "     |          from langchain.prompts import PromptTemplate\n",
      "     |          from langchain.llms import OpenAI\n",
      "     |  \n",
      "     |          # This controls how each document will be formatted. Specifically,\n",
      "     |          # it will be passed to `format_document` - see that function for more\n",
      "     |          # details.\n",
      "     |          document_prompt = PromptTemplate(\n",
      "     |              input_variables=[\"page_content\"],\n",
      "     |               template=\"{page_content}\"\n",
      "     |          )\n",
      "     |          document_variable_name = \"context\"\n",
      "     |          llm = OpenAI()\n",
      "     |          # The prompt here should take as an input variable the\n",
      "     |          # `document_variable_name`\n",
      "     |          prompt = PromptTemplate.from_template(\n",
      "     |              \"Summarize this content: {context}\"\n",
      "     |          )\n",
      "     |          llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "     |          # We now define how to combine these summaries\n",
      "     |          reduce_prompt = PromptTemplate.from_template(\n",
      "     |              \"Combine these summaries: {context}\"\n",
      "     |          )\n",
      "     |          reduce_llm_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
      "     |          combine_documents_chain = StuffDocumentsChain(\n",
      "     |              llm_chain=reduce_llm_chain,\n",
      "     |              document_prompt=document_prompt,\n",
      "     |              document_variable_name=document_variable_name\n",
      "     |          )\n",
      "     |          reduce_documents_chain = ReduceDocumentsChain(\n",
      "     |              combine_documents_chain=combine_documents_chain,\n",
      "     |          )\n",
      "     |          chain = MapReduceDocumentsChain(\n",
      "     |              llm_chain=llm_chain,\n",
      "     |              reduce_documents_chain=reduce_documents_chain,\n",
      "     |          )\n",
      "     |          # If we wanted to, we could also pass in collapse_documents_chain\n",
      "     |          # which is specifically aimed at collapsing documents BEFORE\n",
      "     |          # the final call.\n",
      "     |          prompt = PromptTemplate.from_template(\n",
      "     |              \"Collapse this content: {context}\"\n",
      "     |          )\n",
      "     |          llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "     |          collapse_documents_chain = StuffDocumentsChain(\n",
      "     |              llm_chain=llm_chain,\n",
      "     |              document_prompt=document_prompt,\n",
      "     |              document_variable_name=document_variable_name\n",
      "     |          )\n",
      "     |          reduce_documents_chain = ReduceDocumentsChain(\n",
      "     |              combine_documents_chain=combine_documents_chain,\n",
      "     |              collapse_documents_chain=collapse_documents_chain,\n",
      "     |          )\n",
      "     |          chain = MapReduceDocumentsChain(\n",
      "     |              llm_chain=llm_chain,\n",
      "     |              reduce_documents_chain=reduce_documents_chain,\n",
      "     |          )\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MapReduceDocumentsChain\n",
      "     |      langchain.chains.combine_documents.base.BaseCombineDocumentsChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  async acombine_docs(self, docs: 'List[Document]', token_max: 'Optional[int]' = None, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Tuple[str, dict]'\n",
      "     |      Combine documents in a map reduce manner.\n",
      "     |      \n",
      "     |      Combine by mapping first chain over all documents, then reducing the results.\n",
      "     |      This reducing can be done recursively if needed (if there are many documents).\n",
      "     |  \n",
      "     |  combine_docs(self, docs: 'List[Document]', token_max: 'Optional[int]' = None, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Tuple[str, dict]'\n",
      "     |      Combine documents in a map reduce manner.\n",
      "     |      \n",
      "     |      Combine by mapping first chain over all documents, then reducing the results.\n",
      "     |      This reducing can be done recursively if needed (if there are many documents).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  get_default_document_variable_name(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |      Get default document variable name, if not provided.\n",
      "     |  \n",
      "     |  get_reduce_chain(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |      For backwards compatibility.\n",
      "     |  \n",
      "     |  get_return_intermediate_steps(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |      For backwards compatibility.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  collapse_document_chain\n",
      "     |      Kept for backward compatibility.\n",
      "     |  \n",
      "     |  combine_document_chain\n",
      "     |      Kept for backward compatibility.\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.combine_documents.map_reduce.MapRedu...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'document_variable_name': 'str', 'llm_chain': 'LLMC...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.combine_documents.map_reduce.Con...\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function MapReduceDocumentsChain.get_reduc...\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...ret...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.combine_documents.base.BaseCombineDocumentsChain:\n",
      "     |  \n",
      "     |  prompt_length(self, docs: List[langchain.schema.document.Document], **kwargs: Any) -> Optional[int]\n",
      "     |      Return the prompt length given the documents passed in.\n",
      "     |      \n",
      "     |      This can be used by a caller to determine whether passing in a list\n",
      "     |      of documents would exceed a certain prompt length. This useful when\n",
      "     |      trying to ensure that the size of a prompt remains below a certain\n",
      "     |      context limit.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          docs: List[Document], a list of documents to use to calculate the\n",
      "     |              total prompt length.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Returns None if the method does not depend on the prompt length,\n",
      "     |          otherwise the length of the prompt in tokens.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.chains.combine_documents.base.BaseCombineDocumentsChain:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class MapRerankDocumentsChain(langchain.chains.combine_documents.base.BaseCombineDocumentsChain)\n",
      "     |  MapRerankDocumentsChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, input_key: str = 'input_documents', output_key: str = 'output_text', llm_chain: langchain.chains.llm.LLMChain, document_variable_name: str, rank_key: str, answer_key: str, metadata_keys: Optional[List[str]] = None, return_intermediate_steps: bool = False) -> None\n",
      "     |  \n",
      "     |  Combining documents by mapping a chain over them, then reranking results.\n",
      "     |  \n",
      "     |      This algorithm calls an LLMChain on each input document. The LLMChain is expected\n",
      "     |      to have an OutputParser that parses the result into both an answer (`answer_key`)\n",
      "     |      and a score (`rank_key`). The answer with the highest score is then returned.\n",
      "     |  \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |  \n",
      "     |              from langchain.chains import StuffDocumentsChain, LLMChain\n",
      "     |              from langchain.prompts import PromptTemplate\n",
      "     |              from langchain.llms import OpenAI\n",
      "     |              from langchain.output_parsers.regex import RegexParser\n",
      "     |  \n",
      "     |              document_variable_name = \"context\"\n",
      "     |              llm = OpenAI()\n",
      "     |              # The prompt here should take as an input variable the\n",
      "     |              # `document_variable_name`\n",
      "     |              # The actual prompt will need to be a lot more complex, this is just\n",
      "     |              # an example.\n",
      "     |              prompt_template = (\n",
      "     |                  \"Use the following context to tell me the chemical formula \"\n",
      "     |                  \"for water. Output both your answer and a score of how confident \"\n",
      "     |                  \"you are. Context: {content}\"\n",
      "     |              )\n",
      "     |              output_parser = RegexParser(\n",
      "     |                  regex=r\"(.*?)\n",
      "     |  Score: (.*)\",\n",
      "     |                  output_keys=[\"answer\", \"score\"],\n",
      "     |              )\n",
      "     |              prompt = PromptTemplate(\n",
      "     |                  template=prompt_template,\n",
      "     |                  input_variables=[\"context\"],\n",
      "     |                  output_parser=output_parser,\n",
      "     |              )\n",
      "     |              llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "     |              chain = MapRerankDocumentsChain(\n",
      "     |                  llm_chain=llm_chain,\n",
      "     |                  document_variable_name=document_variable_name,\n",
      "     |                  rank_key=\"score\",\n",
      "     |                  answer_key=\"answer\",\n",
      "     |              )\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MapRerankDocumentsChain\n",
      "     |      langchain.chains.combine_documents.base.BaseCombineDocumentsChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  async acombine_docs(self, docs: 'List[Document]', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Tuple[str, dict]'\n",
      "     |      Combine documents in a map rerank manner.\n",
      "     |      \n",
      "     |      Combine by mapping first chain over all documents, then reranking the results.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          docs: List of documents to combine\n",
      "     |          callbacks: Callbacks to be passed through\n",
      "     |          **kwargs: additional parameters to be passed to LLM calls (like other\n",
      "     |              input variables besides the documents)\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The first element returned is the single string output. The second\n",
      "     |          element returned is a dictionary of other keys to return.\n",
      "     |  \n",
      "     |  combine_docs(self, docs: 'List[Document]', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Tuple[str, dict]'\n",
      "     |      Combine documents in a map rerank manner.\n",
      "     |      \n",
      "     |      Combine by mapping first chain over all documents, then reranking the results.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          docs: List of documents to combine\n",
      "     |          callbacks: Callbacks to be passed through\n",
      "     |          **kwargs: additional parameters to be passed to LLM calls (like other\n",
      "     |              input variables besides the documents)\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The first element returned is the single string output. The second\n",
      "     |          element returned is a dictionary of other keys to return.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  get_default_document_variable_name(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |      Get default document variable name, if not provided.\n",
      "     |  \n",
      "     |  validate_llm_output(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |      Validate that the combine chain outputs a dictionary.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.combine_documents.map_rerank.MapRera...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'answer_key': 'str', 'document_variable_name': 'str...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.combine_documents.map_rerank.Con...\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'answer_key': ModelField(name='answer_key', type=str, re...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function MapRerankDocumentsChain.get_defau...\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...ret...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.combine_documents.base.BaseCombineDocumentsChain:\n",
      "     |  \n",
      "     |  prompt_length(self, docs: List[langchain.schema.document.Document], **kwargs: Any) -> Optional[int]\n",
      "     |      Return the prompt length given the documents passed in.\n",
      "     |      \n",
      "     |      This can be used by a caller to determine whether passing in a list\n",
      "     |      of documents would exceed a certain prompt length. This useful when\n",
      "     |      trying to ensure that the size of a prompt remains below a certain\n",
      "     |      context limit.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          docs: List[Document], a list of documents to use to calculate the\n",
      "     |              total prompt length.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Returns None if the method does not depend on the prompt length,\n",
      "     |          otherwise the length of the prompt in tokens.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.chains.combine_documents.base.BaseCombineDocumentsChain:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class MultiPromptChain(langchain.chains.router.base.MultiRouteChain)\n",
      "     |  MultiPromptChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, router_chain: langchain.chains.router.base.RouterChain, destination_chains: Mapping[str, langchain.chains.llm.LLMChain], default_chain: langchain.chains.llm.LLMChain, silent_errors: bool = False) -> None\n",
      "     |  \n",
      "     |  A multi-route chain that uses an LLM router chain to choose amongst prompts.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MultiPromptChain\n",
      "     |      langchain.chains.router.base.MultiRouteChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_prompts(llm: 'BaseLanguageModel', prompt_infos: 'List[Dict[str, str]]', default_chain: 'Optional[LLMChain]' = None, **kwargs: 'Any') -> 'MultiPromptChain' from pydantic.main.ModelMetaclass\n",
      "     |      Convenience constructor for instantiating from destination prompts.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Will always return text key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'default_chain': 'LLMChain', 'destination_chains': ...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.router.multi_prompt.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...m.L...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.chains.router.base.MultiRouteChain:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Will be whatever keys the router chain prompt expects.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.router.base.MultiRouteChain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.router.base.MultiRouteChain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class MultiRetrievalQAChain(langchain.chains.router.base.MultiRouteChain)\n",
      "     |  MultiRetrievalQAChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, router_chain: langchain.chains.router.llm_router.LLMRouterChain, destination_chains: Mapping[str, langchain.chains.retrieval_qa.base.BaseRetrievalQA], default_chain: langchain.chains.base.Chain, silent_errors: bool = False) -> None\n",
      "     |  \n",
      "     |  A multi-route chain that uses an LLM router chain to choose amongst retrieval\n",
      "     |  qa chains.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MultiRetrievalQAChain\n",
      "     |      langchain.chains.router.base.MultiRouteChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_retrievers(llm: 'BaseLanguageModel', retriever_infos: 'List[Dict[str, Any]]', default_retriever: 'Optional[BaseRetriever]' = None, default_prompt: 'Optional[PromptTemplate]' = None, default_chain: 'Optional[Chain]' = None, **kwargs: 'Any') -> 'MultiRetrievalQAChain' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Will always return text key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'default_chain': 'Chain', 'destination_chains': 'Ma...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.router.multi_retrieval_qa.Config...\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...bas...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.chains.router.base.MultiRouteChain:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Will be whatever keys the router chain prompt expects.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.router.base.MultiRouteChain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.router.base.MultiRouteChain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class MultiRouteChain(langchain.chains.base.Chain)\n",
      "     |  MultiRouteChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, router_chain: langchain.chains.router.base.RouterChain, destination_chains: Mapping[str, langchain.chains.base.Chain], default_chain: langchain.chains.base.Chain, silent_errors: bool = False) -> None\n",
      "     |  \n",
      "     |  Use a single chain to route an input to one of multiple candidate chains.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MultiRouteChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Will be whatever keys the router chain prompt expects.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Will always return text key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.router.base.MultiRouteChain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'default_chain': 'Chain', 'destination_chains': 'Ma...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.router.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...bas...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class NatBotChain(langchain.chains.base.Chain)\n",
      "     |  NatBotChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, llm_chain: langchain.chains.llm.LLMChain, objective: str, llm: Optional[langchain.schema.language_model.BaseLanguageModel] = None, input_url_key: str = 'url', input_browser_content_key: str = 'browser_content', previous_command: str = '', output_key: str = 'command') -> None\n",
      "     |  \n",
      "     |  Implement an LLM driven browser.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain import NatBotChain\n",
      "     |          natbot = NatBotChain.from_default(\"Buy me a new hat.\")\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NatBotChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  execute(self, url: 'str', browser_content: 'str') -> 'str'\n",
      "     |      Figure out next browser command to run.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          url: URL of the site currently on.\n",
      "     |          browser_content: Content of the page as currently displayed by the browser.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Next browser command to run.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              browser_content = \"....\"\n",
      "     |              llm_command = natbot.run(\"www.google.com\", browser_content)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_default(objective: 'str', **kwargs: 'Any') -> 'NatBotChain' from pydantic.main.ModelMetaclass\n",
      "     |      Load with default LLMChain.\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', objective: 'str', **kwargs: 'Any') -> 'NatBotChain' from pydantic.main.ModelMetaclass\n",
      "     |      Load from LLM.\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect url and browser content.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return command.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.natbot.base.NatBotChain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'input_browser_content_key': 'str', 'input_url_key'...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.natbot.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function NatBotChain.raise_deprecation>]\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...: s...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class NebulaGraphQAChain(langchain.chains.base.Chain)\n",
      "     |  NebulaGraphQAChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, graph: langchain.graphs.nebula_graph.NebulaGraph, ngql_generation_chain: langchain.chains.llm.LLMChain, qa_chain: langchain.chains.llm.LLMChain, input_key: str = 'query', output_key: str = 'result') -> None\n",
      "     |  \n",
      "     |  Chain for question-answering against a graph by generating nGQL statements.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      NebulaGraphQAChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', *, qa_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['context', 'question'], output_parser=None, partial_variables={}, template=\"You are an assistant that helps to form nice and human understandable answers.\\nThe information part contains the provided information that you must use to construct an answer.\\nThe provided information is authoritative, you must never doubt it or try to use your internal knowledge to correct it.\\nMake the answer sound as a response to the question. Do not mention that you based the result on the given information.\\nIf the provided information is empty, say that you don't know the answer.\\nInformation:\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\", template_format='f-string', validate_template=True), ngql_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['schema', 'question'], output_parser=None, partial_variables={}, template=\"Task:Generate NebulaGraph Cypher statement to query a graph database.\\n\\nInstructions:\\n\\nFirst, generate cypher then convert it to NebulaGraph Cypher dialect(rather than standard):\\n1. it requires explicit label specification only when referring to node properties: v.`Foo`.name\\n2. note explicit label specification is not needed for edge properties, so it's e.name instead of e.`Bar`.name\\n3. it uses double equals sign for comparison: `==` rather than `=`\\nFor instance:\\n```diff\\n< MATCH (p:person)-[e:directed]->(m:movie) WHERE m.name = 'The Godfather II'\\n< RETURN p.name, e.year, m.name;\\n---\\n> MATCH (p:`person`)-[e:directed]->(m:`movie`) WHERE m.`movie`.`name` == 'The Godfather II'\\n> RETURN p.`person`.`name`, e.year, m.`movie`.`name`;\\n```\\n\\nUse only the provided relationship types and properties in the schema.\\nDo not use any other relationship types or properties that are not provided.\\nSchema:\\n{schema}\\nNote: Do not include any explanations or apologies in your responses.\\nDo not respond to any questions that might ask anything else than for you to construct a Cypher statement.\\nDo not include any text except the generated Cypher statement.\\n\\nThe question is:\\n{question}\", template_format='f-string', validate_template=True), **kwargs: 'Any') -> 'NebulaGraphQAChain' from pydantic.main.ModelMetaclass\n",
      "     |      Initialize from LLM.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Return the input keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return the output keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'graph': 'NebulaGraph', 'input_key': 'str', 'ngql_g...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.graph_qa.nebulagraph.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'gr...\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...r =...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class OpenAIModerationChain(langchain.chains.base.Chain)\n",
      "     |  OpenAIModerationChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, client: Any = None, model_name: Optional[str] = None, error: bool = False, input_key: str = 'input', output_key: str = 'output', openai_api_key: Optional[str] = None, openai_organization: Optional[str] = None) -> None\n",
      "     |  \n",
      "     |  Pass input through a moderation endpoint.\n",
      "     |  \n",
      "     |  To use, you should have the ``openai`` python package installed, and the\n",
      "     |  environment variable ``OPENAI_API_KEY`` set with your API key.\n",
      "     |  \n",
      "     |  Any parameters that are valid to be passed to the openai.create call can be passed\n",
      "     |  in, even if not explicitly saved on this class.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain.chains import OpenAIModerationChain\n",
      "     |          moderation = OpenAIModerationChain()\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OpenAIModerationChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  validate_environment(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Validate that api key and python package exists in environment.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'client': typing.Any, 'error': <class 'bool'>, 'inp...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.moderation.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...ena...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class OpenAPIEndpointChain(langchain.chains.base.Chain, pydantic.main.BaseModel)\n",
      "     |  OpenAPIEndpointChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, api_request_chain: langchain.chains.llm.LLMChain, api_response_chain: Optional[langchain.chains.llm.LLMChain] = None, api_operation: langchain.tools.openapi.utils.api_models.APIOperation, requests: langchain.requests.Requests = None, param_mapping: langchain.chains.api.openapi.chain._ParamMapping, return_intermediate_steps: bool = False, instructions_key: str = 'instructions', output_key: str = 'output', max_text_length: Optional[langchain.chains.api.openapi.chain.ConstrainedIntValue] = None) -> None\n",
      "     |  \n",
      "     |  Chain interacts with an OpenAPI endpoint using natural language.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      OpenAPIEndpointChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  deserialize_json_input(self, serialized_args: 'str') -> 'dict'\n",
      "     |      Use the serialized typescript dictionary.\n",
      "     |      \n",
      "     |      Resolve the path, query params dict, and optional requestBody dict.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_api_operation(operation: 'APIOperation', llm: 'BaseLanguageModel', requests: 'Optional[Requests]' = None, verbose: 'bool' = False, return_intermediate_steps: 'bool' = False, raw_response: 'bool' = False, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> \"'OpenAPIEndpointChain'\" from pydantic.main.ModelMetaclass\n",
      "     |      Create an OpenAPIEndpointChain from an operation and a spec.\n",
      "     |  \n",
      "     |  from_url_and_method(spec_url: 'str', path: 'str', method: 'str', llm: 'BaseLanguageModel', requests: 'Optional[Requests]' = None, return_intermediate_steps: 'bool' = False, **kwargs: 'Any') -> \"'OpenAPIEndpointChain'\" from pydantic.main.ModelMetaclass\n",
      "     |      Create an OpenAPIEndpoint from a spec at the specified url.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Expect output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'api_operation': 'APIOperation', 'api_request_chain...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.api.openapi.chain.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 're...\n",
      "     |  \n",
      "     |  __fields__ = {'api_operation': ModelField(name='api_operation', type=A...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...ena...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class PALChain(langchain.chains.base.Chain)\n",
      "     |  PALChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, llm_chain: langchain.chains.llm.LLMChain, llm: Optional[langchain.schema.language_model.BaseLanguageModel] = None, prompt: langchain.schema.prompt_template.BasePromptTemplate = PromptTemplate(input_variables=['question'], output_parser=None, partial_variables={}, template='Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\\n\\n# solution in Python:\\n\\n\\ndef solution():\\n    \"\"\"Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\"\"\"\\n    money_initial = 23\\n    bagels = 5\\n    bagel_cost = 3\\n    money_spent = bagels * bagel_cost\\n    money_left = money_initial - money_spent\\n    result = money_left\\n    return result\\n\\n\\n\\n\\n\\nQ: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\\n\\n# solution in Python:\\n\\n\\ndef solution():\\n    \"\"\"Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he have at the end of wednesday?\"\"\"\\n    golf_balls_initial = 58\\n    golf_balls_lost_tuesday = 23\\n    golf_balls_lost_wednesday = 2\\n    golf_balls_left = golf_balls_initial - golf_balls_lost_tuesday - golf_balls_lost_wednesday\\n    result = golf_balls_left\\n    return result\\n\\n\\n\\n\\n\\nQ: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\\n\\n# solution in Python:\\n\\n\\ndef solution():\\n    \"\"\"There were nine computers in the server room. Five more computers were installed each day, from monday to thursday. How many computers are now in the server room?\"\"\"\\n    computers_initial = 9\\n    computers_per_day = 5\\n    num_days = 4  # 4 days between monday and thursday\\n    computers_added = computers_per_day * num_days\\n    computers_total = computers_initial + computers_added\\n    result = computers_total\\n    return result\\n\\n\\n\\n\\n\\nQ: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\\n\\n# solution in Python:\\n\\n\\ndef solution():\\n    \"\"\"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\"\"\"\\n    toys_initial = 5\\n    mom_toys = 2\\n    dad_toys = 2\\n    total_received = mom_toys + dad_toys\\n    total_toys = toys_initial + total_received\\n    result = total_toys\\n    return result\\n\\n\\n\\n\\n\\nQ: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\\n\\n# solution in Python:\\n\\n\\ndef solution():\\n    \"\"\"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to Denny?\"\"\"\\n    jason_lollipops_initial = 20\\n    jason_lollipops_after = 12\\n    denny_lollipops = jason_lollipops_initial - jason_lollipops_after\\n    result = denny_lollipops\\n    return result\\n\\n\\n\\n\\n\\nQ: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\n\\n# solution in Python:\\n\\n\\ndef solution():\\n    \"\"\"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\"\"\\n    leah_chocolates = 32\\n    sister_chocolates = 42\\n    total_chocolates = leah_chocolates + sister_chocolates\\n    chocolates_eaten = 35\\n    chocolates_left = total_chocolates - chocolates_eaten\\n    result = chocolates_left\\n    return result\\n\\n\\n\\n\\n\\nQ: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\n\\n# solution in Python:\\n\\n\\ndef solution():\\n    \"\"\"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\"\"\\n    cars_initial = 3\\n    cars_arrived = 2\\n    total_cars = cars_initial + cars_arrived\\n    result = total_cars\\n    return result\\n\\n\\n\\n\\n\\nQ: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\\n\\n# solution in Python:\\n\\n\\ndef solution():\\n    \"\"\"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be 21 trees. How many trees did the grove workers plant today?\"\"\"\\n    trees_initial = 15\\n    trees_after = 21\\n    trees_added = trees_after - trees_initial\\n    result = trees_added\\n    return result\\n\\n\\n\\n\\n\\nQ: {question}\\n\\n# solution in Python:\\n\\n\\n', template_format='f-string', validate_template=True), stop: str = '\\n\\n', get_answer_expr: str = 'print(solution())', python_globals: Optional[Dict[str, Any]] = None, python_locals: Optional[Dict[str, Any]] = None, output_key: str = 'result', return_intermediate_steps: bool = False, code_validations: langchain.chains.pal.base.PALValidation = None, timeout: Optional[int] = 10) -> None\n",
      "     |  \n",
      "     |  Implements Program-Aided Language Models (PAL).\n",
      "     |  \n",
      "     |  This class implements the Program-Aided Language Models (PAL) for generating code\n",
      "     |  solutions. PAL is a technique described in the paper \"Program-Aided Language Models\"\n",
      "     |  (https://arxiv.org/pdf/2211.10435.pdf).\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PALChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_colored_object_prompt(llm: 'BaseLanguageModel', **kwargs: 'Any') -> 'PALChain' from pydantic.main.ModelMetaclass\n",
      "     |      Load PAL from colored object prompt.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          llm (BaseLanguageModel): The language model to use for generating code.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          PALChain: An instance of PALChain.\n",
      "     |  \n",
      "     |  from_math_prompt(llm: 'BaseLanguageModel', **kwargs: 'Any') -> 'PALChain' from pydantic.main.ModelMetaclass\n",
      "     |      Load PAL from math prompt.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          llm (BaseLanguageModel): The language model to use for generating code.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          PALChain: An instance of PALChain.\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  validate_code(code: 'str', code_validations: 'PALValidation') -> 'None' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Return the singular input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return the singular output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.pal.base.PALChain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'code_validations': 'PALValidation', 'get_answer_ex...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.pal.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function PALChain.raise_deprecation>]\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...ion...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class QAGenerationChain(langchain.chains.base.Chain)\n",
      "     |  QAGenerationChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, llm_chain: langchain.chains.llm.LLMChain, text_splitter: langchain.text_splitter.TextSplitter = <langchain.text_splitter.RecursiveCharacterTextSplitter object at 0x1319871c0>, input_key: str = 'text', output_key: str = 'questions', k: Optional[int] = None) -> None\n",
      "     |  \n",
      "     |  Base class for question-answer generation chains.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      QAGenerationChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', prompt: 'Optional[BasePromptTemplate]' = None, **kwargs: 'Any') -> 'QAGenerationChain' from pydantic.main.ModelMetaclass\n",
      "     |      Create a QAGenerationChain from a language model.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          llm: a language model\n",
      "     |          prompt: a prompt template\n",
      "     |          **kwargs: additional arguments\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          a QAGenerationChain class\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Keys expected to be in the chain input.\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Keys expected to be in the chain output.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'input_key': 'str', 'k': 'Optional[int]', 'llm_chai...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.qa_generation.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema... = ...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class QAWithSourcesChain(BaseQAWithSourcesChain)\n",
      "     |  QAWithSourcesChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, combine_documents_chain: langchain.chains.combine_documents.base.BaseCombineDocumentsChain, question_key: str = 'question', input_docs_key: str = 'docs', answer_key: str = 'answer', sources_answer_key: str = 'sources', return_source_documents: bool = False) -> None\n",
      "     |  \n",
      "     |  Question answering with sources over documents.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      QAWithSourcesChain\n",
      "     |      BaseQAWithSourcesChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'input_docs_key': 'str'}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.qa_with_sources.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'answer_key': ModelField(name='answer_key', type=str, re...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function BaseQAWithSourcesChain.validate_n...\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema..., r...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from BaseQAWithSourcesChain:\n",
      "     |  \n",
      "     |  from_chain_type(llm: 'BaseLanguageModel', chain_type: 'str' = 'stuff', chain_type_kwargs: 'Optional[dict]' = None, **kwargs: 'Any') -> 'BaseQAWithSourcesChain' from pydantic.main.ModelMetaclass\n",
      "     |      Load chain from chain type.\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', document_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['page_content', 'source'], output_parser=None, partial_variables={}, template='Content: {page_content}\\nSource: {source}', template_format='f-string', validate_template=True), question_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['context', 'question'], output_parser=None, partial_variables={}, template='Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\n{context}\\nQuestion: {question}\\nRelevant text, if any:', template_format='f-string', validate_template=True), combine_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['summaries', 'question'], output_parser=None, partial_variables={}, template='Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \\nIf you don\\'t know the answer, just say that you don\\'t know. Don\\'t try to make up an answer.\\nALWAYS return a \"SOURCES\" part in your answer.\\n\\nQUESTION: Which state/country\\'s law governs the interpretation of the contract?\\n=========\\nContent: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\\nSource: 28-pl\\nContent: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\\n\\n11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\\n\\n11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\\n\\n11.9 No Third-Party Beneficiaries.\\nSource: 30-pl\\nContent: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any Anti-Bribery Laws (as  defined in Clause 8.5) or that such a violation is reasonably likely to occur,\\nSource: 4-pl\\n=========\\nFINAL ANSWER: This Agreement is governed by English law.\\nSOURCES: 28-pl\\n\\nQUESTION: What did the president say about Michael Jackson?\\n=========\\nContent: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russiaâ€™s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \\n\\nGroups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.\\nSource: 0-pl\\nContent: And we wonâ€™t stop. \\n\\nWe have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \\n\\nLetâ€™s use this moment to reset. Letâ€™s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \\n\\nLetâ€™s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \\n\\nWe canâ€™t change how divided weâ€™ve been. But we can change how we move forwardâ€”on COVID-19 and other issues we must face together. \\n\\nI recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \\n\\nThey were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \\n\\nOfficer Mora was 27 years old. \\n\\nOfficer Rivera was 22. \\n\\nBoth Dominican Americans whoâ€™d grown up on the same streets they later chose to patrol as police officers. \\n\\nI spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\\nSource: 24-pl\\nContent: And a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as Iâ€™ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \\n\\nAnd Iâ€™m taking robust action to make sure the pain of our sanctions  is targeted at Russiaâ€™s economy. And I will use every tool at our disposal to protect American businesses and consumers. \\n\\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \\n\\nAmerica will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \\n\\nThese steps will help blunt gas prices here at home. And I know the news about whatâ€™s happening can seem alarming. \\n\\nBut I want you to know that we are going to be okay.\\nSource: 5-pl\\nContent: More support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nItâ€™s based on DARPAâ€”the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purposeâ€”to drive breakthroughs in cancer, Alzheimerâ€™s, diabetes, and more. \\n\\nA unity agenda for the nation. \\n\\nWe can do this. \\n\\nMy fellow Americansâ€”tonight , we have gathered in a sacred spaceâ€”the citadel of our democracy. \\n\\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\n\\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror. \\n\\nAnd built the strongest, freest, and most prosperous nation the world has ever known. \\n\\nNow is the hour. \\n\\nOur moment of responsibility. \\n\\nOur test of resolve and conscience, of history itself. \\n\\nIt is in this moment that our character is formed. Our purpose is found. Our future is forged. \\n\\nWell I know this nation.\\nSource: 34-pl\\n=========\\nFINAL ANSWER: The president did not mention Michael Jackson.\\nSOURCES:\\n\\nQUESTION: {question}\\n=========\\n{summaries}\\n=========\\nFINAL ANSWER:', template_format='f-string', validate_template=True), **kwargs: 'Any') -> 'BaseQAWithSourcesChain' from pydantic.main.ModelMetaclass\n",
      "     |      Construct the chain from an LLM.\n",
      "     |  \n",
      "     |  validate_naming(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |      Fix backwards compatibility in naming.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseQAWithSourcesChain:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseQAWithSourcesChain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.qa_with_sources.base.BaseQAWithSourc...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class ReduceDocumentsChain(langchain.chains.combine_documents.base.BaseCombineDocumentsChain)\n",
      "     |  ReduceDocumentsChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, input_key: str = 'input_documents', output_key: str = 'output_text', combine_documents_chain: langchain.chains.combine_documents.base.BaseCombineDocumentsChain, collapse_documents_chain: Optional[langchain.chains.combine_documents.base.BaseCombineDocumentsChain] = None, token_max: int = 3000) -> None\n",
      "     |  \n",
      "     |  Combine documents by recursively reducing them.\n",
      "     |  \n",
      "     |  This involves\n",
      "     |  \n",
      "     |  - combine_documents_chain\n",
      "     |  \n",
      "     |  - collapse_documents_chain\n",
      "     |  \n",
      "     |  `combine_documents_chain` is ALWAYS provided. This is final chain that is called.\n",
      "     |  We pass all previous results to this chain, and the output of this chain is\n",
      "     |  returned as a final result.\n",
      "     |  \n",
      "     |  `collapse_documents_chain` is used if the documents passed in are too many to all\n",
      "     |  be passed to `combine_documents_chain` in one go. In this case,\n",
      "     |  `collapse_documents_chain` is called recursively on as big of groups of documents\n",
      "     |  as are allowed.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain.chains import (\n",
      "     |              StuffDocumentsChain, LLMChain, ReduceDocumentsChain\n",
      "     |          )\n",
      "     |          from langchain.prompts import PromptTemplate\n",
      "     |          from langchain.llms import OpenAI\n",
      "     |  \n",
      "     |          # This controls how each document will be formatted. Specifically,\n",
      "     |          # it will be passed to `format_document` - see that function for more\n",
      "     |          # details.\n",
      "     |          document_prompt = PromptTemplate(\n",
      "     |              input_variables=[\"page_content\"],\n",
      "     |               template=\"{page_content}\"\n",
      "     |          )\n",
      "     |          document_variable_name = \"context\"\n",
      "     |          llm = OpenAI()\n",
      "     |          # The prompt here should take as an input variable the\n",
      "     |          # `document_variable_name`\n",
      "     |          prompt = PromptTemplate.from_template(\n",
      "     |              \"Summarize this content: {context}\"\n",
      "     |          )\n",
      "     |          llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "     |          combine_documents_chain = StuffDocumentsChain(\n",
      "     |              llm_chain=llm_chain,\n",
      "     |              document_prompt=document_prompt,\n",
      "     |              document_variable_name=document_variable_name\n",
      "     |          )\n",
      "     |          chain = ReduceDocumentsChain(\n",
      "     |              combine_documents_chain=combine_documents_chain,\n",
      "     |          )\n",
      "     |          # If we wanted to, we could also pass in collapse_documents_chain\n",
      "     |          # which is specifically aimed at collapsing documents BEFORE\n",
      "     |          # the final call.\n",
      "     |          prompt = PromptTemplate.from_template(\n",
      "     |              \"Collapse this content: {context}\"\n",
      "     |          )\n",
      "     |          llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "     |          collapse_documents_chain = StuffDocumentsChain(\n",
      "     |              llm_chain=llm_chain,\n",
      "     |              document_prompt=document_prompt,\n",
      "     |              document_variable_name=document_variable_name\n",
      "     |          )\n",
      "     |          chain = ReduceDocumentsChain(\n",
      "     |              combine_documents_chain=combine_documents_chain,\n",
      "     |              collapse_documents_chain=collapse_documents_chain,\n",
      "     |          )\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ReduceDocumentsChain\n",
      "     |      langchain.chains.combine_documents.base.BaseCombineDocumentsChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  async acombine_docs(self, docs: 'List[Document]', token_max: 'Optional[int]' = None, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Tuple[str, dict]'\n",
      "     |      Async combine multiple documents recursively.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          docs: List of documents to combine, assumed that each one is less than\n",
      "     |              `token_max`.\n",
      "     |          token_max: Recursively creates groups of documents less than this number\n",
      "     |              of tokens.\n",
      "     |          callbacks: Callbacks to be passed through\n",
      "     |          **kwargs: additional parameters to be passed to LLM calls (like other\n",
      "     |              input variables besides the documents)\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The first element returned is the single string output. The second\n",
      "     |          element returned is a dictionary of other keys to return.\n",
      "     |  \n",
      "     |  combine_docs(self, docs: 'List[Document]', token_max: 'Optional[int]' = None, callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Tuple[str, dict]'\n",
      "     |      Combine multiple documents recursively.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          docs: List of documents to combine, assumed that each one is less than\n",
      "     |              `token_max`.\n",
      "     |          token_max: Recursively creates groups of documents less than this number\n",
      "     |              of tokens.\n",
      "     |          callbacks: Callbacks to be passed through\n",
      "     |          **kwargs: additional parameters to be passed to LLM calls (like other\n",
      "     |              input variables besides the documents)\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The first element returned is the single string output. The second\n",
      "     |          element returned is a dictionary of other keys to return.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.combine_documents.reduce.ReduceDocum...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'collapse_documents_chain': 'Optional[BaseCombineDo...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.combine_documents.reduce.Config'...\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...nts...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.combine_documents.base.BaseCombineDocumentsChain:\n",
      "     |  \n",
      "     |  prompt_length(self, docs: List[langchain.schema.document.Document], **kwargs: Any) -> Optional[int]\n",
      "     |      Return the prompt length given the documents passed in.\n",
      "     |      \n",
      "     |      This can be used by a caller to determine whether passing in a list\n",
      "     |      of documents would exceed a certain prompt length. This useful when\n",
      "     |      trying to ensure that the size of a prompt remains below a certain\n",
      "     |      context limit.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          docs: List[Document], a list of documents to use to calculate the\n",
      "     |              total prompt length.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Returns None if the method does not depend on the prompt length,\n",
      "     |          otherwise the length of the prompt in tokens.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.chains.combine_documents.base.BaseCombineDocumentsChain:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class RefineDocumentsChain(langchain.chains.combine_documents.base.BaseCombineDocumentsChain)\n",
      "     |  RefineDocumentsChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, input_key: str = 'input_documents', output_key: str = 'output_text', initial_llm_chain: langchain.chains.llm.LLMChain, refine_llm_chain: langchain.chains.llm.LLMChain, document_variable_name: str, initial_response_name: str, document_prompt: langchain.schema.prompt_template.BasePromptTemplate = None, return_intermediate_steps: bool = False) -> None\n",
      "     |  \n",
      "     |  Combine documents by doing a first pass and then refining on more documents.\n",
      "     |  \n",
      "     |  This algorithm first calls `initial_llm_chain` on the first document, passing\n",
      "     |  that first document in with the variable name `document_variable_name`, and\n",
      "     |  produces a new variable with the variable name `initial_response_name`.\n",
      "     |  \n",
      "     |  Then, it loops over every remaining document. This is called the \"refine\" step.\n",
      "     |  It calls `refine_llm_chain`,\n",
      "     |  passing in that document with the variable name `document_variable_name`\n",
      "     |  as well as the previous response with the variable name `initial_response_name`.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain.chains import RefineDocumentsChain, LLMChain\n",
      "     |          from langchain.prompts import PromptTemplate\n",
      "     |          from langchain.llms import OpenAI\n",
      "     |  \n",
      "     |          # This controls how each document will be formatted. Specifically,\n",
      "     |          # it will be passed to `format_document` - see that function for more\n",
      "     |          # details.\n",
      "     |          document_prompt = PromptTemplate(\n",
      "     |              input_variables=[\"page_content\"],\n",
      "     |               template=\"{page_content}\"\n",
      "     |          )\n",
      "     |          document_variable_name = \"context\"\n",
      "     |          llm = OpenAI()\n",
      "     |          # The prompt here should take as an input variable the\n",
      "     |          # `document_variable_name`\n",
      "     |          prompt = PromptTemplate.from_template(\n",
      "     |              \"Summarize this content: {context}\"\n",
      "     |          )\n",
      "     |          llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "     |          initial_response_name = \"prev_response\"\n",
      "     |          # The prompt here should take as an input variable the\n",
      "     |          # `document_variable_name` as well as `initial_response_name`\n",
      "     |          prompt_refine = PromptTemplate.from_template(\n",
      "     |              \"Here's your first summary: {prev_response}. \"\n",
      "     |              \"Now add to it based on the following context: {context}\"\n",
      "     |          )\n",
      "     |          llm_chain_refine = LLMChain(llm=llm, prompt=prompt_refine)\n",
      "     |          chain = RefineDocumentsChain(\n",
      "     |              initial_llm_chain=initial_llm_chain,\n",
      "     |              refine_llm_chain=refine_llm_chain,\n",
      "     |              document_prompt=document_prompt,\n",
      "     |              document_variable_name=document_variable_name,\n",
      "     |              initial_response_name=initial_response_name,\n",
      "     |          )\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RefineDocumentsChain\n",
      "     |      langchain.chains.combine_documents.base.BaseCombineDocumentsChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  async acombine_docs(self, docs: 'List[Document]', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Tuple[str, dict]'\n",
      "     |      Async combine by mapping a first chain over all, then stuffing\n",
      "     |       into a final chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          docs: List of documents to combine\n",
      "     |          callbacks: Callbacks to be passed through\n",
      "     |          **kwargs: additional parameters to be passed to LLM calls (like other\n",
      "     |              input variables besides the documents)\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The first element returned is the single string output. The second\n",
      "     |          element returned is a dictionary of other keys to return.\n",
      "     |  \n",
      "     |  combine_docs(self, docs: 'List[Document]', callbacks: 'Callbacks' = None, **kwargs: 'Any') -> 'Tuple[str, dict]'\n",
      "     |      Combine by mapping first chain over all, then stuffing into final chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          docs: List of documents to combine\n",
      "     |          callbacks: Callbacks to be passed through\n",
      "     |          **kwargs: additional parameters to be passed to LLM calls (like other\n",
      "     |              input variables besides the documents)\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The first element returned is the single string output. The second\n",
      "     |          element returned is a dictionary of other keys to return.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  get_default_document_variable_name(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |      Get default document variable name, if not provided.\n",
      "     |  \n",
      "     |  get_return_intermediate_steps(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |      For backwards compatibility.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.combine_documents.refine.RefineDocum...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'document_prompt': 'BasePromptTemplate', 'document_...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.combine_documents.refine.Config'...\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function RefineDocumentsChain.get_return_i...\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...ret...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.combine_documents.base.BaseCombineDocumentsChain:\n",
      "     |  \n",
      "     |  prompt_length(self, docs: List[langchain.schema.document.Document], **kwargs: Any) -> Optional[int]\n",
      "     |      Return the prompt length given the documents passed in.\n",
      "     |      \n",
      "     |      This can be used by a caller to determine whether passing in a list\n",
      "     |      of documents would exceed a certain prompt length. This useful when\n",
      "     |      trying to ensure that the size of a prompt remains below a certain\n",
      "     |      context limit.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          docs: List[Document], a list of documents to use to calculate the\n",
      "     |              total prompt length.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Returns None if the method does not depend on the prompt length,\n",
      "     |          otherwise the length of the prompt in tokens.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.chains.combine_documents.base.BaseCombineDocumentsChain:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class RetrievalQA(BaseRetrievalQA)\n",
      "     |  RetrievalQA(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, combine_documents_chain: langchain.chains.combine_documents.base.BaseCombineDocumentsChain, input_key: str = 'query', output_key: str = 'result', return_source_documents: bool = False, retriever: langchain.schema.retriever.BaseRetriever) -> None\n",
      "     |  \n",
      "     |  Chain for question-answering against an index.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain.llms import OpenAI\n",
      "     |          from langchain.chains import RetrievalQA\n",
      "     |          from langchain.faiss import FAISS\n",
      "     |          from langchain.vectorstores.base import VectorStoreRetriever\n",
      "     |          retriever = VectorStoreRetriever(vectorstore=FAISS(...))\n",
      "     |          retrievalQA = RetrievalQA.from_llm(llm=OpenAI(), retriever=retriever)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RetrievalQA\n",
      "     |      BaseRetrievalQA\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'retriever': 'BaseRetriever'}\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.retrieval_qa.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 're...\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...ang...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from BaseRetrievalQA:\n",
      "     |  \n",
      "     |  from_chain_type(llm: 'BaseLanguageModel', chain_type: 'str' = 'stuff', chain_type_kwargs: 'Optional[dict]' = None, **kwargs: 'Any') -> 'BaseRetrievalQA' from pydantic.main.ModelMetaclass\n",
      "     |      Load chain from chain type.\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', prompt: 'Optional[PromptTemplate]' = None, **kwargs: 'Any') -> 'BaseRetrievalQA' from pydantic.main.ModelMetaclass\n",
      "     |      Initialize from LLM.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseRetrievalQA:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Input keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Output keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseRetrievalQA:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.retrieval_qa.base.BaseRetrievalQA.Co...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class RetrievalQAWithSourcesChain(langchain.chains.qa_with_sources.base.BaseQAWithSourcesChain)\n",
      "     |  RetrievalQAWithSourcesChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, combine_documents_chain: langchain.chains.combine_documents.base.BaseCombineDocumentsChain, question_key: str = 'question', input_docs_key: str = 'docs', answer_key: str = 'answer', sources_answer_key: str = 'sources', return_source_documents: bool = False, retriever: langchain.schema.retriever.BaseRetriever, reduce_k_below_max_tokens: bool = False, max_tokens_limit: int = 3375) -> None\n",
      "     |  \n",
      "     |  Question-answering with sources over an index.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RetrievalQAWithSourcesChain\n",
      "     |      langchain.chains.qa_with_sources.base.BaseQAWithSourcesChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'max_tokens_limit': <class 'int'>, 'reduce_k_below_...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.qa_with_sources.retrieval.Config...\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 're...\n",
      "     |  \n",
      "     |  __fields__ = {'answer_key': ModelField(name='answer_key', type=str, re...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function BaseQAWithSourcesChain.validate_n...\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...l =...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.qa_with_sources.base.BaseQAWithSourcesChain:\n",
      "     |  \n",
      "     |  from_chain_type(llm: 'BaseLanguageModel', chain_type: 'str' = 'stuff', chain_type_kwargs: 'Optional[dict]' = None, **kwargs: 'Any') -> 'BaseQAWithSourcesChain' from pydantic.main.ModelMetaclass\n",
      "     |      Load chain from chain type.\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', document_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['page_content', 'source'], output_parser=None, partial_variables={}, template='Content: {page_content}\\nSource: {source}', template_format='f-string', validate_template=True), question_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['context', 'question'], output_parser=None, partial_variables={}, template='Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\n{context}\\nQuestion: {question}\\nRelevant text, if any:', template_format='f-string', validate_template=True), combine_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['summaries', 'question'], output_parser=None, partial_variables={}, template='Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \\nIf you don\\'t know the answer, just say that you don\\'t know. Don\\'t try to make up an answer.\\nALWAYS return a \"SOURCES\" part in your answer.\\n\\nQUESTION: Which state/country\\'s law governs the interpretation of the contract?\\n=========\\nContent: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\\nSource: 28-pl\\nContent: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\\n\\n11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\\n\\n11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\\n\\n11.9 No Third-Party Beneficiaries.\\nSource: 30-pl\\nContent: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any Anti-Bribery Laws (as  defined in Clause 8.5) or that such a violation is reasonably likely to occur,\\nSource: 4-pl\\n=========\\nFINAL ANSWER: This Agreement is governed by English law.\\nSOURCES: 28-pl\\n\\nQUESTION: What did the president say about Michael Jackson?\\n=========\\nContent: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russiaâ€™s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \\n\\nGroups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.\\nSource: 0-pl\\nContent: And we wonâ€™t stop. \\n\\nWe have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \\n\\nLetâ€™s use this moment to reset. Letâ€™s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \\n\\nLetâ€™s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \\n\\nWe canâ€™t change how divided weâ€™ve been. But we can change how we move forwardâ€”on COVID-19 and other issues we must face together. \\n\\nI recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \\n\\nThey were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \\n\\nOfficer Mora was 27 years old. \\n\\nOfficer Rivera was 22. \\n\\nBoth Dominican Americans whoâ€™d grown up on the same streets they later chose to patrol as police officers. \\n\\nI spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\\nSource: 24-pl\\nContent: And a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as Iâ€™ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \\n\\nAnd Iâ€™m taking robust action to make sure the pain of our sanctions  is targeted at Russiaâ€™s economy. And I will use every tool at our disposal to protect American businesses and consumers. \\n\\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \\n\\nAmerica will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \\n\\nThese steps will help blunt gas prices here at home. And I know the news about whatâ€™s happening can seem alarming. \\n\\nBut I want you to know that we are going to be okay.\\nSource: 5-pl\\nContent: More support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nItâ€™s based on DARPAâ€”the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purposeâ€”to drive breakthroughs in cancer, Alzheimerâ€™s, diabetes, and more. \\n\\nA unity agenda for the nation. \\n\\nWe can do this. \\n\\nMy fellow Americansâ€”tonight , we have gathered in a sacred spaceâ€”the citadel of our democracy. \\n\\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\n\\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror. \\n\\nAnd built the strongest, freest, and most prosperous nation the world has ever known. \\n\\nNow is the hour. \\n\\nOur moment of responsibility. \\n\\nOur test of resolve and conscience, of history itself. \\n\\nIt is in this moment that our character is formed. Our purpose is found. Our future is forged. \\n\\nWell I know this nation.\\nSource: 34-pl\\n=========\\nFINAL ANSWER: The president did not mention Michael Jackson.\\nSOURCES:\\n\\nQUESTION: {question}\\n=========\\n{summaries}\\n=========\\nFINAL ANSWER:', template_format='f-string', validate_template=True), **kwargs: 'Any') -> 'BaseQAWithSourcesChain' from pydantic.main.ModelMetaclass\n",
      "     |      Construct the chain from an LLM.\n",
      "     |  \n",
      "     |  validate_naming(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |      Fix backwards compatibility in naming.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.chains.qa_with_sources.base.BaseQAWithSourcesChain:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.qa_with_sources.base.BaseQAWithSourcesChain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.qa_with_sources.base.BaseQAWithSourc...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class RouterChain(langchain.chains.base.Chain, abc.ABC)\n",
      "     |  RouterChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None) -> None\n",
      "     |  \n",
      "     |  Chain that outputs the name of a destination chain and the inputs to it.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RouterChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  async aroute(self, inputs: 'Dict[str, Any]', callbacks: 'Callbacks' = None) -> 'Route'\n",
      "     |  \n",
      "     |  route(self, inputs: 'Dict[str, Any]', callbacks: 'Callbacks' = None) -> 'Route'\n",
      "     |      Route inputs to a destination chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: inputs to the chain\n",
      "     |          callbacks: callbacks to use for the chain\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          a Route object\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Keys expected to be in the chain output.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'_call', 'input_keys'})\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.router.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...tad...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Keys expected to be in the chain input.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __annotations__ = {'callback_manager': typing.Optional[langchain.callb...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class SQLDatabaseChain(langchain.chains.base.Chain)\n",
      "     |  SQLDatabaseChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, llm_chain: langchain.chains.llm.LLMChain, llm: Optional[langchain.schema.language_model.BaseLanguageModel] = None, database: langchain.utilities.sql_database.SQLDatabase, prompt: Optional[langchain.schema.prompt_template.BasePromptTemplate] = None, top_k: int = 5, input_key: str = 'query', output_key: str = 'result', return_sql: bool = False, return_intermediate_steps: bool = False, return_direct: bool = False, use_query_checker: bool = False, query_checker_prompt: Optional[langchain.schema.prompt_template.BasePromptTemplate] = None) -> None\n",
      "     |  \n",
      "     |  Chain for interacting with SQL Database.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain import SQLDatabaseChain, OpenAI, SQLDatabase\n",
      "     |          db = SQLDatabase(...)\n",
      "     |          db_chain = SQLDatabaseChain.from_llm(OpenAI(), db)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SQLDatabaseChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', db: 'SQLDatabase', prompt: 'Optional[BasePromptTemplate]' = None, **kwargs: 'Any') -> 'SQLDatabaseChain' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Return the singular input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return the singular output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.sql_database.base.SQLDatabaseChain.C...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'database': 'SQLDatabase', 'input_key': 'str', 'llm...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.sql_database.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 'da...\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function SQLDatabaseChain.raise_deprecatio...\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...mpt...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class SQLDatabaseSequentialChain(langchain.chains.base.Chain)\n",
      "     |  SQLDatabaseSequentialChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, decider_chain: langchain.chains.llm.LLMChain, sql_chain: langchain.chains.sql_database.base.SQLDatabaseChain, input_key: str = 'query', output_key: str = 'result', return_intermediate_steps: bool = False) -> None\n",
      "     |  \n",
      "     |  Chain for querying SQL database that is a sequential chain.\n",
      "     |  \n",
      "     |  The chain is as follows:\n",
      "     |  1. Based on the query, determine which tables to use.\n",
      "     |  2. Based on those tables, call the normal SQL database chain.\n",
      "     |  \n",
      "     |  This is useful in cases where the number of tables in the database is large.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SQLDatabaseSequentialChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', database: 'SQLDatabase', query_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['input', 'table_info', 'dialect', 'top_k'], output_parser=None, partial_variables={}, template='Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer. Unless the user specifies in his question a specific number of examples he wishes to obtain, always limit your query to at most {top_k} results. You can order the results by a relevant column to return the most interesting examples in the database.\\n\\nNever query for all the columns from a specific table, only ask for a the few relevant columns given the question.\\n\\nPay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\\n\\nUse the following format:\\n\\nQuestion: Question here\\nSQLQuery: SQL Query to run\\nSQLResult: Result of the SQLQuery\\nAnswer: Final answer here\\n\\nOnly use the following tables:\\n{table_info}\\n\\nQuestion: {input}', template_format='f-string', validate_template=True), decider_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['query', 'table_names'], output_parser=CommaSeparatedListOutputParser(), partial_variables={}, template='Given the below input question and list of potential tables, output a comma separated list of the table names that may be necessary to answer this question.\\n\\nQuestion: {query}\\n\\nTable Names: {table_names}\\n\\nRelevant Table Names:', template_format='f-string', validate_template=True), **kwargs: 'Any') -> 'SQLDatabaseSequentialChain' from pydantic.main.ModelMetaclass\n",
      "     |      Load the necessary chains.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Return the singular input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return the singular output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'decider_chain': 'LLMChain', 'input_key': 'str', 'o...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.sql_database.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...ret...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class SequentialChain(langchain.chains.base.Chain)\n",
      "     |  SequentialChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, chains: List[langchain.chains.base.Chain], input_variables: List[str], output_variables: List[str], return_all: bool = False) -> None\n",
      "     |  \n",
      "     |  Chain where the outputs of one chain feed directly into next.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SequentialChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  validate_chains(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Validate that the correct inputs exist for all chains.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Return expected input keys to the chain.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.sequential.SequentialChain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'chains': typing.List[langchain.chains.base.Chain],...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.sequential.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function SequentialChain.validate_chains>]\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...es:...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class SimpleSequentialChain(langchain.chains.base.Chain)\n",
      "     |  SimpleSequentialChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, chains: List[langchain.chains.base.Chain], strip_outputs: bool = False, input_key: str = 'input', output_key: str = 'output') -> None\n",
      "     |  \n",
      "     |  Simple chain where the outputs of one step feed directly into next.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SimpleSequentialChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  validate_chains(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Validate that chains are all single input/output.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.sequential.SimpleSequentialChain.Con...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'chains': typing.List[langchain.chains.base.Chain],...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.sequential.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...r =...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class StuffDocumentsChain(langchain.chains.combine_documents.base.BaseCombineDocumentsChain)\n",
      "     |  StuffDocumentsChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, input_key: str = 'input_documents', output_key: str = 'output_text', llm_chain: langchain.chains.llm.LLMChain, document_prompt: langchain.schema.prompt_template.BasePromptTemplate = None, document_variable_name: str, document_separator: str = '\\n\\n') -> None\n",
      "     |  \n",
      "     |  Chain that combines documents by stuffing into context.\n",
      "     |  \n",
      "     |  This chain takes a list of documents and first combines them into a single string.\n",
      "     |  It does this by formatting each document into a string with the `document_prompt`\n",
      "     |  and then joining them together with `document_separator`. It then adds that new\n",
      "     |  string to the inputs with the variable name set by `document_variable_name`.\n",
      "     |  Those inputs are then passed to the `llm_chain`.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain.chains import StuffDocumentsChain, LLMChain\n",
      "     |          from langchain.prompts import PromptTemplate\n",
      "     |          from langchain.llms import OpenAI\n",
      "     |  \n",
      "     |          # This controls how each document will be formatted. Specifically,\n",
      "     |          # it will be passed to `format_document` - see that function for more\n",
      "     |          # details.\n",
      "     |          document_prompt = PromptTemplate(\n",
      "     |              input_variables=[\"page_content\"],\n",
      "     |               template=\"{page_content}\"\n",
      "     |          )\n",
      "     |          document_variable_name = \"context\"\n",
      "     |          llm = OpenAI()\n",
      "     |          # The prompt here should take as an input variable the\n",
      "     |          # `document_variable_name`\n",
      "     |          prompt = PromptTemplate.from_template(\n",
      "     |              \"Summarize this content: {context}\"\n",
      "     |          )\n",
      "     |          llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "     |          chain = StuffDocumentsChain(\n",
      "     |              llm_chain=llm_chain,\n",
      "     |              document_prompt=document_prompt,\n",
      "     |              document_variable_name=document_variable_name\n",
      "     |          )\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      StuffDocumentsChain\n",
      "     |      langchain.chains.combine_documents.base.BaseCombineDocumentsChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  async acombine_docs(self, docs: List[langchain.schema.document.Document], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, **kwargs: Any) -> Tuple[str, dict]\n",
      "     |      Async stuff all documents into one prompt and pass to LLM.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          docs: List of documents to join together into one variable\n",
      "     |          callbacks: Optional callbacks to pass along\n",
      "     |          **kwargs: additional parameters to use to get inputs to LLMChain.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The first element returned is the single string output. The second\n",
      "     |          element returned is a dictionary of other keys to return.\n",
      "     |  \n",
      "     |  combine_docs(self, docs: List[langchain.schema.document.Document], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, **kwargs: Any) -> Tuple[str, dict]\n",
      "     |      Stuff all documents into one prompt and pass to LLM.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          docs: List of documents to join together into one variable\n",
      "     |          callbacks: Optional callbacks to pass along\n",
      "     |          **kwargs: additional parameters to use to get inputs to LLMChain.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The first element returned is the single string output. The second\n",
      "     |          element returned is a dictionary of other keys to return.\n",
      "     |  \n",
      "     |  prompt_length(self, docs: List[langchain.schema.document.Document], **kwargs: Any) -> Optional[int]\n",
      "     |      Return the prompt length given the documents passed in.\n",
      "     |      \n",
      "     |      This can be used by a caller to determine whether passing in a list\n",
      "     |      of documents would exceed a certain prompt length. This useful when\n",
      "     |      trying to ensure that the size of a prompt remains below a certain\n",
      "     |      context limit.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          docs: List[Document], a list of documents to use to calculate the\n",
      "     |              total prompt length.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          Returns None if the method does not depend on the prompt length,\n",
      "     |          otherwise the length of the prompt in tokens.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  get_default_document_variable_name(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Get default document variable name, if not provided.\n",
      "     |      \n",
      "     |      If only one variable is present in the llm_chain.prompt,\n",
      "     |      we can infer that the formatted documents should be passed in\n",
      "     |      with this variable name.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.combine_documents.stuff.StuffDocumen...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'document_prompt': <class 'langchain.schema.prompt_...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.combine_documents.stuff.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function StuffDocumentsChain.get_default_d...\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...: s...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.chains.combine_documents.base.BaseCombineDocumentsChain:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class TransformChain(langchain.chains.base.Chain)\n",
      "     |  TransformChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, input_variables: List[str], output_variables: List[str], transform: Callable[[Dict[str, str]], Dict[str, str]]) -> None\n",
      "     |  \n",
      "     |  Chain transform chain output.\n",
      "     |  \n",
      "     |  Example:\n",
      "     |      .. code-block:: python\n",
      "     |  \n",
      "     |          from langchain import TransformChain\n",
      "     |          transform_chain = TransformChain(input_variables=[\"text\"],\n",
      "     |           output_variables[\"entities\"], transform=func())\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TransformChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties defined here:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return output keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'input_variables': typing.List[str], 'output_variab...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.transform.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True}\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...lab...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.base.Chain.Config'>\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class VectorDBQA(BaseRetrievalQA)\n",
      "     |  VectorDBQA(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, combine_documents_chain: langchain.chains.combine_documents.base.BaseCombineDocumentsChain, input_key: str = 'query', output_key: str = 'result', return_source_documents: bool = False, vectorstore: langchain.vectorstores.base.VectorStore, k: int = 4, search_type: str = 'similarity', search_kwargs: Dict[str, Any] = None) -> None\n",
      "     |  \n",
      "     |  Chain for question-answering against a vector database.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VectorDBQA\n",
      "     |      BaseRetrievalQA\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  raise_deprecation(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  validate_search_type(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |      Validate search type.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'k': 'int', 'search_kwargs': 'Dict[str, Any]', 'sea...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.retrieval_qa.base.Config'>\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 've...\n",
      "     |  \n",
      "     |  __fields__ = {'callback_manager': ModelField(name='callback_manager', ...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = []\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...', ...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from BaseRetrievalQA:\n",
      "     |  \n",
      "     |  from_chain_type(llm: 'BaseLanguageModel', chain_type: 'str' = 'stuff', chain_type_kwargs: 'Optional[dict]' = None, **kwargs: 'Any') -> 'BaseRetrievalQA' from pydantic.main.ModelMetaclass\n",
      "     |      Load chain from chain type.\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', prompt: 'Optional[PromptTemplate]' = None, **kwargs: 'Any') -> 'BaseRetrievalQA' from pydantic.main.ModelMetaclass\n",
      "     |      Initialize from LLM.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseRetrievalQA:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Input keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Output keys.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from BaseRetrievalQA:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.retrieval_qa.base.BaseRetrievalQA.Co...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "    \n",
      "    class VectorDBQAWithSourcesChain(langchain.chains.qa_with_sources.base.BaseQAWithSourcesChain)\n",
      "     |  VectorDBQAWithSourcesChain(*, memory: Optional[langchain.schema.memory.BaseMemory] = None, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, callback_manager: Optional[langchain.callbacks.base.BaseCallbackManager] = None, verbose: bool = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, combine_documents_chain: langchain.chains.combine_documents.base.BaseCombineDocumentsChain, question_key: str = 'question', input_docs_key: str = 'docs', answer_key: str = 'answer', sources_answer_key: str = 'sources', return_source_documents: bool = False, vectorstore: langchain.vectorstores.base.VectorStore, k: int = 4, reduce_k_below_max_tokens: bool = False, max_tokens_limit: int = 3375, search_kwargs: Dict[str, Any] = None) -> None\n",
      "     |  \n",
      "     |  Question-answering with sources over a vector database.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      VectorDBQAWithSourcesChain\n",
      "     |      langchain.chains.qa_with_sources.base.BaseQAWithSourcesChain\n",
      "     |      langchain.chains.base.Chain\n",
      "     |      langchain.load.serializable.Serializable\n",
      "     |      pydantic.main.BaseModel\n",
      "     |      pydantic.utils.Representation\n",
      "     |      abc.ABC\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Class methods defined here:\n",
      "     |  \n",
      "     |  raise_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __json_encoder__ = pydantic_encoder(obj: Any) -> Any\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  __annotations__ = {'k': <class 'int'>, 'max_tokens_limit': <class 'int...\n",
      "     |  \n",
      "     |  __class_vars__ = set()\n",
      "     |  \n",
      "     |  __config__ = <class 'langchain.chains.qa_with_sources.vector_db.Config...\n",
      "     |  \n",
      "     |  __custom_root_type__ = False\n",
      "     |  \n",
      "     |  __exclude_fields__ = {'callback_manager': True, 'callbacks': True, 've...\n",
      "     |  \n",
      "     |  __fields__ = {'answer_key': ModelField(name='answer_key', type=str, re...\n",
      "     |  \n",
      "     |  __hash__ = None\n",
      "     |  \n",
      "     |  __include_fields__ = None\n",
      "     |  \n",
      "     |  __post_root_validators__ = [(False, <function Chain.raise_callback_man...\n",
      "     |  \n",
      "     |  __pre_root_validators__ = [<function BaseQAWithSourcesChain.validate_n...\n",
      "     |  \n",
      "     |  __private_attributes__ = {'_lc_kwargs': ModelPrivateAttr(default=Pydan...\n",
      "     |  \n",
      "     |  __schema_cache__ = {}\n",
      "     |  \n",
      "     |  __signature__ = <Signature (*, memory: Optional[langchain.schema...5, ...\n",
      "     |  \n",
      "     |  __validators__ = {'verbose': [<pydantic.class_validators.Validator obj...\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.qa_with_sources.base.BaseQAWithSourcesChain:\n",
      "     |  \n",
      "     |  from_chain_type(llm: 'BaseLanguageModel', chain_type: 'str' = 'stuff', chain_type_kwargs: 'Optional[dict]' = None, **kwargs: 'Any') -> 'BaseQAWithSourcesChain' from pydantic.main.ModelMetaclass\n",
      "     |      Load chain from chain type.\n",
      "     |  \n",
      "     |  from_llm(llm: 'BaseLanguageModel', document_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['page_content', 'source'], output_parser=None, partial_variables={}, template='Content: {page_content}\\nSource: {source}', template_format='f-string', validate_template=True), question_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['context', 'question'], output_parser=None, partial_variables={}, template='Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\n{context}\\nQuestion: {question}\\nRelevant text, if any:', template_format='f-string', validate_template=True), combine_prompt: 'BasePromptTemplate' = PromptTemplate(input_variables=['summaries', 'question'], output_parser=None, partial_variables={}, template='Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \\nIf you don\\'t know the answer, just say that you don\\'t know. Don\\'t try to make up an answer.\\nALWAYS return a \"SOURCES\" part in your answer.\\n\\nQUESTION: Which state/country\\'s law governs the interpretation of the contract?\\n=========\\nContent: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\\nSource: 28-pl\\nContent: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\\n\\n11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\\n\\n11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\\n\\n11.9 No Third-Party Beneficiaries.\\nSource: 30-pl\\nContent: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any Anti-Bribery Laws (as  defined in Clause 8.5) or that such a violation is reasonably likely to occur,\\nSource: 4-pl\\n=========\\nFINAL ANSWER: This Agreement is governed by English law.\\nSOURCES: 28-pl\\n\\nQUESTION: What did the president say about Michael Jackson?\\n=========\\nContent: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russiaâ€™s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \\n\\nGroups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.\\nSource: 0-pl\\nContent: And we wonâ€™t stop. \\n\\nWe have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \\n\\nLetâ€™s use this moment to reset. Letâ€™s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \\n\\nLetâ€™s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \\n\\nWe canâ€™t change how divided weâ€™ve been. But we can change how we move forwardâ€”on COVID-19 and other issues we must face together. \\n\\nI recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \\n\\nThey were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \\n\\nOfficer Mora was 27 years old. \\n\\nOfficer Rivera was 22. \\n\\nBoth Dominican Americans whoâ€™d grown up on the same streets they later chose to patrol as police officers. \\n\\nI spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\\nSource: 24-pl\\nContent: And a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \\n\\nTo all Americans, I will be honest with you, as Iâ€™ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \\n\\nAnd Iâ€™m taking robust action to make sure the pain of our sanctions  is targeted at Russiaâ€™s economy. And I will use every tool at our disposal to protect American businesses and consumers. \\n\\nTonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \\n\\nAmerica will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \\n\\nThese steps will help blunt gas prices here at home. And I know the news about whatâ€™s happening can seem alarming. \\n\\nBut I want you to know that we are going to be okay.\\nSource: 5-pl\\nContent: More support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nItâ€™s based on DARPAâ€”the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purposeâ€”to drive breakthroughs in cancer, Alzheimerâ€™s, diabetes, and more. \\n\\nA unity agenda for the nation. \\n\\nWe can do this. \\n\\nMy fellow Americansâ€”tonight , we have gathered in a sacred spaceâ€”the citadel of our democracy. \\n\\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\n\\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror. \\n\\nAnd built the strongest, freest, and most prosperous nation the world has ever known. \\n\\nNow is the hour. \\n\\nOur moment of responsibility. \\n\\nOur test of resolve and conscience, of history itself. \\n\\nIt is in this moment that our character is formed. Our purpose is found. Our future is forged. \\n\\nWell I know this nation.\\nSource: 34-pl\\n=========\\nFINAL ANSWER: The president did not mention Michael Jackson.\\nSOURCES:\\n\\nQUESTION: {question}\\n=========\\n{summaries}\\n=========\\nFINAL ANSWER:', template_format='f-string', validate_template=True), **kwargs: 'Any') -> 'BaseQAWithSourcesChain' from pydantic.main.ModelMetaclass\n",
      "     |      Construct the chain from an LLM.\n",
      "     |  \n",
      "     |  validate_naming(values: 'Dict') -> 'Dict' from pydantic.main.ModelMetaclass\n",
      "     |      Fix backwards compatibility in naming.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.chains.qa_with_sources.base.BaseQAWithSourcesChain:\n",
      "     |  \n",
      "     |  input_keys\n",
      "     |      Expect input key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  output_keys\n",
      "     |      Return output key.\n",
      "     |      \n",
      "     |      :meta private:\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes inherited from langchain.chains.qa_with_sources.base.BaseQAWithSourcesChain:\n",
      "     |  \n",
      "     |  Config = <class 'langchain.chains.qa_with_sources.base.BaseQAWithSourc...\n",
      "     |      Configuration for this pydantic object.\n",
      "     |  \n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  __call__(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  async acall(self, inputs: Union[Dict[str, Any], Any], return_only_outputs: bool = False, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, *, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, include_run_info: bool = False) -> Dict[str, Any]\n",
      "     |      Asynchronously execute the chain.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |          return_only_outputs: Whether to return only outputs in the\n",
      "     |              response. If True, only new keys generated by this chain will be\n",
      "     |              returned. If False, both input keys and new keys generated by this\n",
      "     |              chain will be returned. Defaults to False.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          metadata: Optional metadata associated with the chain. Defaults to None\n",
      "     |          include_run_info: Whether to include run info in the response. Defaults\n",
      "     |              to False.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of named outputs. Should contain all outputs specified in\n",
      "     |              `Chain.output_keys`.\n",
      "     |  \n",
      "     |  apply(self, input_list: List[Dict[str, Any]], callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None) -> List[Dict[str, str]]\n",
      "     |      Call the chain on all inputs in the list.\n",
      "     |  \n",
      "     |  async arun(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              await chain.arun(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              await chain.arun(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  dict(self, **kwargs: Any) -> Dict\n",
      "     |      Dictionary representation of chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          **kwargs: Keyword arguments passed to default `pydantic.BaseModel.dict`\n",
      "     |              method.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary representation of the chain.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          ..code-block:: python\n",
      "     |      \n",
      "     |              chain.dict(exclude_unset=True)\n",
      "     |              # -> {\"_type\": \"foo\", \"verbose\": False, ...}\n",
      "     |  \n",
      "     |  prep_inputs(self, inputs: Union[Dict[str, Any], Any]) -> Dict[str, str]\n",
      "     |      Validate and prepare chain inputs, including adding inputs from memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of raw inputs, or single input if chain expects\n",
      "     |              only one param. Should contain all inputs specified in\n",
      "     |              `Chain.input_keys` except for inputs that will be set by the chain's\n",
      "     |              memory.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dictionary of all inputs, including those added by the chain's memory.\n",
      "     |  \n",
      "     |  prep_outputs(self, inputs: Dict[str, str], outputs: Dict[str, str], return_only_outputs: bool = False) -> Dict[str, str]\n",
      "     |      Validate and prepare chain outputs, and save info about this run to memory.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          inputs: Dictionary of chain inputs, including any inputs added by chain\n",
      "     |              memory.\n",
      "     |          outputs: Dictionary of initial chain outputs.\n",
      "     |          return_only_outputs: Whether to only return the chain outputs. If False,\n",
      "     |              inputs are also added to the final outputs.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          A dict of the final chain outputs.\n",
      "     |  \n",
      "     |  run(self, *args: Any, callbacks: Union[List[langchain.callbacks.base.BaseCallbackHandler], langchain.callbacks.base.BaseCallbackManager, NoneType] = None, tags: Optional[List[str]] = None, metadata: Optional[Dict[str, Any]] = None, **kwargs: Any) -> str\n",
      "     |      Execute chain when there's a single string output.\n",
      "     |      \n",
      "     |      The main difference between this method and `Chain.__call__` is that this method\n",
      "     |          can only be used for chains that return a single string output. If a Chain\n",
      "     |          has more outputs, a non-string output, or you want to return the inputs/run\n",
      "     |          info along with the outputs, use `Chain.__call__`.\n",
      "     |      \n",
      "     |      The other difference is that this method expects inputs to be passed directly in\n",
      "     |      as positional arguments or keyword arguments, whereas `Chain.__call__` expects\n",
      "     |      a single input dictionary with all the inputs.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          *args: If the chain expects a single input, it can be passed in as the\n",
      "     |              sole positional argument.\n",
      "     |          callbacks: Callbacks to use for this chain run. These will be called in\n",
      "     |              addition to callbacks passed to the chain during construction, but only\n",
      "     |              these runtime callbacks will propagate to calls to other objects.\n",
      "     |          tags: List of string tags to pass to all callbacks. These will be passed in\n",
      "     |              addition to tags passed to the chain during construction, but only\n",
      "     |              these runtime tags will propagate to calls to other objects.\n",
      "     |          **kwargs: If the chain expects multiple inputs, they can be passed in\n",
      "     |              directly as keyword arguments.\n",
      "     |      \n",
      "     |      Returns:\n",
      "     |          The chain output as a string.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              # Suppose we have a single-input chain that takes a 'question' string:\n",
      "     |              chain.run(\"What's the temperature in Boise, Idaho?\")\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |      \n",
      "     |              # Suppose we have a multi-input chain that takes a 'question' string\n",
      "     |              # and 'context' string:\n",
      "     |              question = \"What's the temperature in Boise, Idaho?\"\n",
      "     |              context = \"Weather report for Boise, Idaho on 07/03/23...\"\n",
      "     |              chain.run(question=question, context=context)\n",
      "     |              # -> \"The temperature in Boise is...\"\n",
      "     |  \n",
      "     |  save(self, file_path: Union[pathlib.Path, str]) -> None\n",
      "     |      Save the chain.\n",
      "     |      \n",
      "     |      Expects `Chain._chain_type` property to be implemented and for memory to be\n",
      "     |          null.\n",
      "     |      \n",
      "     |      Args:\n",
      "     |          file_path: Path to file to save the chain to.\n",
      "     |      \n",
      "     |      Example:\n",
      "     |          .. code-block:: python\n",
      "     |      \n",
      "     |              chain.save(file_path=\"path/chain.yaml\")\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from langchain.chains.base.Chain:\n",
      "     |  \n",
      "     |  raise_callback_manager_deprecation(values: Dict) -> Dict from pydantic.main.ModelMetaclass\n",
      "     |      Raise deprecation warning if callback_manager is used.\n",
      "     |  \n",
      "     |  set_verbose(verbose: Optional[bool]) -> bool from pydantic.main.ModelMetaclass\n",
      "     |      Set the chain verbosity.\n",
      "     |      \n",
      "     |      Defaults to the global setting if not specified by the user.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  __init__(self, **kwargs: Any) -> None\n",
      "     |      Create a new model by parsing and validating input data from keyword arguments.\n",
      "     |      \n",
      "     |      Raises ValidationError if the input data cannot be parsed to form a valid model.\n",
      "     |  \n",
      "     |  to_json(self) -> Union[langchain.load.serializable.SerializedConstructor, langchain.load.serializable.SerializedNotImplemented]\n",
      "     |  \n",
      "     |  to_json_not_implemented(self) -> langchain.load.serializable.SerializedNotImplemented\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from langchain.load.serializable.Serializable:\n",
      "     |  \n",
      "     |  lc_attributes\n",
      "     |      Return a list of attribute names that should be included in the\n",
      "     |      serialized kwargs. These attributes must be accepted by the\n",
      "     |      constructor.\n",
      "     |  \n",
      "     |  lc_namespace\n",
      "     |      Return the namespace of the langchain object.\n",
      "     |      eg. [\"langchain\", \"llms\", \"openai\"]\n",
      "     |  \n",
      "     |  lc_secrets\n",
      "     |      Return a map of constructor argument names to secret ids.\n",
      "     |      eg. {\"openai_api_key\": \"OPENAI_API_KEY\"}\n",
      "     |  \n",
      "     |  lc_serializable\n",
      "     |      Return whether or not the class is serializable.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __eq__(self, other: Any) -> bool\n",
      "     |  \n",
      "     |  __getstate__(self) -> 'DictAny'\n",
      "     |  \n",
      "     |  __iter__(self) -> 'TupleGenerator'\n",
      "     |      so `dict(model)` works\n",
      "     |  \n",
      "     |  __repr_args__(self) -> 'ReprArgs'\n",
      "     |  \n",
      "     |  __setattr__(self, name, value)\n",
      "     |  \n",
      "     |  __setstate__(self, state: 'DictAny') -> None\n",
      "     |  \n",
      "     |  copy(self: 'Model', *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, update: Optional[ForwardRef('DictStrAny')] = None, deep: bool = False) -> 'Model'\n",
      "     |      Duplicate a model, optionally choose which fields to include, exclude and change.\n",
      "     |      \n",
      "     |      :param include: fields to include in new model\n",
      "     |      :param exclude: fields to exclude from new model, as with values this takes precedence over include\n",
      "     |      :param update: values to change/add in the new model. Note: the data is not validated before creating\n",
      "     |          the new model: you should trust this data\n",
      "     |      :param deep: set to `True` to make a deep copy of the model\n",
      "     |      :return: new model instance\n",
      "     |  \n",
      "     |  json(self, *, include: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, exclude: Union[ForwardRef('AbstractSetIntStr'), ForwardRef('MappingIntStrAny'), NoneType] = None, by_alias: bool = False, skip_defaults: Optional[bool] = None, exclude_unset: bool = False, exclude_defaults: bool = False, exclude_none: bool = False, encoder: Optional[Callable[[Any], Any]] = None, models_as_dict: bool = True, **dumps_kwargs: Any) -> 'unicode'\n",
      "     |      Generate a JSON representation of the model, `include` and `exclude` arguments as per `dict()`.\n",
      "     |      \n",
      "     |      `encoder` is an optional function to supply as `default` to json.dumps(), other arguments as per `json.dumps()`.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Class methods inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __get_validators__() -> 'CallableGenerator' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  __try_update_forward_refs__(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Same as update_forward_refs but will not raise exception\n",
      "     |      when forward references are not defined.\n",
      "     |  \n",
      "     |  construct(_fields_set: Optional[ForwardRef('SetStr')] = None, **values: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |      Creates a new model setting __dict__ and __fields_set__ from trusted or pre-validated data.\n",
      "     |      Default values are respected, but no other validation is performed.\n",
      "     |      Behaves as if `Config.extra = 'allow'` was set since it adds all passed values\n",
      "     |  \n",
      "     |  from_orm(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_file(path: Union[str, pathlib.Path], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_obj(obj: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  parse_raw(b: Union[str, bytes], *, content_type: 'unicode' = None, encoding: 'unicode' = 'utf8', proto: pydantic.parse.Protocol = None, allow_pickle: bool = False) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema(by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}') -> 'DictStrAny' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  schema_json(*, by_alias: bool = True, ref_template: 'unicode' = '#/definitions/{model}', **dumps_kwargs: Any) -> 'unicode' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  update_forward_refs(**localns: Any) -> None from pydantic.main.ModelMetaclass\n",
      "     |      Try to update ForwardRefs on fields based on this Model, globalns and localns.\n",
      "     |  \n",
      "     |  validate(value: Any) -> 'Model' from pydantic.main.ModelMetaclass\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from pydantic.main.BaseModel:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __fields_set__\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from pydantic.utils.Representation:\n",
      "     |  \n",
      "     |  __pretty__(self, fmt: Callable[[Any], Any], **kwargs: Any) -> Generator[Any, NoneType, NoneType]\n",
      "     |      Used by devtools (https://python-devtools.helpmanual.io/) to provide a human readable representations of objects\n",
      "     |  \n",
      "     |  __repr__(self) -> 'unicode'\n",
      "     |  \n",
      "     |  __repr_name__(self) -> 'unicode'\n",
      "     |      Name of the instance's class, used in __repr__.\n",
      "     |  \n",
      "     |  __repr_str__(self, join_str: 'unicode') -> 'unicode'\n",
      "     |  \n",
      "     |  __rich_repr__(self) -> 'RichReprResult'\n",
      "     |      Get fields for Rich library\n",
      "     |  \n",
      "     |  __str__(self) -> 'unicode'\n",
      "\n",
      "FUNCTIONS\n",
      "    create_citation_fuzzy_match_chain(llm: langchain.schema.language_model.BaseLanguageModel) -> langchain.chains.llm.LLMChain\n",
      "        Create a citation fuzzy match chain.\n",
      "        \n",
      "        Args:\n",
      "            llm: Language model to use for the chain.\n",
      "        \n",
      "        Returns:\n",
      "            Chain (LLMChain) that can be used to answer questions with citations.\n",
      "    \n",
      "    create_extraction_chain(schema: dict, llm: langchain.schema.language_model.BaseLanguageModel, verbose: bool = False) -> langchain.chains.base.Chain\n",
      "        Creates a chain that extracts information from a passage.\n",
      "        \n",
      "        Args:\n",
      "            schema: The schema of the entities to extract.\n",
      "            llm: The language model to use.\n",
      "            verbose: Whether to run in verbose mode. In verbose mode, some intermediate\n",
      "                logs will be printed to the console. Defaults to `langchain.verbose` value.\n",
      "        \n",
      "        Returns:\n",
      "            Chain that can be used to extract information from a passage.\n",
      "    \n",
      "    create_extraction_chain_pydantic(pydantic_schema: Any, llm: langchain.schema.language_model.BaseLanguageModel) -> langchain.chains.base.Chain\n",
      "        Creates a chain that extracts information from a passage using pydantic schema.\n",
      "        \n",
      "        Args:\n",
      "            pydantic_schema: The pydantic schema of the entities to extract.\n",
      "            llm: The language model to use.\n",
      "        \n",
      "        Returns:\n",
      "            Chain that can be used to extract information from a passage.\n",
      "    \n",
      "    create_qa_with_sources_chain(llm: langchain.schema.language_model.BaseLanguageModel, **kwargs: Any) -> langchain.chains.llm.LLMChain\n",
      "        Create a question answering chain that returns an answer with sources.\n",
      "        \n",
      "        Args:\n",
      "            llm: Language model to use for the chain.\n",
      "            **kwargs: Keyword arguments to pass to `create_qa_with_structure_chain`.\n",
      "        \n",
      "        Returns:\n",
      "            Chain (LLMChain) that can be used to answer questions with citations.\n",
      "    \n",
      "    create_qa_with_structure_chain(llm: langchain.schema.language_model.BaseLanguageModel, schema: Union[dict, Type[pydantic.main.BaseModel]], output_parser: str = 'base', prompt: Union[langchain.prompts.prompt.PromptTemplate, langchain.prompts.chat.ChatPromptTemplate, NoneType] = None) -> langchain.chains.llm.LLMChain\n",
      "        Create a question answering chain that returns an answer with sources\n",
      "         based on schema.\n",
      "        \n",
      "        Args:\n",
      "            llm: Language model to use for the chain.\n",
      "            schema: Pydantic schema to use for the output.\n",
      "            output_parser: Output parser to use. Should be one of `pydantic` or `base`.\n",
      "                Default to `base`.\n",
      "            prompt: Optional prompt to use for the chain.\n",
      "        \n",
      "        Returns:\n",
      "    \n",
      "    create_tagging_chain(schema: dict, llm: langchain.schema.language_model.BaseLanguageModel, prompt: Optional[langchain.prompts.chat.ChatPromptTemplate] = None, **kwargs: Any) -> langchain.chains.base.Chain\n",
      "        Creates a chain that extracts information from a passage\n",
      "         based on a schema.\n",
      "        \n",
      "        Args:\n",
      "            schema: The schema of the entities to extract.\n",
      "            llm: The language model to use.\n",
      "        \n",
      "        Returns:\n",
      "            Chain (LLMChain) that can be used to extract information from a passage.\n",
      "    \n",
      "    create_tagging_chain_pydantic(pydantic_schema: Any, llm: langchain.schema.language_model.BaseLanguageModel, prompt: Optional[langchain.prompts.chat.ChatPromptTemplate] = None, **kwargs: Any) -> langchain.chains.base.Chain\n",
      "        Creates a chain that extracts information from a passage\n",
      "         based on a pydantic schema.\n",
      "        \n",
      "        Args:\n",
      "            pydantic_schema: The pydantic schema of the entities to extract.\n",
      "            llm: The language model to use.\n",
      "        \n",
      "        Returns:\n",
      "            Chain (LLMChain) that can be used to extract information from a passage.\n",
      "    \n",
      "    load_chain(path: Union[str, pathlib.Path], **kwargs: Any) -> langchain.chains.base.Chain\n",
      "        Unified method for loading a chain from LangChainHub or local fs.\n",
      "\n",
      "DATA\n",
      "    __all__ = ['APIChain', 'AnalyzeDocumentChain', 'ChatVectorDBChain', 'C...\n",
      "\n",
      "FILE\n",
      "    /Users/india.kerlenesta/opt/anaconda3/envs/dap_taltech/lib/python3.9/site-packages/langchain/chains/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#You can investigate the different types of chains by\n",
    "#calling help on langchain.chains\n",
    "\n",
    "help(langchain.chains)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ”—ðŸ¤– Chains & Agents: Agents\n",
    "\n",
    "Now that we've explored a few different types of chains that LangChain supports, let's pivot to exploring agents.\n",
    "\n",
    "Chains and agents are somewhat similar. However, in chains, a sequence of actions is hardcoded (in code). In agents, a language model is used as a reasoning engine to determine which actions to take and in which order. Here are a list of [Agent types that langchain supports](https://python.langchain.com/docs/modules/agents/agent_types/). \n",
    "\n",
    "Key to an Agent are tools. Tools are functions that an agent calls. You can define your own tools by adding a `tool` decorator to a function.\n",
    "\n",
    "Let's walk through a simple example first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_s_count` with `{'word': 'Sesquipedalian'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m2\u001b[0m\u001b[32;1m\u001b[1;3mThe letter 's' appears 2 times in the word \"Sesquipedalian\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The letter \\'s\\' appears 2 times in the word \"Sesquipedalian\".'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets load our chat model \n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "#lets define a really simple tool \n",
    "#to return the number of s's in a word\n",
    "@tool\n",
    "def get_s_count(word: str) -> int:\n",
    "    \"\"\"Returns a count of the number of s's in a word\"\"\"\n",
    "    return word.lower().count(\"s\")\n",
    "\n",
    "system_message = SystemMessage(content=\"You are very powerful assistant, but bad at calculating the number of times the letter s appears in a word.\")\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(system_message=system_message)\n",
    "\n",
    "tools = [get_s_count]\n",
    "#putting it alltogether\n",
    "agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt)\n",
    "#this defines the run time for the agent\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "agent_executor.run(\"how many times do you spot the letter 's' in the word Sesquipedalian?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila - we have an agent! However, the agent is stateless - meaning it doesn't remember anything about previous interactions, making follow up questions difficult. I don't know about you, but I have no idea what \"Sesquipedalian\" means. Let's add memory to fix this and ask a few follow up questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_s_count` with `{'word': 'Sesquipedalian'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m2\u001b[0m\u001b[32;1m\u001b[1;3mThe letter 's' appears 2 times in the word \"Sesquipedalian\".\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\"Sesquipedalian\" is an adjective that means using long words or characterized by long words; long-winded. It is often used to describe someone who tends to use excessively long and complex words in their speech or writing.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mCertainly! Here's an example sentence using the word \"sesquipedalian\":\n",
      "\n",
      "\"During the lecture, the professor's sesquipedalian style of speaking made it difficult for the students to understand the concepts.\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Certainly! Here\\'s an example sentence using the word \"sesquipedalian\":\\n\\n\"During the lecture, the professor\\'s sesquipedalian style of speaking made it difficult for the students to understand the concepts.\"'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MEMORY_KEY = \"chat_history\"\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "    system_message=system_message,\n",
    "    extra_prompt_messages=[MessagesPlaceholder(variable_name=MEMORY_KEY)]\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=MEMORY_KEY, return_messages=True)\n",
    "\n",
    "agent = OpenAIFunctionsAgent(llm=llm, tools=tools, prompt=prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, memory=memory, verbose=True)\n",
    "agent_executor.run(\"how many times do you spot the letter 's' in the word Sesquipedalian?\")\n",
    "agent_executor.run(\"what does that word even mean?\")\n",
    "agent_executor.run(\"can you use it in a sentence?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great - we've created a simple agent that can remember previous interactions. \n",
    "\n",
    "Let's explore different agents by re-visiting our chain that summarised a series of estonian patents as a use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to look at the title_localized column\n",
      "Action: python_repl_ast\n",
      "Action Input: df['title_localized'].tolist()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['A method of making a transparent visual light activated photocatalytic superhydrophilic glass material', 'Method and device for measuring charcteristics of refelection of light on surfaces', 'Method of shoot-through generation for modified sine wave z-source, quasi-z-source and trans-z-source inverters', 'Method of making a portable mip-based electrochemical sensor for the detection of the sars-cov-2 antigen', 'System and method for a partial power transfer between two dc sources', 'Synthesis and polymerization of isosorbide-based monomethacrylates', 'Therapeutic mud mixture and a method for its manufacture', 'Method and device for measuring and monitoring concentration of substances in a biological fluid', 'Method and device for frequency response measurement', 'Molecularly imprinted polymer based electrically conductive surface, method of its preparation and sensor for neurotrophic factors']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The patents are about a transparent visual light activated photocatalytic superhydrophilic glass material, measuring characteristics of reflection of light on surfaces, shoot-through generation for modified sine wave z-source, quasi-z-source and trans-z-source inverters, a portable mip-based electrochemical sensor for the detection of the sars-cov-2 antigen, a partial power transfer between two dc sources, synthesis and polymerization of isosorbide-based monomethacrylates, a therapeutic mud mixture and a method for its manufacture, measuring and monitoring concentration of substances in a biological fluid, frequency response measurement, and a molecularly imprinted polymer based electrically conductive surface, method of its preparation and sensor for neurotrophic factors.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to look at the dataframe\n",
      "Action: python_repl_ast\n",
      "Action Input: df.info()\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10 entries, 889 to 958\n",
      "Data columns (total 10 columns):\n",
      " #   Column                     Non-Null Count  Dtype         \n",
      "---  ------                     --------------  -----         \n",
      " 0   publication_number         10 non-null     object        \n",
      " 1   family_id                  10 non-null     object        \n",
      " 2   title_localized            10 non-null     object        \n",
      " 3   publication_date           10 non-null     datetime64[ns]\n",
      " 4   grant_date                 0 non-null      datetime64[ns]\n",
      " 5   cpc                        10 non-null     object        \n",
      " 6   inventor_harmonized        10 non-null     object        \n",
      " 7   assignee_harmonized        10 non-null     object        \n",
      " 8   inventor_harmonized_names  10 non-null     object        \n",
      " 9   assignee_harmonized_names  10 non-null     object        \n",
      "dtypes: datetime64[ns](2), object(8)\n",
      "memory usage: 880.0+ bytes\n",
      "\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: The dataframe contains 10 entries, with 10 columns of data. The columns contain information about the patent, such as the publication number, family id, title, publication date, grant date, cpc, inventor and assignee harmonized names, and inventor and assignee harmonized names.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The dataframe contains 10 entries, with 10 columns of data. The columns contain information about the patent, such as the publication number, family id, title, publication date, grant date, cpc, inventor and assignee harmonized names, and inventor and assignee harmonized names.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets create a dataframe agent \n",
    "\n",
    "#lets get our patents data\n",
    "patents_sample = (dg.get_estonian_patents()\n",
    " .explode('assignee_harmonized_names')\n",
    " .query('assignee_harmonized_names.str.contains(\"TALLINN\")')\n",
    " .drop_duplicates('family_id')\n",
    " .sample(10, random_state=42)\n",
    " .drop(columns=['inventor_harmonized_country_codes', 'assignee_harmonized_country_codes', 'abstract_localized', 'country_code', 'application_number', 'filing_date', 'priority_date']))\n",
    "\n",
    "#lets add memory so we can ask follow up questions\n",
    "MEMORY_KEY = \"chat_history\"\n",
    "prompt = OpenAIFunctionsAgent.create_prompt(\n",
    "    system_message=system_message,\n",
    "    extra_prompt_messages=[MessagesPlaceholder(variable_name=MEMORY_KEY)]\n",
    ")\n",
    "memory = ConversationBufferMemory(memory_key=MEMORY_KEY, return_messages=True)\n",
    "\n",
    "#let's instantiate a pandas df agent with a chat model                    \n",
    "agent = create_pandas_dataframe_agent(OpenAI(temperature=0), patents_sample, verbose=True, memory=memory)\n",
    "agent.run(\"what are the patents about?\")\n",
    "agent.run(\"can you tell me more about the patents?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸ›¸ TASK**: Reflect on the chain vs. agent approach. How do the two differ? \n",
    "\n",
    "Build your own **agent** using tools [from a list of available langchain tools](https://python.langchain.com/docs/integrations/tools/) and a combination of the components we've explored so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build your own agent here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”—ðŸ¤– Chains & Agents: Chaining it all together\n",
    "\n",
    "Nice. Now we're familiar with prompts, chains and agents. We also dabbled in using our own data (primarily patents) as part of building our LLM application. \n",
    "\n",
    "LangChain provides much more functionality for using external data sources than what we've seen. Using external data is a key part to building real-world use cases with LLM applications. Let's explore this in more detail in the cells below. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Data Augmented Generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“š Data Augmented Generation: Document Loaders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've been using data from our utils library. LangChain has many different integrations to be able to load data to use external sources in your LLM application, ranging from loading your own data from a local directory or AWS's S3 to external data sources from Twitter or Open City Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/india.kerlenesta/opt/anaconda3/envs/dap_taltech/lib/python3.9/site-packages/wikipedia/wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file /Users/india.kerlenesta/opt/anaconda3/envs/dap_taltech/lib/python3.9/site-packages/wikipedia/wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We have loaded a list of Document objects related to the Wikipedia query \"Barbie\"\n",
    "barbie_pages = WikipediaLoader(query=\"Barbie\", load_max_docs=10).load()\n",
    "len(barbie_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The page content begins as follows:\n",
      "\n",
      "Barbenheimer is an Internet phenomenon that began on social media before the simultaneous theatrical release of two blockbuster films, Barbie and Oppenheimer, on July 21, 2023, in the United States and several other countries. The word is a portmanteau of the films' titles. The contrast of Barbieâ€”a fantasy comedy by Greta Gerwig about the fashion doll Barbieâ€”and Oppenheimerâ€”an epic biographical thriller by Christopher Nolan about physicist J. Robert Oppenheimer, scientific director of the Manhattan Project, which developed the first nuclear weapons during World War IIâ€”prompted a comedic response from Internet users, including memes and merchandise. Polygon described the two films as \"extreme opposites\", and Variety called the phenomenon \"the movie event of the year\".The films' simultaneous release was an instance of counterprogramming. As their release date approached, instead of generating a rivalry, suggestions emerged to watch the films as a double featureâ€”as well as what order to w...\n"
     ]
    }
   ],
   "source": [
    "#lets have a look at a Document\n",
    "print(f\"The page content begins as follows:\")\n",
    "print('') \n",
    "print(f\"{barbie_pages[3].page_content[:1000]}...\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's as easy as that! Feel free to refer to LangChain's document loaders [here](https://python.langchain.com/docs/integrations/document_loaders/) to explore different types of loaders. \n",
    "\n",
    "We won't explore document loading or transformation too much in this tutorial. Instead, we pivot to focus on combining LLMs and traditional Information Retrieval (IR) techniques called Retrieval Augmented Generation (RAG), using langchain's document loaders as a departure point for building a vector database."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“š Data Augmented Generation: Retrival"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we've already seen, we can load external data sources and pass them to our LLMs as context via a prompt. However, sometimes when our data is much larger, we want to be able to retrieve the most relevant datapoints first. This is where **Retrieval Augmented Generation (RAG)** comes in.\n",
    "\n",
    "**RAG** is a new generative paradigm that fuses Large Language Models and traditional Information Retrieval (IR) techniques. We can use a retrieval system for the input prompt to augment the output generated by the LLM. This technique allows us to bypass fine-tuning as we can easily expose the model to external data (non-parametric), instead of having to retrain it on our domain-specific data. There are a number of advantages to RAG including:\n",
    "\n",
    "1. **Easy Knowledge Acquisition.** RAG methods allow can easily acquire knowledge from external sources, improving LLM performance within domain specific tasks.   \n",
    "\n",
    "2. **Minimal Training Cost.** The only training needed is the indexing of your knowledge base. No fine-tuning necessary.\n",
    "\n",
    "3. **Multiple Sources of Knowledge.**  With RAG, one can make use of multiple sources of knowledge, including those that are baked into the model parameters as well as information contained within many different knowledge bases.\n",
    "\n",
    "4. **Scalability.** Using performant vector databases, we can easily scale RAG to large datasets and handle complex queries.\n",
    "\n",
    "5. **Improved Performance & Reduced Hallucination.** RAG generates more accurate and contextually informed content by leveraging retrieval techniques, reducing the likelihood of generating incorrect or fabricated information.\n",
    "\n",
    "6. **Overcome Context-Window Limit.** All language models have a fixed length of tokens they can process at once, known as the context-window. Using Retrieval Augmentation, we can overcome this fixed text constraint, allowing the model to incorporate data from larger document collections \n",
    "\n",
    "7. **Return Sources.** RAG also offers explainability, which is essential for building trust in LLMs. Unlike a black-box LLM, RAG allows users to read the sources they retrieved and judge their relevance and credibility for themselves.\n",
    "\n",
    "_Taken from [Harnessing Retrieval Augmented Generation With Langchain](https://betterprogramming.pub/harnessing-retrieval-augmented-generation-with-langchain-2eae65926e82)_\n",
    "\n",
    "Let's build on our knowledge of prompts, chains, agents and document loading to explore RAG in more detail in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we will create a vector database from 9 barbie related wikipedia pages...\n"
     ]
    }
   ],
   "source": [
    "#1. Load data\n",
    "\n",
    "# First, we need to load data from a document loader - let's revisit our barbie example by loading barbie related wikipedia pages\n",
    "print(f\"we will create a vector database from {len(barbie_pages)} barbie related wikipedia pages...\")\n",
    "\n",
    "#2. Preprocess data\n",
    "\n",
    "# As we've already loaded the barbie pages, we need to preprocess the data next. \n",
    "# Let's revisit some of the techniques we learned in the text analysis tutorial to \n",
    "#preprocess our wikipedia pages. Let's chunk and tokenize our documents.\n",
    "\n",
    "##Itâ€™s important to chunk the data as we want to embed a meaningful length of context within our vector index. \n",
    "# Embedding just a word or two is too little information to match relevant vectors, and embedding entire pages would be too long \n",
    "# to fit within the context window of the prompt. Try to strike the right balance for your use case and dataset.\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "text_splitter = TokenTextSplitter(chunk_size=500, chunk_overlap=25)\n",
    "docs = text_splitter.split_documents(barbie_pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##3. Index your data\n",
    " \n",
    "# Once weâ€™ve gathered our data sources, itâ€™s time to build our knowledge-base index. \n",
    "# In general, the term â€œindexâ€ refers to a data structure that is used to optimize the retrieval of information \n",
    "# from a larger collection of data.\n",
    "# In this demo, I'll use the chromadb vector database, a free, open-source vector store that\n",
    "#runs on your local machine and OpenAI embeddings. \n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "#build our vector store with OpenAI embeddings and barbie pages\n",
    "db = Chroma.from_documents(docs, embeddings)\n",
    "\n",
    "##4. Build a Retriever\n",
    "\n",
    "#Once our vector store is indexed, itâ€™s time to define our retriever. Retriever is the module that determines \n",
    "# how the relevant documents are fetched from the vector database, determined by its search algorithm.\n",
    "# load index\n",
    "\n",
    "# initialize base retriever\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 3}) #we will return the top 3 results\n",
    "\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "compressor = LLMChainExtractor.from_llm(llm) #this will add contextual compression, meaning it will\n",
    "#iterate over the initially returned documents \n",
    "# and extract from each only the context relevant to the query, not the whole wikipedia page.\n",
    "reranker = ContextualCompressionRetriever(base_compressor=compressor, base_retriever=retriever) \n",
    "\n",
    "##5. Create our Conversational Retrieval Chain\n",
    "\n",
    "#Now that we've stored our data in a vector store and defined our retriever, \n",
    "# we can create our conversational retrieval chain.\n",
    "\n",
    "\n",
    "#Lets define memory so we can ask follow up questions\n",
    "memory = ConversationTokenBufferMemory(llm=llm, \n",
    "                                       memory_key=\"chat_history\", \n",
    "                                       return_messages=True, \n",
    "                                       input_key='question', \n",
    "                                       max_token_limit=1000)\n",
    "#Let's define our LLM chain\n",
    "\n",
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)\n",
    "\n",
    "question_generator = LLMChain(llm=llm, \n",
    "                              prompt=CONDENSE_QUESTION_PROMPT, \n",
    "                              verbose=True)\n",
    "#Let's define our answer chain\n",
    "answer_chain = load_qa_with_sources_chain(llm, chain_type=\"stuff\", verbose=True)\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "            retriever=reranker,\n",
    "            question_generator=question_generator,\n",
    "            combine_docs_chain=answer_chain,\n",
    "            verbose=True,\n",
    "            memory=memory,\n",
    "            rephrase_question=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazing! Now we can ask all our barbie related questions ðŸ’… ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "ALWAYS return a \"SOURCES\" part in your answer.\n",
      "\n",
      "QUESTION: Which state/country's law governs the interpretation of the contract?\n",
      "=========\n",
      "Content: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\n",
      "Source: 28-pl\n",
      "Content: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\n",
      "\n",
      "11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\n",
      "\n",
      "11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\n",
      "\n",
      "11.9 No Third-Party Beneficiaries.\n",
      "Source: 30-pl\n",
      "Content: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any Anti-Bribery Laws (as  defined in Clause 8.5) or that such a violation is reasonably likely to occur,\n",
      "Source: 4-pl\n",
      "=========\n",
      "FINAL ANSWER: This Agreement is governed by English law.\n",
      "SOURCES: 28-pl\n",
      "\n",
      "QUESTION: What did the president say about Michael Jackson?\n",
      "=========\n",
      "Content: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
      "\n",
      "Last year COVID-19 kept us apart. This year we are finally together again. \n",
      "\n",
      "Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n",
      "\n",
      "With a duty to one another to the American people to the Constitution. \n",
      "\n",
      "And with an unwavering resolve that freedom will always triumph over tyranny. \n",
      "\n",
      "Six days ago, Russiaâ€™s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \n",
      "\n",
      "He thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \n",
      "\n",
      "He met the Ukrainian people. \n",
      "\n",
      "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \n",
      "\n",
      "Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.\n",
      "Source: 0-pl\n",
      "Content: And we wonâ€™t stop. \n",
      "\n",
      "We have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \n",
      "\n",
      "Letâ€™s use this moment to reset. Letâ€™s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \n",
      "\n",
      "Letâ€™s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \n",
      "\n",
      "We canâ€™t change how divided weâ€™ve been. But we can change how we move forwardâ€”on COVID-19 and other issues we must face together. \n",
      "\n",
      "I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \n",
      "\n",
      "They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \n",
      "\n",
      "Officer Mora was 27 years old. \n",
      "\n",
      "Officer Rivera was 22. \n",
      "\n",
      "Both Dominican Americans whoâ€™d grown up on the same streets they later chose to patrol as police officers. \n",
      "\n",
      "I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\n",
      "Source: 24-pl\n",
      "Content: And a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \n",
      "\n",
      "To all Americans, I will be honest with you, as Iâ€™ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \n",
      "\n",
      "And Iâ€™m taking robust action to make sure the pain of our sanctions  is targeted at Russiaâ€™s economy. And I will use every tool at our disposal to protect American businesses and consumers. \n",
      "\n",
      "Tonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \n",
      "\n",
      "America will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \n",
      "\n",
      "These steps will help blunt gas prices here at home. And I know the news about whatâ€™s happening can seem alarming. \n",
      "\n",
      "But I want you to know that we are going to be okay.\n",
      "Source: 5-pl\n",
      "Content: More support for patients and families. \n",
      "\n",
      "To get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \n",
      "\n",
      "Itâ€™s based on DARPAâ€”the Defense Department project that led to the Internet, GPS, and so much more.  \n",
      "\n",
      "ARPA-H will have a singular purposeâ€”to drive breakthroughs in cancer, Alzheimerâ€™s, diabetes, and more. \n",
      "\n",
      "A unity agenda for the nation. \n",
      "\n",
      "We can do this. \n",
      "\n",
      "My fellow Americansâ€”tonight , we have gathered in a sacred spaceâ€”the citadel of our democracy. \n",
      "\n",
      "In this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \n",
      "\n",
      "We have fought for freedom, expanded liberty, defeated totalitarianism and terror. \n",
      "\n",
      "And built the strongest, freest, and most prosperous nation the world has ever known. \n",
      "\n",
      "Now is the hour. \n",
      "\n",
      "Our moment of responsibility. \n",
      "\n",
      "Our test of resolve and conscience, of history itself. \n",
      "\n",
      "It is in this moment that our character is formed. Our purpose is found. Our future is forged. \n",
      "\n",
      "Well I know this nation.\n",
      "Source: 34-pl\n",
      "=========\n",
      "FINAL ANSWER: The president did not mention Michael Jackson.\n",
      "SOURCES:\n",
      "\n",
      "QUESTION: Who directed the Barbie film?\n",
      "=========\n",
      "Content: Greta Gerwig\n",
      "Source: https://en.wikipedia.org/wiki/Barbie_(film)\n",
      "\n",
      "Content: Mattel partnered with animation studios to produce films which were broadcast on Nickelodeon in the United States from 2002 and released on home video formats, originally by Family Home Entertainment and successor Lionsgate, and then predominantly by Universal Pictures Home Entertainment, both until 2017.\n",
      "Source: https://en.wikipedia.org/wiki/List_of_Barbie_animated_films\n",
      "=========\n",
      "FINAL ANSWER:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The director of the Barbie film is Greta Gerwig.\\nSOURCES: https://en.wikipedia.org/wiki/Barbie_(film), https://en.wikipedia.org/wiki/List_of_Barbie_animated_films'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Who directed the Barbie film?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: Who directed the Barbie film?\n",
      "Assistant: The director of the Barbie film is Greta Gerwig.\n",
      "SOURCES: https://en.wikipedia.org/wiki/Barbie_(film), https://en.wikipedia.org/wiki/List_of_Barbie_animated_films\n",
      "Follow Up Input: Who did she produce the film with?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "ALWAYS return a \"SOURCES\" part in your answer.\n",
      "\n",
      "QUESTION: Which state/country's law governs the interpretation of the contract?\n",
      "=========\n",
      "Content: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\n",
      "Source: 28-pl\n",
      "Content: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\n",
      "\n",
      "11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\n",
      "\n",
      "11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\n",
      "\n",
      "11.9 No Third-Party Beneficiaries.\n",
      "Source: 30-pl\n",
      "Content: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any Anti-Bribery Laws (as  defined in Clause 8.5) or that such a violation is reasonably likely to occur,\n",
      "Source: 4-pl\n",
      "=========\n",
      "FINAL ANSWER: This Agreement is governed by English law.\n",
      "SOURCES: 28-pl\n",
      "\n",
      "QUESTION: What did the president say about Michael Jackson?\n",
      "=========\n",
      "Content: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
      "\n",
      "Last year COVID-19 kept us apart. This year we are finally together again. \n",
      "\n",
      "Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n",
      "\n",
      "With a duty to one another to the American people to the Constitution. \n",
      "\n",
      "And with an unwavering resolve that freedom will always triumph over tyranny. \n",
      "\n",
      "Six days ago, Russiaâ€™s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \n",
      "\n",
      "He thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \n",
      "\n",
      "He met the Ukrainian people. \n",
      "\n",
      "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \n",
      "\n",
      "Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.\n",
      "Source: 0-pl\n",
      "Content: And we wonâ€™t stop. \n",
      "\n",
      "We have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \n",
      "\n",
      "Letâ€™s use this moment to reset. Letâ€™s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \n",
      "\n",
      "Letâ€™s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \n",
      "\n",
      "We canâ€™t change how divided weâ€™ve been. But we can change how we move forwardâ€”on COVID-19 and other issues we must face together. \n",
      "\n",
      "I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \n",
      "\n",
      "They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \n",
      "\n",
      "Officer Mora was 27 years old. \n",
      "\n",
      "Officer Rivera was 22. \n",
      "\n",
      "Both Dominican Americans whoâ€™d grown up on the same streets they later chose to patrol as police officers. \n",
      "\n",
      "I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\n",
      "Source: 24-pl\n",
      "Content: And a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \n",
      "\n",
      "To all Americans, I will be honest with you, as Iâ€™ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \n",
      "\n",
      "And Iâ€™m taking robust action to make sure the pain of our sanctions  is targeted at Russiaâ€™s economy. And I will use every tool at our disposal to protect American businesses and consumers. \n",
      "\n",
      "Tonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \n",
      "\n",
      "America will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \n",
      "\n",
      "These steps will help blunt gas prices here at home. And I know the news about whatâ€™s happening can seem alarming. \n",
      "\n",
      "But I want you to know that we are going to be okay.\n",
      "Source: 5-pl\n",
      "Content: More support for patients and families. \n",
      "\n",
      "To get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \n",
      "\n",
      "Itâ€™s based on DARPAâ€”the Defense Department project that led to the Internet, GPS, and so much more.  \n",
      "\n",
      "ARPA-H will have a singular purposeâ€”to drive breakthroughs in cancer, Alzheimerâ€™s, diabetes, and more. \n",
      "\n",
      "A unity agenda for the nation. \n",
      "\n",
      "We can do this. \n",
      "\n",
      "My fellow Americansâ€”tonight , we have gathered in a sacred spaceâ€”the citadel of our democracy. \n",
      "\n",
      "In this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \n",
      "\n",
      "We have fought for freedom, expanded liberty, defeated totalitarianism and terror. \n",
      "\n",
      "And built the strongest, freest, and most prosperous nation the world has ever known. \n",
      "\n",
      "Now is the hour. \n",
      "\n",
      "Our moment of responsibility. \n",
      "\n",
      "Our test of resolve and conscience, of history itself. \n",
      "\n",
      "It is in this moment that our character is formed. Our purpose is found. Our future is forged. \n",
      "\n",
      "Well I know this nation.\n",
      "Source: 34-pl\n",
      "=========\n",
      "FINAL ANSWER: The president did not mention Michael Jackson.\n",
      "SOURCES:\n",
      "\n",
      "QUESTION: Who did she produce the film with?\n",
      "=========\n",
      "Content: Mattel partnered with animation studios to produce films.\n",
      "Source: https://en.wikipedia.org/wiki/List_of_Barbie_animated_films\n",
      "\n",
      "Content: Laurence Mark producing.\n",
      "Source: https://en.wikipedia.org/wiki/Barbie_(film)\n",
      "=========\n",
      "FINAL ANSWER:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'She produced the film with Laurence Mark.\\nSOURCES: https://en.wikipedia.org/wiki/Barbie_(film)'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"Who did she produce the film with?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
      "\n",
      "Chat History:\n",
      "\n",
      "Human: Who directed the Barbie film?\n",
      "Assistant: The director of the Barbie film is Greta Gerwig.\n",
      "SOURCES: https://en.wikipedia.org/wiki/Barbie_(film), https://en.wikipedia.org/wiki/List_of_Barbie_animated_films\n",
      "Human: Who did she produce the film with?\n",
      "Assistant: She produced the film with Laurence Mark.\n",
      "SOURCES: https://en.wikipedia.org/wiki/Barbie_(film)\n",
      "Follow Up Input: What does Barbie have to do with Oppenheimer?\n",
      "Standalone question:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGiven the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\"). \n",
      "If you don't know the answer, just say that you don't know. Don't try to make up an answer.\n",
      "ALWAYS return a \"SOURCES\" part in your answer.\n",
      "\n",
      "QUESTION: Which state/country's law governs the interpretation of the contract?\n",
      "=========\n",
      "Content: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English courts in  relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may apply to any court for an  injunction or other relief to protect its Intellectual Property Rights.\n",
      "Source: 28-pl\n",
      "Content: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver of such (or any other)  right or remedy.\n",
      "\n",
      "11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall not affect the continuation  in force of the remainder of the term (if any) and this Agreement.\n",
      "\n",
      "11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or joint venture of any  kind between the parties.\n",
      "\n",
      "11.9 No Third-Party Beneficiaries.\n",
      "Source: 30-pl\n",
      "Content: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any Anti-Bribery Laws (as  defined in Clause 8.5) or that such a violation is reasonably likely to occur,\n",
      "Source: 4-pl\n",
      "=========\n",
      "FINAL ANSWER: This Agreement is governed by English law.\n",
      "SOURCES: 28-pl\n",
      "\n",
      "QUESTION: What did the president say about Michael Jackson?\n",
      "=========\n",
      "Content: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \n",
      "\n",
      "Last year COVID-19 kept us apart. This year we are finally together again. \n",
      "\n",
      "Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \n",
      "\n",
      "With a duty to one another to the American people to the Constitution. \n",
      "\n",
      "And with an unwavering resolve that freedom will always triumph over tyranny. \n",
      "\n",
      "Six days ago, Russiaâ€™s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \n",
      "\n",
      "He thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \n",
      "\n",
      "He met the Ukrainian people. \n",
      "\n",
      "From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world. \n",
      "\n",
      "Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland.\n",
      "Source: 0-pl\n",
      "Content: And we wonâ€™t stop. \n",
      "\n",
      "We have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life. \n",
      "\n",
      "Letâ€™s use this moment to reset. Letâ€™s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A God-awful disease.  \n",
      "\n",
      "Letâ€™s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.  \n",
      "\n",
      "We canâ€™t change how divided weâ€™ve been. But we can change how we move forwardâ€”on COVID-19 and other issues we must face together. \n",
      "\n",
      "I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner, Officer Jason Rivera. \n",
      "\n",
      "They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun. \n",
      "\n",
      "Officer Mora was 27 years old. \n",
      "\n",
      "Officer Rivera was 22. \n",
      "\n",
      "Both Dominican Americans whoâ€™d grown up on the same streets they later chose to patrol as police officers. \n",
      "\n",
      "I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their mission to restore the trust and safety every community deserves.\n",
      "Source: 24-pl\n",
      "Content: And a proud Ukrainian people, who have known 30 years  of independence, have repeatedly shown that they will not tolerate anyone who tries to take their country backwards.  \n",
      "\n",
      "To all Americans, I will be honest with you, as Iâ€™ve always promised. A Russian dictator, invading a foreign country, has costs around the world. \n",
      "\n",
      "And Iâ€™m taking robust action to make sure the pain of our sanctions  is targeted at Russiaâ€™s economy. And I will use every tool at our disposal to protect American businesses and consumers. \n",
      "\n",
      "Tonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil from reserves around the world.  \n",
      "\n",
      "America will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready to do more if necessary, unified with our allies.  \n",
      "\n",
      "These steps will help blunt gas prices here at home. And I know the news about whatâ€™s happening can seem alarming. \n",
      "\n",
      "But I want you to know that we are going to be okay.\n",
      "Source: 5-pl\n",
      "Content: More support for patients and families. \n",
      "\n",
      "To get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \n",
      "\n",
      "Itâ€™s based on DARPAâ€”the Defense Department project that led to the Internet, GPS, and so much more.  \n",
      "\n",
      "ARPA-H will have a singular purposeâ€”to drive breakthroughs in cancer, Alzheimerâ€™s, diabetes, and more. \n",
      "\n",
      "A unity agenda for the nation. \n",
      "\n",
      "We can do this. \n",
      "\n",
      "My fellow Americansâ€”tonight , we have gathered in a sacred spaceâ€”the citadel of our democracy. \n",
      "\n",
      "In this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \n",
      "\n",
      "We have fought for freedom, expanded liberty, defeated totalitarianism and terror. \n",
      "\n",
      "And built the strongest, freest, and most prosperous nation the world has ever known. \n",
      "\n",
      "Now is the hour. \n",
      "\n",
      "Our moment of responsibility. \n",
      "\n",
      "Our test of resolve and conscience, of history itself. \n",
      "\n",
      "It is in this moment that our character is formed. Our purpose is found. Our future is forged. \n",
      "\n",
      "Well I know this nation.\n",
      "Source: 34-pl\n",
      "=========\n",
      "FINAL ANSWER: The president did not mention Michael Jackson.\n",
      "SOURCES:\n",
      "\n",
      "QUESTION: What does Barbie have to do with Oppenheimer?\n",
      "=========\n",
      "Content: Barbenheimer is an Internet phenomenon that began on social media before the simultaneous theatrical release of two blockbuster films, Barbie and Oppenheimer, on July 21, 2023, in the United States and several other countries. The word is a portmanteau of the films' titles. The contrast of Barbieâ€”a fantasy comedy by Greta Gerwig about the fashion doll Barbieâ€”and Oppenheimerâ€”an epic biographical thriller by Christopher Nolan about physicist J. Robert Oppenheimer, scientific director of the Manhattan Project, which developed the first nuclear weapons during World War IIâ€”prompted a comedic response from Internet users, including memes and merchandise.\n",
      "Source: https://en.wikipedia.org/wiki/Barbenheimer\n",
      "\n",
      "Content: Barbenheimer is an Internet phenomenon that began on social media before the simultaneous theatrical release of two blockbuster films, Barbie and Oppenheimer, on July 21, 2023, in the United States and several other countries. The word is a portmanteau of the films' titles. The contrast of Barbieâ€”a fantasy comedy by Greta Gerwig about the fashion doll Barbieâ€”and Oppenheimerâ€”an epic biographical thriller by Christopher Nolan about physicist J. Robert Oppenheimer, scientific director of the Manhattan Project, which developed the first nuclear weapons during World War IIâ€”prompted a comedic response from Internet users, including memes and merchandise.\n",
      "Source: https://en.wikipedia.org/wiki/Barbenheimer\n",
      "\n",
      "Content: Barbenheimer is an Internet phenomenon that began on social media before the simultaneous theatrical release of two blockbuster films, Barbie and Oppenheimer, on July 21, 2023, in the United States and several other countries. The word is a portmanteau of the films' titles. The contrast of Barbieâ€”a fantasy comedy by Greta Gerwig about the fashion doll Barbieâ€”and Oppenheimerâ€”an epic biographical thriller by Christopher Nolan about physicist J. Robert Oppenheimer, scientific director of the Manhattan Project, which developed the first nuclear weapons during World War IIâ€”prompted a comedic response from Internet users, including memes and merchandise.\n",
      "Source: https://en.wikipedia.org/wiki/Barbenheimer\n",
      "=========\n",
      "FINAL ANSWER:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Barbie and Oppenheimer are two blockbuster films that were released simultaneously on July 21, 2023. The contrast between the two films, Barbie being a fantasy comedy and Oppenheimer being an epic biographical thriller about physicist J. Robert Oppenheimer, led to an Internet phenomenon called Barbenheimer. This phenomenon included memes and merchandise related to the combination of the two films. \\nSOURCES: https://en.wikipedia.org/wiki/Barbenheimer'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What does Barbie have to do with Oppenheimer?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸ›¸ TASK**: Build your own `ConversationalRetrievalChain` using a different data source to index in a vector store. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is my own example..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ“š Data Augmented Generation: Chaining it all together\n",
    "\n",
    "Great! We've learned about:\n",
    "\n",
    "1. **Document Loaders**: Ways to load external data sources into our LLM application.\n",
    "2. **Retrival**: How to use a vector database to retrieve the most relevant datapoints from our external data sources."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸ§ A note on Evaluation\n",
    "\n",
    "Throughout these exercises, responses from LLMs and chat models have not always been accurate. Evaluating LLMs systems is the wild west. There are some ways to evaluate compontents of a system like A/B testing prompts and examples or using LLMs to evaluate the quality of its responses. \n",
    "\n",
    "To learn more about evaluating LLM applications, check out [this video of Josh Tobin discussing evaluation from LLMs in prod conference](https://www.youtube.com/watch?v=r-HUnht-Gns)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ‰ Conclusions\n",
    "\n",
    "From this tutorial, you should have a sense of how to build LLM applications using LangChain. You've familiarised yourself with:\n",
    "\n",
    "1. **Prompting.** How to make use of a prompt template, the benefits of few-shot prompting, how to format instructions to parse the output of a model.\n",
    "\n",
    "2. **Chains & Agents.** How to write a simple LLMChain, how to build a sequential chain and investigating agents.  \n",
    "\n",
    "3. **Data Augmented Generation.** How to use document loaders to load external data sources; how to create a vector database and store external data as embeddings; how to build a qa chain using a vector database.\n",
    "\n",
    "Let's see how we can build an LLM application around these areas in a practical use case, focused on innovation mapping. Please head to the `./llm_innovation_mapping.ipynb` notebook to follow along. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dap_taltech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "10280fdd29a5f790370cdf255c4a66c215f248ca8aa68590910e05113a9680f8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
